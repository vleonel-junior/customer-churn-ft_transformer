"""
√âtapes d'Entra√Ænement pour FTT++

Ce module contient les deux √©tapes d'entra√Ænement du pipeline FTT++ :
1. Stage1Trainer - Entra√Ænement FTT+ et s√©lection des features importantes
2. Stage2Trainer - Entra√Ænement Random sur les features s√©lectionn√©es
"""

import torch
import torch.nn as nn
import time
from typing import Dict, List, Tuple, Optional, Any

from .random_model import InterpretableFTTRandom
from .config import FeatureMapping
from ftt_plus.model import InterpretableFTTPlus

from train.Telecom.train_ftt_plus.train_func import train, val, evaluate
from num_embedding_factory import get_num_embedding
import zero


class Stage1Trainer:
    """
    Gestionnaire de l'√©tape 1 : Entra√Ænement FTT+ et s√©lection des features importantes.
    """
    
    def __init__(self, feature_mapping: FeatureMapping, ftt_plus_config: Dict[str, Any], 
                 M: int, results_dir: str):
        """
        Args:
            feature_mapping: Mapping des features
            ftt_plus_config: Configuration du mod√®le FTT+
            M: Nombre de features √† s√©lectionner
            results_dir: R√©pertoire de sauvegarde
        """
        self.feature_mapping = feature_mapping
        self.ftt_plus_config = ftt_plus_config
        self.M = M
        self.results_dir = results_dir
    
    def train_ftt_plus(
        self,
        X: Dict[str, Tuple[torch.Tensor, torch.Tensor]],
        y: Dict[str, torch.Tensor],
        cat_cardinalities: List[int],
        n_epochs: int = 50,
        lr: float = 1e-3,
        batch_size: int = 64,
        patience: int = 10,
        seed: int = 0,
        embedding_type: str = "LR",
        device: str = 'cuda'
    ) -> Dict[str, Any]:
        """
        Entra√Æne un mod√®le FTT+ complet et s√©lectionne les features importantes.
        
        Args:
            X: Donn√©es d'entr√©e (train, val, test) avec X[split] = (x_num, x_cat)
            y: Labels (train, val, test)
            cat_cardinalities: Cardinalit√©s des features cat√©gorielles
            n_epochs: Nombre d'√©poques d'entra√Ænement
            lr: Taux d'apprentissage
            batch_size: Taille des batches
            patience: Patience pour early stopping
            seed: Seed pour la reproductibilit√©
            embedding_type: Type d'embedding num√©rique
            device: Device configur√© par setup_device() dans le script d'entra√Ænement
            
        Returns:
            R√©sultats de l'√©tape 1 avec features s√©lectionn√©es
        """
        print("üöÄ === √âTAPE 1: Entra√Ænement FTT+ Complet ===")
        print(f"üñ•Ô∏è  Device utilis√©: {device}")
        
        # Validation des donn√©es avec le mapping
        n_num_features = X['train'][0].shape[1]
        n_cat_features = X['train'][1].shape[1] if X['train'][1] is not None else 0
        self.feature_mapping.validate_data_consistency(n_num_features, n_cat_features)
        
        # Cr√©er et configurer le mod√®le FTT+
        model_ftt_plus = self._create_ftt_plus_model(
            n_num_features, cat_cardinalities, embedding_type, X, y, device
        )
        
        # Entra√Ænement complet
        training_results = self._train_model(
            model_ftt_plus, X, y, n_epochs, lr, batch_size, patience, device
        )
        
        # √âvaluation finale
        performance_results = self._evaluate_model(model_ftt_plus, X, y, seed)
        
        # Analyse d'interpr√©tabilit√© et s√©lection des features
        interpretability_results, selected_features, feature_importance_scores = (
            self._analyze_and_select_features(
                model_ftt_plus, X, y, seed, n_num_features, cat_cardinalities, 
                embedding_type, training_results, performance_results
            )
        )
        
        # R√©sultats de l'√©tape 1
        stage1_results = {
            'model_ftt_plus': model_ftt_plus,
            'selected_features': selected_features,
            'feature_importance_scores': feature_importance_scores,
            'cls_importance_all': interpretability_results['cls_importance'],
            'n_total_features': len(self.feature_mapping.all_feature_names),
            'n_selected_features': self.M,
            'selection_ratio': self.M / len(self.feature_mapping.all_feature_names),
            'training_results': training_results,
            'performance_results': performance_results,
            'interpretability_results': interpretability_results
        }
        
        return stage1_results
    
    def _create_ftt_plus_model(self, n_num_features: int, cat_cardinalities: List[int],
                              embedding_type: str, X: Dict, y: Dict, device: str) -> InterpretableFTTPlus:
        """Cr√©e et configure le mod√®le FTT+."""
        model_ftt_plus = InterpretableFTTPlus.make_baseline(
            n_num_features=n_num_features,
            cat_cardinalities=cat_cardinalities,
            **self.ftt_plus_config
        )
        
        # Embedding num√©rique personnalis√©
        print(f"Type d'embedding num√©rique: {embedding_type}")
        num_embedding = get_num_embedding(
            embedding_type=embedding_type,
            X_train=X['train'][0],
            d_embedding=self.ftt_plus_config['d_token'],
            y_train=y['train'] if embedding_type in ("T", "T-L", "T-LR", "T-LR-LR") else None
        )
        model_ftt_plus.feature_tokenizer.num_tokenizer = num_embedding
        
        model_ftt_plus.to(device)
        
        print(f"Mod√®le FTT+ cr√©√© avec {sum(p.numel() for p in model_ftt_plus.parameters()):,} param√®tres")
        
        return model_ftt_plus
    
    def _train_model(self, model: nn.Module, X: Dict, y: Dict, n_epochs: int,
                    lr: float, batch_size: int, patience: int, device: str) -> Dict[str, Any]:
        """Entra√Æne le mod√®le avec early stopping."""
        # Cr√©er les loaders
        train_loader = zero.data.IndexLoader(len(y['train']), batch_size, device=device)
        val_loader = zero.data.IndexLoader(len(y['val']), batch_size, device=device)
        
        # Optimiseur et fonction de perte
        optimizer = torch.optim.AdamW(model.optimization_param_groups(), lr=lr, weight_decay=0.0)
        loss_fn = torch.nn.BCEWithLogitsLoss()
        
        # Entra√Ænement
        print("‚è≥ Entra√Ænement du mod√®le FTT+ en cours...")
        train_loss_list = []
        val_loss_list = []
        best_val_loss = float('inf')
        best_epoch = 0
        patience_counter = 0
        best_model_state = None
        
        for epoch in range(n_epochs):
            start_time = time.time()
            
            # Entra√Ænement
            train_loss = train(epoch, model, optimizer, X, y, train_loader, loss_fn)
            
            # Validation
            val_loss = val(epoch, model, X, y, val_loader, loss_fn)
            
            # Sauvegarde des m√©triques
            train_loss_list.append(train_loss)
            val_loss_list.append(val_loss)
            
            epoch_time = time.time() - start_time
            print(f'Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Time: {epoch_time:.2f}s')
            
            # Early stopping et sauvegarde du meilleur mod√®le
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                best_epoch = epoch
                patience_counter = 0
                best_model_state = model.state_dict().copy()
                print(f' <<< NOUVEAU MEILLEUR MOD√àLE (val_loss: {val_loss:.4f})')
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    print(f'\nEarly stopping √† l\'√©poque {epoch} (patience: {patience})')
                    break
        
        # Charger le meilleur mod√®le
        if best_model_state is not None:
            model.load_state_dict(best_model_state)
            print(f"‚úÖ Meilleur mod√®le charg√© (√©poque {best_epoch}, val_loss: {best_val_loss:.4f})")
        
        return {
            'train_losses': train_loss_list,
            'val_losses': val_loss_list,
            'best_epoch': best_epoch,
            'best_val_loss': best_val_loss
        }
    
    def _evaluate_model(self, model: nn.Module, X: Dict, y: Dict, seed: int) -> Dict[str, Any]:
        """√âvalue le mod√®le sur validation et test."""
        print("\n √âvaluation finale du mod√®le FTT+...")
        val_performance = evaluate(model, 'val', X, y, seed)
        test_performance = evaluate(model, 'test', X, y, seed)
        
        return {
            'val': val_performance,
            'test': test_performance
        }
    
    def _analyze_and_select_features(self, model: nn.Module, X: Dict, y: Dict, seed: int,
                                   n_num_features: int, cat_cardinalities: List[int],
                                   embedding_type: str, training_results: Dict,
                                   performance_results: Dict) -> Tuple[Dict, List[str], Dict[str, float]]:
        """Analyse l'interpr√©tabilit√© et s√©lectionne les M features importantes."""
        print("\nüîç Analyse d'interpr√©tabilit√© avec interpretability_analyzer...")
        
        model_config = {
            'n_num_features': n_num_features,
            'cat_cardinalities': cat_cardinalities,
            'embedding_type': embedding_type,
            **self.ftt_plus_config
        }

        from interpretability_analyzer import analyze_interpretability
        
        # Utiliser interpretability_analyzer pour l'analyse compl√®te
        interpretability_results = analyze_interpretability(
            model=model,
            X=X,
            y=y,
            model_name='interpretable_ftt_plus',
            seed=seed,
            model_config=model_config,
            training_results=training_results,
            performance_results=performance_results,
            feature_names=self.feature_mapping.all_feature_names,
            local_output_dir=None,  # Pas de sauvegarde locale pour l'√©tape 1
            results_base_dir=str(self.results_dir)
        )
        
        # Extraire l'importance des features depuis les r√©sultats
        cls_importance = interpretability_results['cls_importance']
        
        # S√©lectionner les M features les plus importantes
        print(f"\nüéØ S√©lection des {self.M} features les plus importantes...")
        sorted_importance = sorted(cls_importance.items(), key=lambda x: x[1], reverse=True)
        selected_features = [name for name, score in sorted_importance[:self.M]]
        feature_importance_scores = {name: score for name, score in sorted_importance[:self.M]}
        
        print("üìã Features s√©lectionn√©es:")
        for i, (feature, score) in enumerate(feature_importance_scores.items(), 1):
            feature_type = "NUM" if feature in self.feature_mapping.num_feature_names else "CAT"
            print(f"  {i:2d}. {feature:<20} ({feature_type}): {score:.4f}")
        
        return interpretability_results, selected_features, feature_importance_scores


class Stage2Trainer:
    """
    Gestionnaire de l'√©tape 2 : Entra√Ænement Random sur les features s√©lectionn√©es.
    """
    
    def __init__(self, feature_mapping: FeatureMapping, random_model_config: Dict[str, Any],
                 k: int, attention_seed: int):
        """
        Args:
            feature_mapping: Mapping des features
            random_model_config: Configuration du mod√®le Random
            k: Nombre d'interactions al√©atoires
            attention_seed: Seed pour l'attention
        """
        self.feature_mapping = feature_mapping
        self.random_model_config = random_model_config
        self.k = k
        self.attention_seed = attention_seed
    
    def train_random_model(
        self,
        X: Dict[str, Tuple[torch.Tensor, torch.Tensor]],
        y: Dict[str, torch.Tensor],
        cat_cardinalities: List[int],
        selected_features: List[str],
        n_epochs: int = 50,
        lr: float = 1e-3,
        batch_size: int = 64,
        patience: int = 10,
        seed: int = 0,
        device: str = 'cuda'
    ) -> Dict[str, Any]:
        """
        Entra√Æne un mod√®le Random sur les features s√©lectionn√©es.
        
        Args:
            X: Donn√©es d'entr√©e (train, val, test)
            y: Labels (train, val, test)
            cat_cardinalities: Cardinalit√©s des features cat√©gorielles
            selected_features: Features s√©lectionn√©es de l'√©tape 1
            n_epochs: Nombre d'√©poques d'entra√Ænement
            lr: Taux d'apprentissage
            batch_size: Taille des batches
            patience: Patience pour early stopping
            seed: Seed pour la reproductibilit√©
            device: Device configur√© par setup_device() dans le script d'entra√Ænement
            
        Returns:
            R√©sultats de l'√©tape 2
        """
        print("\nüéØ === √âTAPE 2: Entra√Ænement Mod√®le Random ===")
        print(f"üñ•Ô∏è  Device utilis√©: {device}")
        
        # Cr√©er et configurer le mod√®le Random
        model_random, attention_stats = self._create_random_model(
            selected_features, cat_cardinalities, device
        )
        
        # Entra√Ænement complet
        training_results = self._train_model(
            model_random, X, y, n_epochs, lr, batch_size, patience, device
        )
        
        # √âvaluation finale
        performance_results = self._evaluate_model(model_random, X, y, seed)
        
        # Analyse de l'importance dans le mod√®le Random
        random_importance = self._analyze_random_importance(model_random, X, selected_features)
        
        # Analyse d'interpr√©tabilit√© compl√®te pour le mod√®le Random
        self._analyze_random_interpretability(
            model_random, X, y, seed, selected_features, cat_cardinalities,
            training_results, performance_results
        )
        
        # R√©sultats de l'√©tape 2
        stage2_results = {
            'model_random': model_random,
            'selected_features': selected_features,
            'selected_indices_num': self.selected_indices_num,
            'selected_indices_cat': self.selected_indices_cat,
            'cat_cardinalities_selected': self.cat_cardinalities_selected,
            'random_importance_scores': random_importance,
            'attention_statistics': attention_stats,
            'sparsity_ratio': attention_stats['sparsity_ratio'],
            'n_parameters': sum(p.numel() for p in model_random.parameters()),
            'training_results': training_results,
            'performance_results': performance_results
        }
        
        return stage2_results
    
    def _create_random_model(self, selected_features: List[str], cat_cardinalities: List[int],
                           device: str) -> Tuple[InterpretableFTTRandom, Dict[str, Any]]:
        """Cr√©e et configure le mod√®le Random."""
        # Utiliser le mapping robuste pour d√©terminer les indices
        selected_indices_num, selected_indices_cat = (
            self.feature_mapping.get_selected_feature_indices(selected_features)
        )
        
        # Sauvegarder pour utilisation ult√©rieure
        self.selected_indices_num = selected_indices_num
        self.selected_indices_cat = selected_indices_cat
        
        # Cardinalit√©s des features cat√©gorielles s√©lectionn√©es
        cat_cardinalities_selected = [cat_cardinalities[i] for i in selected_indices_cat]
        self.cat_cardinalities_selected = cat_cardinalities_selected
        
        print(f"üìä Features s√©lectionn√©es: {len(selected_indices_num)} num√©riques, {len(selected_indices_cat)} cat√©gorielles")
        print(f"üé≤ Interactions al√©atoires: {self.k} paires")
        
        # Cr√©er le mod√®le Random
        model_random = InterpretableFTTRandom.from_selected_features(
            selected_feature_indices_num=selected_indices_num,
            selected_feature_indices_cat=selected_indices_cat,
            cat_cardinalities_selected=cat_cardinalities_selected,
            k=self.k,
            attention_seed=self.attention_seed,
            **self.random_model_config
        )
        
        model_random.to(device)
        
        print(f"Mod√®le Random cr√©√© avec {sum(p.numel() for p in model_random.parameters()):,} param√®tres")
        
        # Statistiques d'attention sparse
        attention_stats = model_random.get_attention_statistics()
        print(f"üîó Sparsit√© d'attention: {attention_stats['sparsity_ratio']:.2%}")
        print(f"   - Connexions feature-feature: {attention_stats['feature_feature_connections']}")
        
        return model_random, attention_stats
    
    def _train_model(self, model: nn.Module, X: Dict, y: Dict, n_epochs: int,
                    lr: float, batch_size: int, patience: int, device: str) -> Dict[str, Any]:
        """Entra√Æne le mod√®le Random avec early stopping."""
        # Cr√©er les loaders
        train_loader = zero.data.IndexLoader(len(y['train']), batch_size, device=device)
        val_loader = zero.data.IndexLoader(len(y['val']), batch_size, device=device)
        
        # Optimiseur et fonction de perte
        optimizer = torch.optim.AdamW(model.optimization_param_groups(), lr=lr, weight_decay=0.0)
        loss_fn = torch.nn.BCEWithLogitsLoss()
        
        # Entra√Ænement
        print("‚è≥ Entra√Ænement du mod√®le Random en cours...")
        train_loss_list = []
        val_loss_list = []
        best_val_loss = float('inf')
        best_epoch = 0
        patience_counter = 0
        best_model_state = None
        
        for epoch in range(n_epochs):
            start_time = time.time()
            
            # Entra√Ænement
            train_loss = train(epoch, model, optimizer, X, y, train_loader, loss_fn)
            
            # Validation
            val_loss = val(epoch, model, X, y, val_loader, loss_fn)
            
            # Sauvegarde des m√©triques
            train_loss_list.append(train_loss)
            val_loss_list.append(val_loss)
            
            epoch_time = time.time() - start_time
            print(f'Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Time: {epoch_time:.2f}s')
            
            # Early stopping et sauvegarde du meilleur mod√®le
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                best_epoch = epoch
                patience_counter = 0
                best_model_state = model.state_dict().copy()
                print(f' <<< NOUVEAU MEILLEUR MOD√àLE (val_loss: {val_loss:.4f})')
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    print(f'\nEarly stopping √† l\'√©poque {epoch} (patience: {patience})')
                    break
        
        # Charger le meilleur mod√®le
        if best_model_state is not None:
            model.load_state_dict(best_model_state)
            print(f"‚úÖ Meilleur mod√®le Random charg√© (√©poque {best_epoch}, val_loss: {best_val_loss:.4f})")
        
        return {
            'train_losses': train_loss_list,
            'val_losses': val_loss_list,
            'best_epoch': best_epoch,
            'best_val_loss': best_val_loss
        }
    
    def _evaluate_model(self, model: nn.Module, X: Dict, y: Dict, seed: int) -> Dict[str, Any]:
        """√âvalue le mod√®le Random sur validation et test."""
        print("\n √âvaluation finale du mod√®le Random...")
        val_performance = evaluate(model, 'val', X, y, seed)
        test_performance = evaluate(model, 'test', X, y, seed)
        
        return {
            'val': val_performance,
            'test': test_performance
        }
    
    def _analyze_random_importance(self, model: InterpretableFTTRandom, X: Dict,
                                 selected_features: List[str]) -> Dict[str, float]:
        """Analyse l'importance des features dans le mod√®le Random."""
        print("\nüîç Analyse d'importance des features dans le mod√®le Random...")
        random_importance = model.get_cls_importance(
            X['test'][0], X['test'][1], selected_features
        )
        
        print("\n Importance des features dans le mod√®le Random:")
        sorted_random_importance = sorted(random_importance.items(), key=lambda x: x[1], reverse=True)
        for i, (feature, score) in enumerate(sorted_random_importance, 1):
            feature_type = "NUM" if feature in self.feature_mapping.num_feature_names else "CAT"
            print(f"  {i:2d}. {feature:<20} ({feature_type}): {score:.4f}")
        
        return random_importance
    
    def _analyze_random_interpretability(self, model: InterpretableFTTRandom, X: Dict, y: Dict,
                                       seed: int, selected_features: List[str],
                                       cat_cardinalities: List[int], training_results: Dict,
                                       performance_results: Dict):
        """Analyse d'interpr√©tabilit√© compl√®te pour le mod√®le Random."""
        print("\nüîç Analyse d'interpr√©tabilit√© compl√®te du mod√®le Random...")
        
        model_config = {
            'selected_features': selected_features,
            'k': self.k,
            'attention_seed': self.attention_seed,
            'selected_indices_num': self.selected_indices_num,
            'selected_indices_cat': self.selected_indices_cat,
            'cat_cardinalities_selected': self.cat_cardinalities_selected,
            **self.random_model_config
        }
        
        from interpretability_analyzer import analyze_interpretability
        
        # Utiliser interpretability_analyzer pour l'analyse compl√®te du mod√®le Random
        analyze_interpretability(
            model=model,
            X=X,
            y=y,
            model_name='interpretable_ftt_plus_plus',
            seed=seed,
            model_config=model_config,
            training_results=training_results,
            performance_results=performance_results,
            feature_names=selected_features,  # Seulement les features s√©lectionn√©es
            local_output_dir=None,
            results_base_dir='results/results_telecom'
        )