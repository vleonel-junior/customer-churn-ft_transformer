# FT-Transformer pour la PrÃ©diction de Churn Client

Ce projet implÃ©mente plusieurs variantes de Feature Tokenizer Transformer (FT-Transformer) pour la prÃ©diction de churn client, avec un focus sur l'interprÃ©tabilitÃ© et l'optimisation des performances.

## ğŸ—ï¸ Architecture des ModÃ¨les

### **FTT (Standard)**
- **Description** : ImplÃ©mentation de base du FT-Transformer
- **CaractÃ©ristiques** : Architecture Transformer classique avec tokenisation des features
- **Usage** : ModÃ¨le de rÃ©fÃ©rence pour comparaisons

### **FTT+ (InterprÃ©table)**
- **Description** : Extension interprÃ©table du FT-Transformer avec mÃ©canismes d'attention analysables
- **CaractÃ©ristiques** :
  - Token CLS pour l'importance des features
  - Extraction des matrices d'attention
  - Heatmaps d'interactions complÃ¨tes
- **Usage** : Analyse d'interprÃ©tabilitÃ© et sÃ©lection de features

### **FTT++ (Sparse + OptimisÃ©)**
- **Description** : Pipeline en deux Ã©tapes combinant FTT+ et modÃ¨le Random avec attention sparse
- **CaractÃ©ristiques** :
  - **Ã‰tape 1** : EntraÃ®nement FTT+ â†’ SÃ©lection des M features les plus importantes
  - **Ã‰tape 2** : ModÃ¨le Random avec k interactions alÃ©atoires sur features sÃ©lectionnÃ©es
  - Attention sparse pour rÃ©duction de complexitÃ©
- **Usage** : ModÃ¨le optimisÃ© pour production avec interprÃ©tabilitÃ© maintenue

## ğŸ“Š Dataset

**Telecom Customer Churn** : Dataset de tÃ©lÃ©communications avec 19 features (3 numÃ©riques, 16 catÃ©gorielles) pour prÃ©dire le churn client.

**Features** :
- NumÃ©riques : `tenure`, `MonthlyCharges`, `TotalCharges`
- CatÃ©gorielles : `gender`, `SeniorCitizen`, `Partner`, `Contract`, `PaymentMethod`, etc.

## ğŸš€ Utilisation

### **EntraÃ®nement FTT**
```bash
python train/Telecom/train_ftt/train.py
```

### **EntraÃ®nement FTT+**
```bash
python train/Telecom/train_ftt_plus/train.py
```

### **EntraÃ®nement FTT++**
```bash
# Configuration de base
python train/Telecom/train_ftt_plus_plus/train.py

# Configuration personnalisÃ©e
python train/Telecom/train_ftt_plus_plus/train.py \
    --embedding_type "Q-LR" \
    --M 12 \
    --k 6 \
    --stage1_epochs 75 \
    --stage2_epochs 50 \
    --lr 0.0005 \
    --seed 42
```

### **Depuis Kaggle**
```python
import os
os.chdir('/kaggle/working/customer-churn-ft_transformer')

!PYTHONPATH=/kaggle/working/customer-churn-ft_transformer \
    python train/Telecom/train_ftt_plus_plus/train.py \
    --embedding_type "Q-LR" --M 15 --k 8
```

## âš™ï¸ ParamÃ¨tres

### **ParamÃ¨tres FTT++**
| ParamÃ¨tre | Description | DÃ©faut |
|-----------|-------------|---------|
| `--M` | Nombre de features Ã  sÃ©lectionner | 10 |
| `--k` | Nombre d'interactions alÃ©atoires | 5 |
| `--embedding_type` | Type d'embedding numÃ©rique | "LR" |
| `--stage1_epochs` | Ã‰poques pour FTT+ | 50 |
| `--stage2_epochs` | Ã‰poques pour Random | 50 |
| `--lr` | Taux d'apprentissage | 1e-3 |
| `--d_token` | Dimension des tokens | 64 |
| `--n_blocks` | Nombre de blocs Transformer | 2 |

### **Types d'Embedding**
- `"LR"` : Linear + ReLU (dÃ©faut)
- `"Q-LR"` : Quantile + Linear + ReLU
- `"T"`, `"T-L"`, `"T-LR"`, `"T-LR-LR"` : Embeddings supervisÃ©s

## ğŸ“ˆ RÃ©sultats et Visualisations

### **MÃ©triques GÃ©nÃ©rÃ©es**
- ROC-AUC, PR-AUC, Accuracy, F1-Score
- Matthews Correlation Coefficient (MCC)
- Sensitivity, Specificity, Cohen's Kappa

### **Visualisations Automatiques**
- **Graphiques d'importance** : Features les plus influentes
- **Heatmaps d'attention** : Interactions feature-to-feature complÃ¨tes
- **Comparaisons FTT+ vs Random** : Ã‰volution de l'importance des features

### **Fichiers SauvegardÃ©s**
```
results/results_telecom/
â”œâ”€â”€ mÃ©triques/
â”‚   â”œâ”€â”€ *_model_performance_metrics_seed_*.json
â”‚   â””â”€â”€ *_feature_importance_analysis_seed_*.json
â”œâ”€â”€ heatmaps/
â”‚   â”œâ”€â”€ *_feature_importance_chart_seed_*.png
â”‚   â””â”€â”€ *_attention_heatmap_seed_*.png
â””â”€â”€ best_models/
    â””â”€â”€ *_trained_model_weights_seed_*.pt
```

## ğŸ”§ Structure du Projet

```
.
â”œâ”€â”€ ftt_plus/                    # FTT+ InterprÃ©table
â”‚   â”œâ”€â”€ model.py                 # Architecture du modÃ¨le
â”‚   â”œâ”€â”€ attention.py             # MÃ©canismes d'attention
â”‚   â””â”€â”€ visualisation.py         # Visualisations FTT+
â”œâ”€â”€ ftt_plus_plus/               # FTT++ Pipeline
â”‚   â”œâ”€â”€ pipeline.py              # Orchestration complÃ¨te
â”‚   â”œâ”€â”€ training_stages.py       # Ã‰tapes d'entraÃ®nement
â”‚   â”œâ”€â”€ random_model.py          # ModÃ¨le Random avec attention sparse
â”‚   â”œâ”€â”€ config.py                # Configurations
â”‚   â””â”€â”€ visualisation.py         # Visualisations FTT++
â”œâ”€â”€ train/Telecom/               # Scripts d'entraÃ®nement
â”‚   â”œâ”€â”€ train_ftt/
â”‚   â”œâ”€â”€ train_ftt_plus/
â”‚   â””â”€â”€ train_ftt_plus_plus/
â”œâ”€â”€ data/                        # Traitement des donnÃ©es
â”œâ”€â”€ rtdl_lib/                    # BibliothÃ¨que RTDL
â””â”€â”€ interpretability_analyzer.py # Analyseur d'interprÃ©tabilitÃ© gÃ©nÃ©rique
```

## ğŸ¯ Pipeline FTT++ DÃ©taillÃ©

### **Ã‰tape 1 : EntraÃ®nement FTT+**
1. EntraÃ®nement complet du modÃ¨le FTT+ sur toutes les features
2. Analyse d'interprÃ©tabilitÃ© avec extraction des scores d'importance
3. SÃ©lection des M features les plus importantes
4. GÃ©nÃ©ration des visualisations (graphiques + heatmaps)

### **Ã‰tape 2 : ModÃ¨le Random**
1. CrÃ©ation du modÃ¨le Random sur les M features sÃ©lectionnÃ©es
2. GÃ©nÃ©ration de k interactions feature-feature alÃ©atoires
3. EntraÃ®nement avec attention sparse
4. Analyse comparative des performances et interprÃ©tabilitÃ©

### **Avantages FTT++**
- **RÃ©duction de complexitÃ©** : Attention sparse sur features sÃ©lectionnÃ©es
- **Maintien de l'interprÃ©tabilitÃ©** : Heatmaps et importance des features
- **Performances optimisÃ©es** : Pipeline en deux Ã©tapes
- **ReproductibilitÃ©** : Gestion des seeds et configurations

## ğŸ“‹ PrÃ©requis

```bash
pip install torch torchvision
pip install numpy pandas matplotlib seaborn
pip install scikit-learn
pip install zero  # Pour les data loaders
```

## ğŸ”¬ Analyse d'InterprÃ©tabilitÃ©

Le systÃ¨me d'analyse d'interprÃ©tabilitÃ© est automatiquement dÃ©clenchÃ© et gÃ©nÃ¨re :

1. **Scores d'importance CLS â†’ Features**
2. **Matrices d'attention complÃ¨tes**
3. **Heatmaps d'interactions**
4. **Comparaisons entre modÃ¨les**
5. **Statistiques de sparsitÃ©**

L'analyseur supporte tous les modÃ¨les FTT et adapte automatiquement les visualisations selon le type de modÃ¨le.

## ğŸ“ Citation

Ce projet implÃ©mente et Ã©tend les concepts du FT-Transformer pour l'interprÃ©tabilitÃ© et l'optimisation des performances sur des donnÃ©es tabulaires de churn client.