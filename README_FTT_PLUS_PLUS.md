# FTT++ (FT-Transformer Plus Plus) - ImplÃ©mentation ComplÃ¨te

## ğŸ¯ Vue d'Ensemble

FTT++ est une approche en deux Ã©tapes qui amÃ©liore l'interprÃ©tabilitÃ© de FTT+ tout en maintenant de hautes performances. Cette implÃ©mentation suit fidÃ¨lement la mÃ©thodologie proposÃ©e par Isomura et al. avec **entraÃ®nement intÃ©grÃ©**.

### ğŸ”¬ Principe Fondamental

FTT++ combine la **focalisation intelligente** de FTT+ avec une **exploration contrÃ´lÃ©e** des interactions feature-feature, crÃ©ant un modÃ¨le Ã  la fois performant et hautement interprÃ©table.

## ğŸ“‹ Architecture du Projet

```
ftt_plus_plus/
â”œâ”€â”€ __init__.py                 # Module principal FTT++
â”œâ”€â”€ sparse_attention.py         # MÃ©canisme d'attention sparse
â”œâ”€â”€ random_model.py            # Ã‰tape 2: ModÃ¨le Random avec attention sparse
â””â”€â”€ pipeline.py                # Orchestration complÃ¨te avec entraÃ®nement intÃ©grÃ©

train/Telecom/train_ftt_plus_plus/
â””â”€â”€ train.py                   # Script d'entraÃ®nement pour dataset Telecom
```

## ğŸš€ Workflow FTT++ en Deux Ã‰tapes IntÃ©grÃ©es

### **Ã‰tape 1 : EntraÃ®nement FTT+ et SÃ©lection de Features**

```python
# 1. EntraÃ®ner un modÃ¨le FTT+ complet avec early stopping
model_ftt_plus = InterpretableFTTPlus.make_baseline(...)
for epoch in range(n_epochs):
    train_loss = train(epoch, model_ftt_plus, optimizer, X, y, train_loader, loss_fn)
    val_loss = val(epoch, model_ftt_plus, X, y, val_loader, loss_fn)

# 2. Analyser l'importance avec interpretability_analyzer
interpretability_results = analyze_interpretability(
    model=model_ftt_plus, X=X, y=y, model_name='interpretable_ftt_plus',
    seed=seed, model_config=model_config, ...
)

# 3. SÃ©lectionner les M features les plus importantes
cls_importance = interpretability_results['cls_importance']
selected_features = [name for name, score in sorted(cls_importance.items(), 
                    key=lambda x: x[1], reverse=True)[:M]]
```

### **Ã‰tape 2 : EntraÃ®nement Random avec Attention Sparse**

```python
# 1. CrÃ©er un modÃ¨le Random focalisÃ© sur les M features sÃ©lectionnÃ©es
model_random = InterpretableFTTRandom.from_selected_features(
    selected_feature_indices_num=indices_num,
    selected_feature_indices_cat=indices_cat,
    k=5  # Nombre d'interactions feature-feature alÃ©atoires
)

# 2. EntraÃ®ner le modÃ¨le Random avec attention sparse
for epoch in range(n_epochs):
    train_loss = train(epoch, model_random, optimizer, X, y, train_loader, loss_fn)
    val_loss = val(epoch, model_random, X, y, val_loader, loss_fn)
```

## ğŸ§  Innovation Technique

### **Attention Sparse ContrÃ´lÃ©e**

L'attention dans le modÃ¨le Random suit un pattern sparse spÃ©cifique :

```python
# Masque d'attention sparse
mask = torch.zeros(seq_len, seq_len, dtype=torch.bool)

# 1. CLS â†” toutes les features sÃ©lectionnÃ©es
mask[0, 1:] = True  # CLS vers features
mask[1:, 0] = True  # Features vers CLS

# 2. k paires d'interactions feature-feature alÃ©atoires
for i, j in random_pairs:
    mask[i, j] = True
    mask[j, i] = True

# 3. Auto-attention interdite (diagonale reste False)
```

### **IntÃ©gration avec interpretability_analyzer.py**

- **Utilisation native** du module d'analyse existant
- **Sauvegarde automatique** dans `results/results_telecom/`
- **Graphiques d'importance** gÃ©nÃ©rÃ©s automatiquement
- **Pas de duplication** de code d'analyse

## ğŸ“Š Utilisation

### **EntraÃ®nement Complet IntÃ©grÃ©**

```bash
# EntraÃ®nement FTT++ avec 10 features sÃ©lectionnÃ©es et 5 interactions alÃ©atoires
cd train/Telecom/train_ftt_plus_plus
python train.py --M 10 --k 5 --seed 0

# Avec configuration personnalisÃ©e
python train.py \
    --M 15 \
    --k 8 \
    --stage1_epochs 100 \
    --stage2_epochs 50 \
    --d_token 128 \
    --ffn_hidden 256 \
    --embedding_type Q-LR
```

### **Pipeline Programmatique**

```python
from ftt_plus_plus.pipeline import FTTPlusPlusPipeline

# Configuration
pipeline = FTTPlusPlusPipeline(M=10, k=5, attention_seed=42)

# ExÃ©cution complÃ¨te avec entraÃ®nements intÃ©grÃ©s
results = pipeline.run_complete_pipeline(
    X=X, y=y, 
    cat_cardinalities=cat_cardinalities,
    feature_names=feature_names,
    stage1_epochs=50,
    stage2_epochs=50,
    embedding_type="LR",
    device=device
)

# Analyse des rÃ©sultats
print(f"Features sÃ©lectionnÃ©es: {results['selected_features']}")
print(f"SparsitÃ© atteinte: {results['comparison']['sparsity_achieved']:.2%}")
```

## ğŸ“ˆ Avantages de FTT++

### **1. Workflow Naturel et IntÃ©grÃ©**

- **EntraÃ®nement continu** : FTT+ â†’ Analyse â†’ SÃ©lection â†’ Random
- **Pas de modÃ¨les prÃ©-entraÃ®nÃ©s** Ã  charger
- **Utilisation native** d'`interpretability_analyzer.py`
- **Pipeline unifiÃ©** pour toute l'expÃ©rimentation

### **2. InterprÃ©tabilitÃ© Maximale**

- **Focalisation claire** : Identification explicite des M features les plus importantes
- **Interactions contrÃ´lÃ©es** : Exploration limitÃ©e des relations feature-feature
- **Attention sparse** : Visualisation directe des connexions importantes
- **Analyse comparative** : Ã‰volution de l'importance FTT+ â†’ Random

### **3. Performance Maintenue**

- **Transfert de connaissance** : Les features importantes sont identifiÃ©es par FTT+
- **Architecture optimisÃ©e** : Focus sur les interactions vraiment utiles
- **Robustesse** : RÃ©duction du sur-apprentissage grÃ¢ce Ã  la sparsitÃ©

### **4. EfficacitÃ© Computationnelle**

- **Moins de paramÃ¨tres** : Seules les M features importantes sont traitÃ©es
- **Calculs rÃ©duits** : Attention sparse vs attention complÃ¨te
- **ScalabilitÃ©** : Performance dÃ©gradÃ©e gracieusement avec la taille des donnÃ©es

## ğŸ” Exemple de RÃ©sultats

### **Workflow d'EntraÃ®nement**

```
ğŸš€ === PIPELINE FTT++ COMPLET ===

ğŸš€ === Ã‰TAPE 1: EntraÃ®nement FTT+ Complet ===
ğŸ“Š ModÃ¨le FTT+ crÃ©Ã© avec 186,457 paramÃ¨tres
â³ EntraÃ®nement du modÃ¨le FTT+ en cours...
Epoch 023 | Train Loss: 0.4234 | Val Loss: 0.4567 | Time: 1.23s
âœ… Meilleur modÃ¨le chargÃ© (Ã©poque 23, val_loss: 0.4567)

ğŸ” Analyse d'interprÃ©tabilitÃ© avec interpretability_analyzer...
ğŸ“‹ Features sÃ©lectionnÃ©es:
  1. Contract             : 0.1234
  2. tenure               : 0.0987
  3. MonthlyCharges       : 0.0876

ğŸ¯ === Ã‰TAPE 2: EntraÃ®nement ModÃ¨le Random ===
ğŸ“Š ModÃ¨le Random crÃ©Ã© avec 89,123 paramÃ¨tres
ğŸ”— SparsitÃ© d'attention: 75.21%
â³ EntraÃ®nement du modÃ¨le Random en cours...
âœ… Meilleur modÃ¨le Random chargÃ© (Ã©poque 18, val_loss: 0.4123)
```

### **Analyse Comparative**

```
ğŸ“Š === ANALYSE DÃ‰TAILLÃ‰E DES RÃ‰SULTATS ===
ğŸ” Comparaison des modÃ¨les:
   - ParamÃ¨tres FTT+: 186,457
   - ParamÃ¨tres Random: 89,123
   - RÃ©duction: 52.20%

ğŸ“ˆ CorrÃ©lation d'importance FTT+ â†” Random: 0.834

ğŸ“‹ Features sÃ©lectionnÃ©es (M=10) - Ã‰volution de l'importance:
Rang Feature              FTT+ Score   Random Score  Ã‰volution
1.   Contract             0.1234       0.1456        +18.0%
2.   tenure               0.0987       0.1123        +13.8%
3.   MonthlyCharges       0.0876       0.0934        +6.6%
```

### **Statistiques d'Attention Sparse**

```
ğŸ”— Statistiques d'attention sparse:
   - Connexions totales possibles: 121
   - Connexions actives: 30
   - SparsitÃ©: 75.21%
   - Connexions CLS â†” features: 20
   - Connexions feature â†” feature: 10
```

## ğŸ› ï¸ Configuration AvancÃ©e

### **ParamÃ¨tres ClÃ©s**

| ParamÃ¨tre | Description | Valeur RecommandÃ©e |
|-----------|-------------|-------------------|
| `M` | Nombre de features sÃ©lectionnÃ©es | 10-15 (50-75% du total) |
| `k` | Interactions feature-feature | 3-8 (â‰ˆM/2) |
| `attention_seed` | Seed pour reproductibilitÃ© | 42 |
| `d_token` | Dimension des tokens | 64-128 |
| `n_blocks` | Blocs Transformer | 2-4 |
| `embedding_type` | Type d'embedding numÃ©rique | LR, Q-LR, T-LR |

### **Types d'Embeddings SupportÃ©s**

- **Linear** : L, LR, LR-LR
- **Quantile** : Q, Q-L, Q-LR, Q-LR-LR
- **Tree-based** : T, T-L, T-LR, T-LR-LR
- **Periodic** : P, P-L, P-LR, P-LR-LR

## ğŸ“Š Analyse et Sauvegarde

### **Sauvegarde StructurÃ©e**

```
results/results_telecom/
â”œâ”€â”€ mÃ©triques/
â”‚   â”œâ”€â”€ interpretable_ftt_plus_model_performance_metrics_seed_0.json
â”‚   â”œâ”€â”€ interpretable_ftt_plus_feature_importance_analysis_seed_0.json
â”‚   â””â”€â”€ ftt_plus_plus_complete_results.json
â”œâ”€â”€ heatmaps/
â”‚   â””â”€â”€ interpretable_ftt_plus_feature_importance_chart_seed_0.png
â””â”€â”€ best_models/
    â””â”€â”€ interpretable_ftt_plus_trained_model_weights_seed_0.pt
```

### **RÃ©sultats Locaux**

```
outputs/ftt_plus_plus_seed_0_M_10_k_5/
â””â”€â”€ ftt_plus_plus_results.json
```

## ğŸ¯ Cas d'Usage RecommandÃ©s

### **1. InterprÃ©tabilitÃ© Critique**
- Applications mÃ©dicales
- Finance et crÃ©dit
- Analyse de risque

### **2. Optimisation de Performance**
- Datasets avec beaucoup de features
- Contraintes computationnelles
- DÃ©ploiement en production

### **3. Recherche et Analyse**
- DÃ©couverte de relations feature-feature
- Validation de l'importance des variables
- Comparaison de modÃ¨les

## ğŸ”§ Architecture SimplifiÃ©e

```python
# Architecture finale simplifiÃ©e
ftt_plus_plus/
â”œâ”€â”€ sparse_attention.py     # MÃ©canisme d'attention sparse
â”œâ”€â”€ random_model.py        # ModÃ¨le Random avec features sÃ©lectionnÃ©es
â””â”€â”€ pipeline.py            # Pipeline intÃ©grÃ© (entraÃ®ne FTT+ + analyse + Random)

# Plus besoin de:
# âŒ feature_selector.py    # RemplacÃ© par interpretability_analyzer.py
# âŒ ModÃ¨les prÃ©-entraÃ®nÃ©s  # EntraÃ®nement intÃ©grÃ© dans le pipeline
```

## ğŸš€ Prochaines Ã‰tapes

1. **EntraÃ®nement sur vos donnÃ©es** : Utiliser le pipeline intÃ©grÃ©
2. **Optimisation des hyperparamÃ¨tres** : Tuner M, k selon vos besoins
3. **Analyse comparative** : Comparer avec FTT+ standard et autres baselines
4. **DÃ©ploiement** : IntÃ©grer le modÃ¨le Random optimisÃ© en production

---

**FTT++** avec entraÃ®nement intÃ©grÃ© reprÃ©sente une approche naturelle et efficace pour l'Ã©quilibre performance-interprÃ©tabilitÃ© sur donnÃ©es tabulaires. Le pipeline unifiÃ© simplifie l'expÃ©rimentation tout en maximisant la rÃ©utilisation du code existant.