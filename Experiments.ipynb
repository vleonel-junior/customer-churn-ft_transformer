{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1bd4489",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-07T11:22:02.250305Z",
     "iopub.status.busy": "2025-07-07T11:22:02.250066Z",
     "iopub.status.idle": "2025-07-07T11:22:03.469644Z",
     "shell.execute_reply": "2025-07-07T11:22:03.468913Z"
    },
    "papermill": {
     "duration": 1.225821,
     "end_time": "2025-07-07T11:22:03.471047",
     "exception": false,
     "start_time": "2025-07-07T11:22:02.245226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'customer-churn-ft_transformer'...\r\n",
      "remote: Enumerating objects: 643, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (335/335), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (217/217), done.\u001b[K\r\n",
      "remote: Total 643 (delta 163), reused 251 (delta 84), pack-reused 308 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (643/643), 724.65 KiB | 15.10 MiB/s, done.\r\n",
      "Resolving deltas: 100% (307/307), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vleonel-junior/customer-churn-ft_transformer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f0afb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T11:22:03.479818Z",
     "iopub.status.busy": "2025-07-07T11:22:03.479545Z",
     "iopub.status.idle": "2025-07-07T11:22:03.483462Z",
     "shell.execute_reply": "2025-07-07T11:22:03.482754Z"
    },
    "papermill": {
     "duration": 0.009336,
     "end_time": "2025-07-07T11:22:03.484555",
     "exception": false,
     "start_time": "2025-07-07T11:22:03.475219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/working/customer-churn-ft_transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86664604",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T11:22:03.492155Z",
     "iopub.status.busy": "2025-07-07T11:22:03.491931Z",
     "iopub.status.idle": "2025-07-07T11:22:03.838484Z",
     "shell.execute_reply": "2025-07-07T11:22:03.837557Z"
    },
    "papermill": {
     "duration": 0.351968,
     "end_time": "2025-07-07T11:22:03.839974",
     "exception": false,
     "start_time": "2025-07-07T11:22:03.488006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/customer-churn-ft_transformer\r\n",
      "total 180\r\n",
      "drwxr-xr-x 9 root root  4096 Jul  7 11:22 .\r\n",
      "drwxr-xr-x 3 root root  4096 Jul  7 11:22 ..\r\n",
      "drwxr-xr-x 3 root root  4096 Jul  7 11:22 data\r\n",
      "-rw-r--r-- 1 root root 98979 Jul  7 11:22 Experiments.ipynb\r\n",
      "drwxr-xr-x 2 root root  4096 Jul  7 11:22 ftt_plus\r\n",
      "drwxr-xr-x 7 root root  4096 Jul  7 11:22 ftt_plus_plus\r\n",
      "drwxr-xr-x 8 root root  4096 Jul  7 11:22 .git\r\n",
      "-rw-r--r-- 1 root root  8324 Jul  7 11:22 interpretability_analyzer.py\r\n",
      "-rw-r--r-- 1 root root 10266 Jul  7 11:22 num_embedding_factory.py\r\n",
      "drwxr-xr-x 2 root root  4096 Jul  7 11:22 __pycache__\r\n",
      "-rw-r--r-- 1 root root  6726 Jul  7 11:22 README.md\r\n",
      "drwxr-xr-x 5 root root  4096 Jul  7 11:22 rtdl_lib\r\n",
      "-rw-r--r-- 1 root root  6821 Jul  7 11:22 test_embeddings.py\r\n",
      "drwxr-xr-x 3 root root  4096 Jul  7 11:22 train\r\n",
      "-rw-r--r-- 1 root root  2213 Jul  7 11:22 utils.py\r\n",
      "total 968\r\n",
      "drwxr-xr-x 3 root root   4096 Jul  7 11:22 .\r\n",
      "drwxr-xr-x 9 root root   4096 Jul  7 11:22 ..\r\n",
      "-rw-r--r-- 1 root root   4224 Jul  7 11:22 process_telecom_data.py\r\n",
      "drwxr-xr-x 2 root root   4096 Jul  7 11:22 __pycache__\r\n",
      "-rw-r--r-- 1 root root 970457 Jul  7 11:22 Telco_Customer_Churn.csv\r\n",
      "-rw-r--r-- 1 root root      0 Jul  7 11:22 utils.py\r\n"
     ]
    }
   ],
   "source": [
    "# Le bon chemin est directement :\n",
    "import os\n",
    "os.chdir('/kaggle/working/customer-churn-ft_transformer')\n",
    "\n",
    "# Vérifier que vous êtes au bon endroit\n",
    "!pwd\n",
    "!ls -la\n",
    "\n",
    "# Vérifier que les datasets sont là\n",
    "!ls -la data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a85bb5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T11:22:03.848846Z",
     "iopub.status.busy": "2025-07-07T11:22:03.848550Z",
     "iopub.status.idle": "2025-07-07T11:23:23.060438Z",
     "shell.execute_reply": "2025-07-07T11:23:23.059423Z"
    },
    "papermill": {
     "duration": 79.218062,
     "end_time": "2025-07-07T11:23:23.062097",
     "exception": false,
     "start_time": "2025-07-07T11:22:03.844035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation de rtdl_num_embeddings réussie\r\n",
      "Installation de scikit-learn réussie\r\n"
     ]
    }
   ],
   "source": [
    "# Installation silencieuse des packages pour rtdl_num_embeddings\n",
    "!pip install rtdl_num_embeddings -qqq > /dev/null 2>&1 && echo 'Installation de rtdl_num_embeddings réussie'\n",
    "!pip install \"scikit-learn>=1.0,<2\" -qqq > /dev/null 2>&1 && echo 'Installation de scikit-learn réussie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68874b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T11:23:23.071620Z",
     "iopub.status.busy": "2025-07-07T11:23:23.070843Z",
     "iopub.status.idle": "2025-07-07T11:24:58.980685Z",
     "shell.execute_reply": "2025-07-07T11:24:58.979943Z"
    },
    "papermill": {
     "duration": 95.916107,
     "end_time": "2025-07-07T11:24:58.982273",
     "exception": false,
     "start_time": "2025-07-07T11:23:23.066166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation de libzero réussie\r\n",
      "Installation de optuna réussie\r\n"
     ]
    }
   ],
   "source": [
    "!pip install libzero==0.0.4 -qqq > /dev/null 2>&1 && echo 'Installation de libzero réussie'\n",
    "!pip install optuna -qqq > /dev/null 2>&1 && echo 'Installation de optuna réussie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc367cdd",
   "metadata": {
    "papermill": {
     "duration": 0.003598,
     "end_time": "2025-07-07T11:24:58.990021",
     "exception": false,
     "start_time": "2025-07-07T11:24:58.986423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d4dce58",
   "metadata": {
    "papermill": {
     "duration": 0.003513,
     "end_time": "2025-07-07T11:24:58.997241",
     "exception": false,
     "start_time": "2025-07-07T11:24:58.993728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modèle FT-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b11de43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T11:24:59.005830Z",
     "iopub.status.busy": "2025-07-07T11:24:59.005558Z",
     "iopub.status.idle": "2025-07-07T11:25:46.465377Z",
     "shell.execute_reply": "2025-07-07T11:25:46.464367Z"
    },
    "papermill": {
     "duration": 47.466003,
     "end_time": "2025-07-07T11:25:46.466855",
     "exception": false,
     "start_time": "2025-07-07T11:24:59.000852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation du device: cuda\r\n",
      "Seed: 0\r\n",
      "Données originales: 7043 lignes\r\n",
      "Après nettoyage: 7032 lignes (11 supprimées)\r\n",
      "\r\n",
      "Informations sur les features:\r\n",
      "Features numériques (3): ['tenure', 'MonthlyCharges', 'TotalCharges']\r\n",
      "Variables catégorielles (16): ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\r\n",
      "Cardinalités des variables catégorielles: [2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4]\r\n",
      "Distribution des classes: [5163 1869]\r\n",
      "Tailles des ensembles:\r\n",
      "Train: 4781 | Val: 844 | Test: 1407\r\n",
      "Type d'embedding numérique: P-LR-LR\r\n",
      "Nombre de paramètres: 996,049\r\n",
      "\r\n",
      "=== Début de l'entraînement ===\r\n",
      "Epoch 000 | Training loss: 0.4906\r\n",
      "Epoch 000 | Validation loss: 0.4506\r\n",
      "Epoch 000 completed in 1.32s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4506)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8282, AUC-PR: 0.5951, Accuracy: 0.7825, B_ACC : 0.6472, MCC: 0.3724, Sensitivity/Recall: 0.3583, Specificity: 0.9361, Precision: 0.67, F1-score: 0.4669, CK-score 0.3457\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8282 | PR-AUC: 0.5951 | Accuracy: 0.7825\r\n",
      "  F1: 0.4669 | MCC: 0.3724 | Balanced Acc: 0.6472\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 001 | Training loss: 0.4464\r\n",
      "Epoch 001 | Validation loss: 0.4470\r\n",
      "Epoch 001 completed in 0.98s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4470)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8366, AUC-PR: 0.6189, Accuracy: 0.7818, B_ACC : 0.6356, MCC: 0.3631, Sensitivity/Recall: 0.3235, Specificity: 0.9477, Precision: 0.6914, F1-score: 0.4408, CK-score 0.3267\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8366 | PR-AUC: 0.6189 | Accuracy: 0.7818\r\n",
      "  F1: 0.4408 | MCC: 0.3631 | Balanced Acc: 0.6356\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 002 | Training loss: 0.4361\r\n",
      "Epoch 002 | Validation loss: 0.4348\r\n",
      "Epoch 002 completed in 0.97s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4348)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8412, AUC-PR: 0.6396, Accuracy: 0.7903, B_ACC : 0.6483, MCC: 0.3931, Sensitivity/Recall: 0.3449, Specificity: 0.9516, Precision: 0.7207, F1-score: 0.4665, CK-score 0.3557\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8412 | PR-AUC: 0.6396 | Accuracy: 0.7903\r\n",
      "  F1: 0.4665 | MCC: 0.3931 | Balanced Acc: 0.6483\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 003 | Training loss: 0.4319\r\n",
      "Epoch 003 | Validation loss: 0.4204\r\n",
      "Epoch 003 completed in 0.97s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4204)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8445, AUC-PR: 0.6474, Accuracy: 0.7932, B_ACC : 0.6579, MCC: 0.4054, Sensitivity/Recall: 0.369, Specificity: 0.9468, Precision: 0.715, F1-score: 0.4868, CK-score 0.3734\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8445 | PR-AUC: 0.6474 | Accuracy: 0.7932\r\n",
      "  F1: 0.4868 | MCC: 0.4054 | Balanced Acc: 0.6579\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 004 | Training loss: 0.4270\r\n",
      "Epoch 004 | Validation loss: 0.4255\r\n",
      "Epoch 004 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 005 | Training loss: 0.4267\r\n",
      "Epoch 005 | Validation loss: 0.4206\r\n",
      "Epoch 005 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 006 | Training loss: 0.4237\r\n",
      "Epoch 006 | Validation loss: 0.4216\r\n",
      "Epoch 006 completed in 0.95s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 007 | Training loss: 0.4229\r\n",
      "Epoch 007 | Validation loss: 0.4254\r\n",
      "Epoch 007 completed in 0.94s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 008 | Training loss: 0.4213\r\n",
      "Epoch 008 | Validation loss: 0.4244\r\n",
      "Epoch 008 completed in 0.99s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 009 | Training loss: 0.4197\r\n",
      "Epoch 009 | Validation loss: 0.4235\r\n",
      "Epoch 009 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 010 | Training loss: 0.4198\r\n",
      "Epoch 010 | Validation loss: 0.4229\r\n",
      "Epoch 010 completed in 1.00s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 011 | Training loss: 0.4187\r\n",
      "Epoch 011 | Validation loss: 0.4219\r\n",
      "Epoch 011 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 012 | Training loss: 0.4167\r\n",
      "Epoch 012 | Validation loss: 0.4228\r\n",
      "Epoch 012 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 013 | Training loss: 0.4156\r\n",
      "Epoch 013 | Validation loss: 0.4250\r\n",
      "Epoch 013 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 014 | Training loss: 0.4159\r\n",
      "Epoch 014 | Validation loss: 0.4249\r\n",
      "Epoch 014 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 015 | Training loss: 0.4170\r\n",
      "Epoch 015 | Validation loss: 0.4267\r\n",
      "Epoch 015 completed in 1.06s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 016 | Training loss: 0.4137\r\n",
      "Epoch 016 | Validation loss: 0.4227\r\n",
      "Epoch 016 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 017 | Training loss: 0.4136\r\n",
      "Epoch 017 | Validation loss: 0.4246\r\n",
      "Epoch 017 completed in 1.00s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 018 | Training loss: 0.4136\r\n",
      "Epoch 018 | Validation loss: 0.4204\r\n",
      "Epoch 018 completed in 0.98s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4204)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8384, AUC-PR: 0.6466, Accuracy: 0.7967, B_ACC : 0.6867, MCC: 0.4316, Sensitivity/Recall: 0.4519, Specificity: 0.9216, Precision: 0.676, F1-score: 0.5417, CK-score 0.4176\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8384 | PR-AUC: 0.6466 | Accuracy: 0.7967\r\n",
      "  F1: 0.5417 | MCC: 0.4316 | Balanced Acc: 0.6867\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 019 | Training loss: 0.4104\r\n",
      "Epoch 019 | Validation loss: 0.4261\r\n",
      "Epoch 019 completed in 0.95s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 020 | Training loss: 0.4104\r\n",
      "Epoch 020 | Validation loss: 0.4155\r\n",
      "Epoch 020 completed in 0.96s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4155)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8408, AUC-PR: 0.6566, Accuracy: 0.7982, B_ACC : 0.6817, MCC: 0.4312, Sensitivity/Recall: 0.4332, Specificity: 0.9303, Precision: 0.6923, F1-score: 0.5329, CK-score 0.4127\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8408 | PR-AUC: 0.6566 | Accuracy: 0.7982\r\n",
      "  F1: 0.5329 | MCC: 0.4312 | Balanced Acc: 0.6817\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 021 | Training loss: 0.4094\r\n",
      "Epoch 021 | Validation loss: 0.4217\r\n",
      "Epoch 021 completed in 1.06s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 022 | Training loss: 0.4075\r\n",
      "Epoch 022 | Validation loss: 0.4226\r\n",
      "Epoch 022 completed in 1.00s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 023 | Training loss: 0.4064\r\n",
      "Epoch 023 | Validation loss: 0.4220\r\n",
      "Epoch 023 completed in 0.94s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 024 | Training loss: 0.4043\r\n",
      "Epoch 024 | Validation loss: 0.4336\r\n",
      "Epoch 024 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 025 | Training loss: 0.4065\r\n",
      "Epoch 025 | Validation loss: 0.4262\r\n",
      "Epoch 025 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 026 | Training loss: 0.4026\r\n",
      "Epoch 026 | Validation loss: 0.4320\r\n",
      "Epoch 026 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 027 | Training loss: 0.4032\r\n",
      "Epoch 027 | Validation loss: 0.4315\r\n",
      "Epoch 027 completed in 0.99s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 028 | Training loss: 0.4005\r\n",
      "Epoch 028 | Validation loss: 0.4310\r\n",
      "Epoch 028 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 029 | Training loss: 0.3987\r\n",
      "Epoch 029 | Validation loss: 0.4275\r\n",
      "Epoch 029 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 030 | Training loss: 0.3965\r\n",
      "Epoch 030 | Validation loss: 0.4384\r\n",
      "Epoch 030 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 031 | Training loss: 0.3960\r\n",
      "Epoch 031 | Validation loss: 0.4383\r\n",
      "Epoch 031 completed in 1.02s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 032 | Training loss: 0.3912\r\n",
      "Epoch 032 | Validation loss: 0.4368\r\n",
      "Epoch 032 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 033 | Training loss: 0.3902\r\n",
      "Epoch 033 | Validation loss: 0.4498\r\n",
      "Epoch 033 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 034 | Training loss: 0.3894\r\n",
      "Epoch 034 | Validation loss: 0.4403\r\n",
      "Epoch 034 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 035 | Training loss: 0.3927\r\n",
      "Epoch 035 | Validation loss: 0.4392\r\n",
      "Epoch 035 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 036 | Training loss: 0.3880\r\n",
      "Epoch 036 | Validation loss: 0.4416\r\n",
      "Epoch 036 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 037 | Training loss: 0.3893\r\n",
      "Epoch 037 | Validation loss: 0.4399\r\n",
      "Epoch 037 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 038 | Training loss: 0.3820\r\n",
      "Epoch 038 | Validation loss: 0.4365\r\n",
      "Epoch 038 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 039 | Training loss: 0.3808\r\n",
      "Epoch 039 | Validation loss: 0.4436\r\n",
      "Epoch 039 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 040 | Training loss: 0.3800\r\n",
      "Epoch 040 | Validation loss: 0.4471\r\n",
      "Epoch 040 completed in 0.95s\r\n",
      "\r\n",
      "Early stopping à l'époque 40 (patience: 20)\r\n",
      "\r\n",
      "Meilleur modèle chargé (époque 20, val_loss: 0.4155)\r\n",
      "\r\n",
      "=== Évaluation finale ===\r\n",
      "Performance sur l'ensemble de validation:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8257, AUC-PR: 0.642, Accuracy: 0.7867, B_ACC : 0.708, MCC: 0.4335, Sensitivity/Recall: 0.5402, Specificity: 0.8758, Precision: 0.6111, F1-score: 0.5735, CK-score 0.432\r\n",
      "Val Performance:\r\n",
      "  ROC-AUC: 0.8257 | PR-AUC: 0.6420 | Accuracy: 0.7867\r\n",
      "  F1: 0.5735 | MCC: 0.4335 | Balanced Acc: 0.7080\r\n",
      "\r\n",
      "Performance sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8164, AUC-PR: 0.6121, Accuracy: 0.779, B_ACC : 0.6849, MCC: 0.3993, Sensitivity/Recall: 0.484, Specificity: 0.8858, Precision: 0.6054, F1-score: 0.5379, CK-score 0.395\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8164 | PR-AUC: 0.6121 | Accuracy: 0.7790\r\n",
      "  F1: 0.5379 | MCC: 0.3993 | Balanced Acc: 0.6849\r\n",
      "\r\n",
      "Résultats sauvegardés dans results/results_telecom/ftt/seed_0/\r\n",
      "Entraînement terminé!\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Changer vers le répertoire racine\n",
    "os.chdir('/kaggle/working/customer-churn-ft_transformer')\n",
    "\n",
    "# Utiliser PYTHONPATH pour que train.py trouve les modules\n",
    "!PYTHONPATH=/kaggle/working/customer-churn-ft_transformer python train/Telecom/train_ftt/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2732d",
   "metadata": {
    "papermill": {
     "duration": 0.006702,
     "end_time": "2025-07-07T11:25:46.481108",
     "exception": false,
     "start_time": "2025-07-07T11:25:46.474406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b72c7",
   "metadata": {
    "papermill": {
     "duration": 0.006602,
     "end_time": "2025-07-07T11:25:46.494414",
     "exception": false,
     "start_time": "2025-07-07T11:25:46.487812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aabe27",
   "metadata": {
    "papermill": {
     "duration": 0.006469,
     "end_time": "2025-07-07T11:25:46.507409",
     "exception": false,
     "start_time": "2025-07-07T11:25:46.500940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfeceffb",
   "metadata": {
    "papermill": {
     "duration": 0.006561,
     "end_time": "2025-07-07T11:25:46.520656",
     "exception": false,
     "start_time": "2025-07-07T11:25:46.514095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modèle FT-T Plus *Interprétable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de942b95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T11:25:46.536216Z",
     "iopub.status.busy": "2025-07-07T11:25:46.535982Z",
     "iopub.status.idle": "2025-07-07T11:27:06.375902Z",
     "shell.execute_reply": "2025-07-07T11:27:06.375121Z"
    },
    "papermill": {
     "duration": 79.848988,
     "end_time": "2025-07-07T11:27:06.377339",
     "exception": false,
     "start_time": "2025-07-07T11:25:46.528351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation du device: cuda\r\n",
      "Seed: 0\r\n",
      "Données originales: 7043 lignes\r\n",
      "Après nettoyage: 7032 lignes (11 supprimées)\r\n",
      "\r\n",
      "Informations sur les features:\r\n",
      "Features numériques (3): ['tenure', 'MonthlyCharges', 'TotalCharges']\r\n",
      "Variables catégorielles (16): ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\r\n",
      "Cardinalités des variables catégorielles: [2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4]\r\n",
      "Distribution des classes: [5163 1869]\r\n",
      "Tailles des ensembles:\r\n",
      "Train: 4781 | Val: 844 | Test: 1407\r\n",
      "Configuration du modèle:\r\n",
      "  - Features numériques: 3\r\n",
      "  - Features catégorielles: 16 (cardinalités: [2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4])\r\n",
      "  - Taille des tokens: 64\r\n",
      "Type d'embedding numérique: P-LR-LR\r\n",
      "Nombre de paramètres: 102,289\r\n",
      "\r\n",
      "=== Début de l'entraînement ===\r\n",
      "Epoch 000 | Training loss: 0.4798\r\n",
      "Epoch 000 | Validation loss: 0.4547\r\n",
      "Epoch 000 completed in 2.10s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4547)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8306, AUC-PR: 0.6355, Accuracy: 0.7768, B_ACC : 0.5956, MCC: 0.3349, Sensitivity/Recall: 0.2086, Specificity: 0.9826, Precision: 0.8125, F1-score: 0.332, CK-score 0.2505\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8306 | PR-AUC: 0.6355 | Accuracy: 0.7768\r\n",
      "  F1: 0.3320 | MCC: 0.3349 | Balanced Acc: 0.5956\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 001 | Training loss: 0.4483\r\n",
      "Epoch 001 | Validation loss: 0.4285\r\n",
      "Epoch 001 completed in 1.79s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4285)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8446, AUC-PR: 0.6631, Accuracy: 0.8024, B_ACC : 0.6829, MCC: 0.4417, Sensitivity/Recall: 0.4278, Specificity: 0.938, Precision: 0.7143, F1-score: 0.5351, CK-score 0.4195\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8446 | PR-AUC: 0.6631 | Accuracy: 0.8024\r\n",
      "  F1: 0.5351 | MCC: 0.4417 | Balanced Acc: 0.6829\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 002 | Training loss: 0.4512\r\n",
      "Epoch 002 | Validation loss: 0.4484\r\n",
      "Epoch 002 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 003 | Training loss: 0.4421\r\n",
      "Epoch 003 | Validation loss: 0.4325\r\n",
      "Epoch 003 completed in 1.87s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 004 | Training loss: 0.4456\r\n",
      "Epoch 004 | Validation loss: 0.4252\r\n",
      "Epoch 004 completed in 1.95s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4252)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8516, AUC-PR: 0.6633, Accuracy: 0.796, B_ACC : 0.6547, MCC: 0.4121, Sensitivity/Recall: 0.3529, Specificity: 0.9564, Precision: 0.7458, F1-score: 0.4791, CK-score 0.3719\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8516 | PR-AUC: 0.6633 | Accuracy: 0.7960\r\n",
      "  F1: 0.4791 | MCC: 0.4121 | Balanced Acc: 0.6547\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 005 | Training loss: 0.4425\r\n",
      "Epoch 005 | Validation loss: 0.4268\r\n",
      "Epoch 005 completed in 1.86s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 006 | Training loss: 0.4408\r\n",
      "Epoch 006 | Validation loss: 0.4469\r\n",
      "Epoch 006 completed in 1.79s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 007 | Training loss: 0.4371\r\n",
      "Epoch 007 | Validation loss: 0.4237\r\n",
      "Epoch 007 completed in 1.78s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4237)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8485, AUC-PR: 0.657, Accuracy: 0.7932, B_ACC : 0.6528, MCC: 0.4031, Sensitivity/Recall: 0.3529, Specificity: 0.9526, Precision: 0.7293, F1-score: 0.4756, CK-score 0.3657\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8485 | PR-AUC: 0.6570 | Accuracy: 0.7932\r\n",
      "  F1: 0.4756 | MCC: 0.4031 | Balanced Acc: 0.6528\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 008 | Training loss: 0.4423\r\n",
      "Epoch 008 | Validation loss: 0.4189\r\n",
      "Epoch 008 completed in 1.86s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4189)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8444, AUC-PR: 0.6507, Accuracy: 0.8017, B_ACC : 0.7208, MCC: 0.468, Sensitivity/Recall: 0.5481, Specificity: 0.8935, Precision: 0.6508, F1-score: 0.5951, CK-score 0.465\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8444 | PR-AUC: 0.6507 | Accuracy: 0.8017\r\n",
      "  F1: 0.5951 | MCC: 0.4680 | Balanced Acc: 0.7208\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 009 | Training loss: 0.4400\r\n",
      "Epoch 009 | Validation loss: 0.4286\r\n",
      "Epoch 009 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 010 | Training loss: 0.4397\r\n",
      "Epoch 010 | Validation loss: 0.4272\r\n",
      "Epoch 010 completed in 1.78s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 011 | Training loss: 0.4350\r\n",
      "Epoch 011 | Validation loss: 0.4248\r\n",
      "Epoch 011 completed in 1.80s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 012 | Training loss: 0.4338\r\n",
      "Epoch 012 | Validation loss: 0.4266\r\n",
      "Epoch 012 completed in 1.80s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 013 | Training loss: 0.4375\r\n",
      "Epoch 013 | Validation loss: 0.4262\r\n",
      "Epoch 013 completed in 1.79s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 014 | Training loss: 0.4379\r\n",
      "Epoch 014 | Validation loss: 0.4206\r\n",
      "Epoch 014 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 015 | Training loss: 0.4316\r\n",
      "Epoch 015 | Validation loss: 0.4227\r\n",
      "Epoch 015 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 016 | Training loss: 0.4346\r\n",
      "Epoch 016 | Validation loss: 0.4191\r\n",
      "Epoch 016 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 017 | Training loss: 0.4369\r\n",
      "Epoch 017 | Validation loss: 0.4143\r\n",
      "Epoch 017 completed in 1.80s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4143)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8496, AUC-PR: 0.6563, Accuracy: 0.8088, B_ACC : 0.706, MCC: 0.4697, Sensitivity/Recall: 0.4866, Specificity: 0.9255, Precision: 0.7027, F1-score: 0.575, CK-score 0.4569\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8496 | PR-AUC: 0.6563 | Accuracy: 0.8088\r\n",
      "  F1: 0.5750 | MCC: 0.4697 | Balanced Acc: 0.7060\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 018 | Training loss: 0.4308\r\n",
      "Epoch 018 | Validation loss: 0.4209\r\n",
      "Epoch 018 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 019 | Training loss: 0.4336\r\n",
      "Epoch 019 | Validation loss: 0.4134\r\n",
      "Epoch 019 completed in 1.87s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4134)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8557, AUC-PR: 0.6658, Accuracy: 0.8145, B_ACC : 0.7133, MCC: 0.4863, Sensitivity/Recall: 0.4973, Specificity: 0.9293, Precision: 0.7181, F1-score: 0.5876, CK-score 0.4731\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8557 | PR-AUC: 0.6658 | Accuracy: 0.8145\r\n",
      "  F1: 0.5876 | MCC: 0.4863 | Balanced Acc: 0.7133\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 020 | Training loss: 0.4294\r\n",
      "Epoch 020 | Validation loss: 0.4223\r\n",
      "Epoch 020 completed in 1.82s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 021 | Training loss: 0.4324\r\n",
      "Epoch 021 | Validation loss: 0.4274\r\n",
      "Epoch 021 completed in 1.89s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 022 | Training loss: 0.4315\r\n",
      "Epoch 022 | Validation loss: 0.4273\r\n",
      "Epoch 022 completed in 1.96s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 023 | Training loss: 0.4258\r\n",
      "Epoch 023 | Validation loss: 0.4189\r\n",
      "Epoch 023 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 024 | Training loss: 0.4259\r\n",
      "Epoch 024 | Validation loss: 0.4189\r\n",
      "Epoch 024 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 025 | Training loss: 0.4286\r\n",
      "Epoch 025 | Validation loss: 0.4232\r\n",
      "Epoch 025 completed in 1.83s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 026 | Training loss: 0.4313\r\n",
      "Epoch 026 | Validation loss: 0.4198\r\n",
      "Epoch 026 completed in 1.82s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 027 | Training loss: 0.4278\r\n",
      "Epoch 027 | Validation loss: 0.4254\r\n",
      "Epoch 027 completed in 1.79s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 028 | Training loss: 0.4263\r\n",
      "Epoch 028 | Validation loss: 0.4163\r\n",
      "Epoch 028 completed in 1.77s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 029 | Training loss: 0.4320\r\n",
      "Epoch 029 | Validation loss: 0.4198\r\n",
      "Epoch 029 completed in 1.79s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 030 | Training loss: 0.4309\r\n",
      "Epoch 030 | Validation loss: 0.4221\r\n",
      "Epoch 030 completed in 1.84s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 031 | Training loss: 0.4325\r\n",
      "Epoch 031 | Validation loss: 0.4194\r\n",
      "Epoch 031 completed in 1.83s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 032 | Training loss: 0.4253\r\n",
      "Epoch 032 | Validation loss: 0.4194\r\n",
      "Epoch 032 completed in 1.82s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 033 | Training loss: 0.4306\r\n",
      "Epoch 033 | Validation loss: 0.4224\r\n",
      "Epoch 033 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 034 | Training loss: 0.4268\r\n",
      "Epoch 034 | Validation loss: 0.4205\r\n",
      "Epoch 034 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 035 | Training loss: 0.4221\r\n",
      "Epoch 035 | Validation loss: 0.4267\r\n",
      "Epoch 035 completed in 1.78s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 036 | Training loss: 0.4232\r\n",
      "Epoch 036 | Validation loss: 0.4314\r\n",
      "Epoch 036 completed in 1.84s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 037 | Training loss: 0.4238\r\n",
      "Epoch 037 | Validation loss: 0.4268\r\n",
      "Epoch 037 completed in 1.79s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 038 | Training loss: 0.4230\r\n",
      "Epoch 038 | Validation loss: 0.4256\r\n",
      "Epoch 038 completed in 1.77s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 039 | Training loss: 0.4250\r\n",
      "Epoch 039 | Validation loss: 0.4168\r\n",
      "Epoch 039 completed in 1.95s\r\n",
      "\r\n",
      "Early stopping à l'époque 39 (patience: 20)\r\n",
      "\r\n",
      "Meilleur modèle chargé (époque 19, val_loss: 0.4134)\r\n",
      "\r\n",
      "=== Évaluation finale ===\r\n",
      "Performance sur l'ensemble de validation:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8468, AUC-PR: 0.6732, Accuracy: 0.8081, B_ACC : 0.7182, MCC: 0.4764, Sensitivity/Recall: 0.5268, Specificity: 0.9097, Precision: 0.6782, F1-score: 0.593, CK-score 0.47\r\n",
      "Val Performance:\r\n",
      "  ROC-AUC: 0.8468 | PR-AUC: 0.6732 | Accuracy: 0.8081\r\n",
      "  F1: 0.5930 | MCC: 0.4764 | Balanced Acc: 0.7182\r\n",
      "\r\n",
      "Performance sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8464, AUC-PR: 0.6623, Accuracy: 0.8131, B_ACC : 0.7286, MCC: 0.4937, Sensitivity/Recall: 0.5481, Specificity: 0.909, Precision: 0.6856, F1-score: 0.6092, CK-score 0.4884\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8464 | PR-AUC: 0.6623 | Accuracy: 0.8131\r\n",
      "  F1: 0.6092 | MCC: 0.4937 | Balanced Acc: 0.7286\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. tenure              : 0.0562\r\n",
      "   2. MonthlyCharges      : 0.0549\r\n",
      "   3. TotalCharges        : 0.0527\r\n",
      "   4. PhoneService        : 0.0526\r\n",
      "   5. InternetService     : 0.0526\r\n",
      "   6. PaymentMethod       : 0.0526\r\n",
      "   7. gender              : 0.0525\r\n",
      "   8. PaperlessBilling    : 0.0525\r\n",
      "   9. OnlineBackup        : 0.0524\r\n",
      "  10. StreamingTV         : 0.0524\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus/seed_0/heatmaps/interpretable_ftt_plus_importance_seed_0.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus/seed_0/interpretable_ftt_plus_metrics_seed_0.json\r\n",
      "Importance: results/results_telecom/ftt_plus/seed_0/interpretable_ftt_plus_importance_seed_0.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus/seed_0/interpretable_ftt_plus_{importance|attention}_seed_0.png\r\n",
      "Modèle: results/results_telecom/ftt_plus/seed_0/interpretable_ftt_plus_weights_seed_0.pt\r\n",
      "Entraînement terminé!\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Changer vers le répertoire racine\n",
    "os.chdir('/kaggle/working/customer-churn-ft_transformer')\n",
    "\n",
    "# Utiliser PYTHONPATH pour que train.py trouve les modules\n",
    "!PYTHONPATH=/kaggle/working/customer-churn-ft_transformer python train/Telecom/train_ftt_plus/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d659976",
   "metadata": {
    "papermill": {
     "duration": 0.010425,
     "end_time": "2025-07-07T11:27:06.399079",
     "exception": false,
     "start_time": "2025-07-07T11:27:06.388654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba43f0",
   "metadata": {
    "papermill": {
     "duration": 0.010036,
     "end_time": "2025-07-07T11:27:06.419185",
     "exception": false,
     "start_time": "2025-07-07T11:27:06.409149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9349460",
   "metadata": {
    "papermill": {
     "duration": 0.009936,
     "end_time": "2025-07-07T11:27:06.439190",
     "exception": false,
     "start_time": "2025-07-07T11:27:06.429254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3020ba79",
   "metadata": {
    "papermill": {
     "duration": 0.009954,
     "end_time": "2025-07-07T11:27:06.459044",
     "exception": false,
     "start_time": "2025-07-07T11:27:06.449090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modèle FT-T Plus Plus *Interprétable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65299ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T11:27:06.480372Z",
     "iopub.status.busy": "2025-07-07T11:27:06.480109Z",
     "iopub.status.idle": "2025-07-07T11:30:43.497303Z",
     "shell.execute_reply": "2025-07-07T11:30:43.496344Z"
    },
    "papermill": {
     "duration": 217.029532,
     "end_time": "2025-07-07T11:30:43.498730",
     "exception": false,
     "start_time": "2025-07-07T11:27:06.469198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENTRAÎNEMENT FTT++ MODULAIRE - DATASET TELECOM ===\r\n",
      "GPU détecté: Tesla P100-PCIE-16GB (17.1GB)\r\n",
      "Device sélectionné: cuda\r\n",
      "Chargement des données (seed: 0)\r\n",
      "Données originales: 7043 lignes\r\n",
      "Après nettoyage: 7032 lignes (11 supprimées)\r\n",
      "\r\n",
      "Informations sur les features:\r\n",
      "Features numériques (3): ['tenure', 'MonthlyCharges', 'TotalCharges']\r\n",
      "Variables catégorielles (16): ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\r\n",
      "Cardinalités des variables catégorielles: [2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4]\r\n",
      "Distribution des classes: [5163 1869]\r\n",
      "Tailles des ensembles:\r\n",
      "Train: 4781 | Val: 844 | Test: 1407\r\n",
      "Features numériques: 3\r\n",
      "Features catégorielles: 16\r\n",
      "Échantillons: train=4781, val=844, test=1407\r\n",
      "🚀 === PIPELINE FTT++ COMPLET ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "🚀 === ÉTAPE 1: Entraînement FTT+ Complet ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "✅ Validation mapping: 3 num + 16 cat = 19 total\r\n",
      "Type d'embedding numérique: LR\r\n",
      "Modèle FTT+ créé avec 88,001 paramètres\r\n",
      "⏳ Entraînement du modèle FTT+ en cours...\r\n",
      "Epoch 000 | Train Loss: 0.5032 | Val Loss: 0.4579 | Time: 2.05s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4579)\r\n",
      "Epoch 001 | Train Loss: 0.4551 | Val Loss: 0.4432 | Time: 1.75s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4432)\r\n",
      "Epoch 002 | Train Loss: 0.4452 | Val Loss: 0.4282 | Time: 1.76s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4282)\r\n",
      "Epoch 003 | Train Loss: 0.4418 | Val Loss: 0.4274 | Time: 1.76s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4274)\r\n",
      "Epoch 004 | Train Loss: 0.4353 | Val Loss: 0.4217 | Time: 1.73s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4217)\r\n",
      "Epoch 005 | Train Loss: 0.4378 | Val Loss: 0.4192 | Time: 1.77s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4192)\r\n",
      "Epoch 006 | Train Loss: 0.4371 | Val Loss: 0.4232 | Time: 1.72s\r\n",
      "Epoch 007 | Train Loss: 0.4366 | Val Loss: 0.4229 | Time: 1.76s\r\n",
      "Epoch 008 | Train Loss: 0.4343 | Val Loss: 0.4221 | Time: 1.82s\r\n",
      "Epoch 009 | Train Loss: 0.4326 | Val Loss: 0.4208 | Time: 1.73s\r\n",
      "Epoch 010 | Train Loss: 0.4320 | Val Loss: 0.4176 | Time: 1.73s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4176)\r\n",
      "Epoch 011 | Train Loss: 0.4305 | Val Loss: 0.4172 | Time: 1.73s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4172)\r\n",
      "Epoch 012 | Train Loss: 0.4330 | Val Loss: 0.4183 | Time: 1.75s\r\n",
      "Epoch 013 | Train Loss: 0.4338 | Val Loss: 0.4205 | Time: 1.78s\r\n",
      "Epoch 014 | Train Loss: 0.4308 | Val Loss: 0.4189 | Time: 1.76s\r\n",
      "Epoch 015 | Train Loss: 0.4306 | Val Loss: 0.4138 | Time: 1.74s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4138)\r\n",
      "Epoch 016 | Train Loss: 0.4342 | Val Loss: 0.4189 | Time: 1.73s\r\n",
      "Epoch 017 | Train Loss: 0.4278 | Val Loss: 0.4242 | Time: 1.72s\r\n",
      "Epoch 018 | Train Loss: 0.4307 | Val Loss: 0.4168 | Time: 1.71s\r\n",
      "Epoch 019 | Train Loss: 0.4258 | Val Loss: 0.4182 | Time: 1.69s\r\n",
      "Epoch 020 | Train Loss: 0.4290 | Val Loss: 0.4219 | Time: 1.74s\r\n",
      "Epoch 021 | Train Loss: 0.4286 | Val Loss: 0.4211 | Time: 1.74s\r\n",
      "Epoch 022 | Train Loss: 0.4223 | Val Loss: 0.4175 | Time: 1.72s\r\n",
      "Epoch 023 | Train Loss: 0.4283 | Val Loss: 0.4214 | Time: 1.72s\r\n",
      "Epoch 024 | Train Loss: 0.4281 | Val Loss: 0.4217 | Time: 1.73s\r\n",
      "Epoch 025 | Train Loss: 0.4271 | Val Loss: 0.4167 | Time: 1.76s\r\n",
      "Epoch 026 | Train Loss: 0.4260 | Val Loss: 0.4187 | Time: 1.74s\r\n",
      "Epoch 027 | Train Loss: 0.4252 | Val Loss: 0.4114 | Time: 1.73s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4114)\r\n",
      "Epoch 028 | Train Loss: 0.4242 | Val Loss: 0.4110 | Time: 1.75s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4110)\r\n",
      "Epoch 029 | Train Loss: 0.4315 | Val Loss: 0.4195 | Time: 1.75s\r\n",
      "Epoch 030 | Train Loss: 0.4214 | Val Loss: 0.4198 | Time: 1.74s\r\n",
      "Epoch 031 | Train Loss: 0.4236 | Val Loss: 0.4220 | Time: 1.90s\r\n",
      "Epoch 032 | Train Loss: 0.4229 | Val Loss: 0.4266 | Time: 1.73s\r\n",
      "Epoch 033 | Train Loss: 0.4274 | Val Loss: 0.4236 | Time: 1.73s\r\n",
      "Epoch 034 | Train Loss: 0.4265 | Val Loss: 0.4193 | Time: 1.73s\r\n",
      "Epoch 035 | Train Loss: 0.4262 | Val Loss: 0.4318 | Time: 1.74s\r\n",
      "Epoch 036 | Train Loss: 0.4263 | Val Loss: 0.4291 | Time: 1.80s\r\n",
      "Epoch 037 | Train Loss: 0.4165 | Val Loss: 0.4336 | Time: 1.77s\r\n",
      "Epoch 038 | Train Loss: 0.4247 | Val Loss: 0.4215 | Time: 1.76s\r\n",
      "Epoch 039 | Train Loss: 0.4224 | Val Loss: 0.4241 | Time: 1.76s\r\n",
      "Epoch 040 | Train Loss: 0.4210 | Val Loss: 0.4342 | Time: 1.75s\r\n",
      "Epoch 041 | Train Loss: 0.4216 | Val Loss: 0.4216 | Time: 1.74s\r\n",
      "Epoch 042 | Train Loss: 0.4252 | Val Loss: 0.4186 | Time: 1.73s\r\n",
      "Epoch 043 | Train Loss: 0.4168 | Val Loss: 0.4217 | Time: 1.78s\r\n",
      "Epoch 044 | Train Loss: 0.4242 | Val Loss: 0.4160 | Time: 1.75s\r\n",
      "Epoch 045 | Train Loss: 0.4187 | Val Loss: 0.4241 | Time: 1.74s\r\n",
      "Epoch 046 | Train Loss: 0.4210 | Val Loss: 0.4250 | Time: 1.75s\r\n",
      "Epoch 047 | Train Loss: 0.4201 | Val Loss: 0.4201 | Time: 1.75s\r\n",
      "Epoch 048 | Train Loss: 0.4192 | Val Loss: 0.4219 | Time: 1.77s\r\n",
      "\r\n",
      "Early stopping à l'époque 48 (patience: 20)\r\n",
      "✅ Meilleur modèle chargé (époque 28, val_loss: 0.4110)\r\n",
      "\r\n",
      "📊 Évaluation finale du modèle FTT+...\r\n",
      "\r\n",
      "🔍 Analyse d'interprétabilité avec interpretability_analyzer...\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. StreamingMovies     : 0.0532\r\n",
      "   2. PaymentMethod       : 0.0530\r\n",
      "   3. Partner             : 0.0530\r\n",
      "   4. MultipleLines       : 0.0529\r\n",
      "   5. Dependents          : 0.0528\r\n",
      "   6. TechSupport         : 0.0528\r\n",
      "   7. MonthlyCharges      : 0.0528\r\n",
      "   8. DeviceProtection    : 0.0528\r\n",
      "   9. StreamingTV         : 0.0526\r\n",
      "  10. InternetService     : 0.0526\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus_plus/seed_0/heatmaps/interpretable_ftt_plus_from_ftt_plus_plus_importance_seed_0.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_metrics_seed_0.json\r\n",
      "Importance: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_importance_seed_0.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_{importance|attention}_seed_0.png\r\n",
      "Modèle: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_weights_seed_0.pt\r\n",
      "\r\n",
      "🎯 Sélection des 10 features les plus importantes...\r\n",
      "📋 Features sélectionnées:\r\n",
      "   1. StreamingMovies      (CAT): 0.0532\r\n",
      "   2. PaymentMethod        (CAT): 0.0530\r\n",
      "   3. Partner              (CAT): 0.0530\r\n",
      "   4. MultipleLines        (CAT): 0.0529\r\n",
      "   5. Dependents           (CAT): 0.0528\r\n",
      "   6. TechSupport          (CAT): 0.0528\r\n",
      "   7. MonthlyCharges       (NUM): 0.0528\r\n",
      "   8. DeviceProtection     (CAT): 0.0528\r\n",
      "   9. StreamingTV          (CAT): 0.0526\r\n",
      "  10. InternetService      (CAT): 0.0526\r\n",
      "\r\n",
      "🎯 === ÉTAPE 2: Entraînement Modèle Random ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "📋 Mapping des features sélectionnées:\r\n",
      "   - Numériques sélectionnées: ['MonthlyCharges'] → indices [1]\r\n",
      "   - Catégorielles sélectionnées: ['StreamingMovies', 'PaymentMethod', 'Partner', 'MultipleLines', 'Dependents', 'TechSupport', 'DeviceProtection', 'StreamingTV', 'InternetService'] → indices [12, 15, 2, 5, 3, 10, 9, 11, 6]\r\n",
      "📊 Features sélectionnées: 1 numériques, 9 catégorielles\r\n",
      "🎲 Interactions aléatoires: 5 paires\r\n",
      "Modèle Random créé avec 86,209 paramètres\r\n",
      "🔗 Sparsité d'attention: 75.21%\r\n",
      "   - Connexions feature-feature: 10\r\n",
      "⏳ Entraînement du modèle Random en cours...\r\n",
      "Epoch 000 | Train Loss: 0.5208 | Val Loss: 0.4926 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4926)\r\n",
      "Epoch 001 | Train Loss: 0.4956 | Val Loss: 0.4803 | Time: 1.66s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4803)\r\n",
      "Epoch 002 | Train Loss: 0.4909 | Val Loss: 0.4779 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4779)\r\n",
      "Epoch 003 | Train Loss: 0.4893 | Val Loss: 0.4828 | Time: 1.64s\r\n",
      "Epoch 004 | Train Loss: 0.4846 | Val Loss: 0.4781 | Time: 1.64s\r\n",
      "Epoch 005 | Train Loss: 0.4860 | Val Loss: 0.4783 | Time: 1.65s\r\n",
      "Epoch 006 | Train Loss: 0.4854 | Val Loss: 0.4748 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4748)\r\n",
      "Epoch 007 | Train Loss: 0.4804 | Val Loss: 0.4786 | Time: 1.64s\r\n",
      "Epoch 008 | Train Loss: 0.4867 | Val Loss: 0.4764 | Time: 1.67s\r\n",
      "Epoch 009 | Train Loss: 0.4842 | Val Loss: 0.4754 | Time: 1.64s\r\n",
      "Epoch 010 | Train Loss: 0.4842 | Val Loss: 0.4718 | Time: 1.63s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4718)\r\n",
      "Epoch 011 | Train Loss: 0.4827 | Val Loss: 0.4768 | Time: 1.69s\r\n",
      "Epoch 012 | Train Loss: 0.4801 | Val Loss: 0.4722 | Time: 1.61s\r\n",
      "Epoch 013 | Train Loss: 0.4803 | Val Loss: 0.4744 | Time: 1.64s\r\n",
      "Epoch 014 | Train Loss: 0.4827 | Val Loss: 0.4706 | Time: 1.62s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4706)\r\n",
      "Epoch 015 | Train Loss: 0.4820 | Val Loss: 0.4738 | Time: 1.64s\r\n",
      "Epoch 016 | Train Loss: 0.4791 | Val Loss: 0.4733 | Time: 1.63s\r\n",
      "Epoch 017 | Train Loss: 0.4799 | Val Loss: 0.4757 | Time: 1.67s\r\n",
      "Epoch 018 | Train Loss: 0.4815 | Val Loss: 0.4736 | Time: 1.63s\r\n",
      "Epoch 019 | Train Loss: 0.4823 | Val Loss: 0.4724 | Time: 1.87s\r\n",
      "Epoch 020 | Train Loss: 0.4829 | Val Loss: 0.4734 | Time: 1.62s\r\n",
      "Epoch 021 | Train Loss: 0.4827 | Val Loss: 0.4674 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4674)\r\n",
      "Epoch 022 | Train Loss: 0.4786 | Val Loss: 0.4699 | Time: 1.62s\r\n",
      "Epoch 023 | Train Loss: 0.4787 | Val Loss: 0.4708 | Time: 1.67s\r\n",
      "Epoch 024 | Train Loss: 0.4774 | Val Loss: 0.4688 | Time: 1.64s\r\n",
      "Epoch 025 | Train Loss: 0.4799 | Val Loss: 0.4711 | Time: 1.65s\r\n",
      "Epoch 026 | Train Loss: 0.4763 | Val Loss: 0.4735 | Time: 1.64s\r\n",
      "Epoch 027 | Train Loss: 0.4748 | Val Loss: 0.4734 | Time: 1.67s\r\n",
      "Epoch 028 | Train Loss: 0.4747 | Val Loss: 0.4734 | Time: 1.65s\r\n",
      "Epoch 029 | Train Loss: 0.4810 | Val Loss: 0.4679 | Time: 1.68s\r\n",
      "Epoch 030 | Train Loss: 0.4739 | Val Loss: 0.4764 | Time: 1.63s\r\n",
      "Epoch 031 | Train Loss: 0.4788 | Val Loss: 0.4734 | Time: 1.65s\r\n",
      "Epoch 032 | Train Loss: 0.4786 | Val Loss: 0.4711 | Time: 1.63s\r\n",
      "Epoch 033 | Train Loss: 0.4778 | Val Loss: 0.4739 | Time: 1.63s\r\n",
      "Epoch 034 | Train Loss: 0.4785 | Val Loss: 0.4710 | Time: 1.63s\r\n",
      "Epoch 035 | Train Loss: 0.4746 | Val Loss: 0.4686 | Time: 1.64s\r\n",
      "Epoch 036 | Train Loss: 0.4775 | Val Loss: 0.4689 | Time: 1.59s\r\n",
      "Epoch 037 | Train Loss: 0.4787 | Val Loss: 0.4688 | Time: 1.64s\r\n",
      "Epoch 038 | Train Loss: 0.4780 | Val Loss: 0.4680 | Time: 1.85s\r\n",
      "Epoch 039 | Train Loss: 0.4764 | Val Loss: 0.4668 | Time: 1.61s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4668)\r\n",
      "Epoch 040 | Train Loss: 0.4777 | Val Loss: 0.4727 | Time: 1.62s\r\n",
      "Epoch 041 | Train Loss: 0.4738 | Val Loss: 0.4731 | Time: 1.69s\r\n",
      "Epoch 042 | Train Loss: 0.4726 | Val Loss: 0.4704 | Time: 1.63s\r\n",
      "Epoch 043 | Train Loss: 0.4755 | Val Loss: 0.4726 | Time: 1.64s\r\n",
      "Epoch 044 | Train Loss: 0.4767 | Val Loss: 0.4728 | Time: 1.62s\r\n",
      "Epoch 045 | Train Loss: 0.4769 | Val Loss: 0.4719 | Time: 1.62s\r\n",
      "Epoch 046 | Train Loss: 0.4753 | Val Loss: 0.4739 | Time: 1.63s\r\n",
      "Epoch 047 | Train Loss: 0.4738 | Val Loss: 0.4692 | Time: 1.66s\r\n",
      "Epoch 048 | Train Loss: 0.4752 | Val Loss: 0.4708 | Time: 1.61s\r\n",
      "Epoch 049 | Train Loss: 0.4730 | Val Loss: 0.4730 | Time: 1.63s\r\n",
      "Epoch 050 | Train Loss: 0.4739 | Val Loss: 0.4713 | Time: 1.61s\r\n",
      "Epoch 051 | Train Loss: 0.4751 | Val Loss: 0.4676 | Time: 1.61s\r\n",
      "Epoch 052 | Train Loss: 0.4724 | Val Loss: 0.4705 | Time: 1.60s\r\n",
      "Epoch 053 | Train Loss: 0.4766 | Val Loss: 0.4675 | Time: 1.64s\r\n",
      "Epoch 054 | Train Loss: 0.4760 | Val Loss: 0.4628 | Time: 1.62s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4628)\r\n",
      "Epoch 055 | Train Loss: 0.4740 | Val Loss: 0.4662 | Time: 1.60s\r\n",
      "Epoch 056 | Train Loss: 0.4775 | Val Loss: 0.4704 | Time: 1.59s\r\n",
      "Epoch 057 | Train Loss: 0.4740 | Val Loss: 0.4728 | Time: 1.69s\r\n",
      "Epoch 058 | Train Loss: 0.4746 | Val Loss: 0.4736 | Time: 1.65s\r\n",
      "Epoch 059 | Train Loss: 0.4753 | Val Loss: 0.4711 | Time: 1.64s\r\n",
      "Epoch 060 | Train Loss: 0.4751 | Val Loss: 0.4733 | Time: 1.60s\r\n",
      "Epoch 061 | Train Loss: 0.4718 | Val Loss: 0.4764 | Time: 1.63s\r\n",
      "Epoch 062 | Train Loss: 0.4766 | Val Loss: 0.4686 | Time: 1.58s\r\n",
      "Epoch 063 | Train Loss: 0.4743 | Val Loss: 0.4719 | Time: 1.59s\r\n",
      "Epoch 064 | Train Loss: 0.4741 | Val Loss: 0.4666 | Time: 1.62s\r\n",
      "Epoch 065 | Train Loss: 0.4697 | Val Loss: 0.4718 | Time: 1.60s\r\n",
      "Epoch 066 | Train Loss: 0.4736 | Val Loss: 0.4691 | Time: 1.64s\r\n",
      "Epoch 067 | Train Loss: 0.4741 | Val Loss: 0.4705 | Time: 1.59s\r\n",
      "Epoch 068 | Train Loss: 0.4695 | Val Loss: 0.4704 | Time: 1.62s\r\n",
      "Epoch 069 | Train Loss: 0.4706 | Val Loss: 0.4727 | Time: 1.64s\r\n",
      "Epoch 070 | Train Loss: 0.4697 | Val Loss: 0.4744 | Time: 1.62s\r\n",
      "Epoch 071 | Train Loss: 0.4732 | Val Loss: 0.4658 | Time: 1.62s\r\n",
      "Epoch 072 | Train Loss: 0.4712 | Val Loss: 0.4702 | Time: 1.66s\r\n",
      "Epoch 073 | Train Loss: 0.4744 | Val Loss: 0.4719 | Time: 1.64s\r\n",
      "Epoch 074 | Train Loss: 0.4732 | Val Loss: 0.4697 | Time: 1.65s\r\n",
      "\r\n",
      "Early stopping à l'époque 74 (patience: 20)\r\n",
      "✅ Meilleur modèle Random chargé (époque 54, val_loss: 0.4628)\r\n",
      "\r\n",
      "📊 Évaluation finale du modèle Random...\r\n",
      "\r\n",
      "🔍 Analyse d'importance des features dans le modèle Random...\r\n",
      "\r\n",
      "📊 Importance des features dans le modèle Random:\r\n",
      "   1. DeviceProtection     (CAT): 0.3663\r\n",
      "   2. MonthlyCharges       (NUM): 0.1910\r\n",
      "   3. TechSupport          (CAT): 0.1777\r\n",
      "   4. InternetService      (CAT): 0.0677\r\n",
      "   5. StreamingMovies      (CAT): 0.0398\r\n",
      "   6. Dependents           (CAT): 0.0395\r\n",
      "   7. MultipleLines        (CAT): 0.0329\r\n",
      "   8. Partner              (CAT): 0.0301\r\n",
      "   9. PaymentMethod        (CAT): 0.0276\r\n",
      "  10. StreamingTV          (CAT): 0.0273\r\n",
      "\r\n",
      "🔍 Analyse d'interprétabilité complète du modèle Random...\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. DeviceProtection    : 0.3663\r\n",
      "   2. MonthlyCharges      : 0.1910\r\n",
      "   3. TechSupport         : 0.1777\r\n",
      "   4. InternetService     : 0.0677\r\n",
      "   5. StreamingMovies     : 0.0398\r\n",
      "   6. Dependents          : 0.0395\r\n",
      "   7. MultipleLines       : 0.0329\r\n",
      "   8. Partner             : 0.0301\r\n",
      "   9. PaymentMethod       : 0.0276\r\n",
      "  10. StreamingTV         : 0.0273\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus_plus/seed_0/heatmaps/interpretable_ftt_plus_plus_importance_seed_0.png\r\n",
      "Heatmap d'attention sparse sauvegardée: results/results_telecom/ftt_plus_plus/seed_0/heatmaps/interpretable_ftt_plus_plus_attention_seed_0.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_metrics_seed_0.json\r\n",
      "Importance: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_importance_seed_0.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_{importance|attention}_seed_0.png\r\n",
      "Modèle: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_weights_seed_0.pt\r\n",
      "💾 Résultats complets sauvegardés: results/results_telecom/ftt_plus_plus/seed_0/métriques/ftt_plus_plus_results.json\r\n",
      "\r\n",
      "✅ === PIPELINE TERMINÉ EN 212.2s ===\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Changer vers le répertoire racine\n",
    "os.chdir('/kaggle/working/customer-churn-ft_transformer')\n",
    "\n",
    "# Embedding par défaut (LR)\n",
    "!PYTHONPATH=/kaggle/working/customer-churn-ft_transformer python train/Telecom/train_ftt_plus_plus/train.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c46bd5d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T11:30:43.531469Z",
     "iopub.status.busy": "2025-07-07T11:30:43.530929Z",
     "iopub.status.idle": "2025-07-07T11:32:57.281266Z",
     "shell.execute_reply": "2025-07-07T11:32:57.280461Z"
    },
    "papermill": {
     "duration": 133.767833,
     "end_time": "2025-07-07T11:32:57.282690",
     "exception": false,
     "start_time": "2025-07-07T11:30:43.514857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENTRAÎNEMENT FTT++ MODULAIRE - DATASET TELECOM ===\r\n",
      "GPU détecté: Tesla P100-PCIE-16GB (17.1GB)\r\n",
      "Device sélectionné: cuda\r\n",
      "Chargement des données (seed: 0)\r\n",
      "Données originales: 7043 lignes\r\n",
      "Après nettoyage: 7032 lignes (11 supprimées)\r\n",
      "\r\n",
      "Informations sur les features:\r\n",
      "Features numériques (3): ['tenure', 'MonthlyCharges', 'TotalCharges']\r\n",
      "Variables catégorielles (16): ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\r\n",
      "Cardinalités des variables catégorielles: [2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4]\r\n",
      "Distribution des classes: [5163 1869]\r\n",
      "Tailles des ensembles:\r\n",
      "Train: 4781 | Val: 844 | Test: 1407\r\n",
      "Features numériques: 3\r\n",
      "Features catégorielles: 16\r\n",
      "Échantillons: train=4781, val=844, test=1407\r\n",
      "🚀 === PIPELINE FTT++ COMPLET ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "🚀 === ÉTAPE 1: Entraînement FTT+ Complet ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "✅ Validation mapping: 3 num + 16 cat = 19 total\r\n",
      "Type d'embedding numérique: T-LR\r\n",
      "/usr/local/lib/python3.11/dist-packages/rtdl_num_embeddings.py:499: UserWarning: Computing tree-based bins involves the conversion of the input PyTorch tensors to NumPy arrays. The provided PyTorch tensors are not located on CPU, so the conversion has some overhead.\r\n",
      "  warnings.warn(\r\n",
      "Modèle FTT+ créé avec 90,689 paramètres\r\n",
      "⏳ Entraînement du modèle FTT+ en cours...\r\n",
      "Epoch 000 | Train Loss: 0.4629 | Val Loss: 0.4237 | Time: 2.08s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4237)\r\n",
      "Epoch 001 | Train Loss: 0.4333 | Val Loss: 0.4156 | Time: 1.74s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4156)\r\n",
      "Epoch 002 | Train Loss: 0.4315 | Val Loss: 0.4099 | Time: 1.73s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4099)\r\n",
      "Epoch 003 | Train Loss: 0.4295 | Val Loss: 0.4046 | Time: 1.72s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4046)\r\n",
      "Epoch 004 | Train Loss: 0.4245 | Val Loss: 0.4105 | Time: 1.78s\r\n",
      "Epoch 005 | Train Loss: 0.4254 | Val Loss: 0.4089 | Time: 1.75s\r\n",
      "Epoch 006 | Train Loss: 0.4176 | Val Loss: 0.4116 | Time: 1.79s\r\n",
      "Epoch 007 | Train Loss: 0.4191 | Val Loss: 0.4014 | Time: 1.74s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4014)\r\n",
      "Epoch 008 | Train Loss: 0.4161 | Val Loss: 0.4046 | Time: 1.74s\r\n",
      "Epoch 009 | Train Loss: 0.4178 | Val Loss: 0.4070 | Time: 1.74s\r\n",
      "Epoch 010 | Train Loss: 0.4139 | Val Loss: 0.4026 | Time: 1.77s\r\n",
      "Epoch 011 | Train Loss: 0.4117 | Val Loss: 0.4108 | Time: 1.75s\r\n",
      "Epoch 012 | Train Loss: 0.4135 | Val Loss: 0.4081 | Time: 1.77s\r\n",
      "Epoch 013 | Train Loss: 0.4086 | Val Loss: 0.4076 | Time: 1.77s\r\n",
      "Epoch 014 | Train Loss: 0.4111 | Val Loss: 0.4063 | Time: 1.78s\r\n",
      "Epoch 015 | Train Loss: 0.4134 | Val Loss: 0.4145 | Time: 1.75s\r\n",
      "Epoch 016 | Train Loss: 0.4092 | Val Loss: 0.4105 | Time: 1.97s\r\n",
      "Epoch 017 | Train Loss: 0.4028 | Val Loss: 0.4154 | Time: 1.71s\r\n",
      "Epoch 018 | Train Loss: 0.4059 | Val Loss: 0.4155 | Time: 1.75s\r\n",
      "Epoch 019 | Train Loss: 0.4019 | Val Loss: 0.4206 | Time: 1.74s\r\n",
      "Epoch 020 | Train Loss: 0.4073 | Val Loss: 0.4170 | Time: 1.78s\r\n",
      "Epoch 021 | Train Loss: 0.4026 | Val Loss: 0.4190 | Time: 1.79s\r\n",
      "Epoch 022 | Train Loss: 0.4046 | Val Loss: 0.4221 | Time: 1.74s\r\n",
      "Epoch 023 | Train Loss: 0.4056 | Val Loss: 0.4224 | Time: 1.76s\r\n",
      "Epoch 024 | Train Loss: 0.3992 | Val Loss: 0.4210 | Time: 1.76s\r\n",
      "Epoch 025 | Train Loss: 0.4017 | Val Loss: 0.4321 | Time: 1.75s\r\n",
      "Epoch 026 | Train Loss: 0.3985 | Val Loss: 0.4236 | Time: 1.75s\r\n",
      "Epoch 027 | Train Loss: 0.4010 | Val Loss: 0.4216 | Time: 1.77s\r\n",
      "\r\n",
      "Early stopping à l'époque 27 (patience: 20)\r\n",
      "✅ Meilleur modèle chargé (époque 7, val_loss: 0.4014)\r\n",
      "\r\n",
      "📊 Évaluation finale du modèle FTT+...\r\n",
      "\r\n",
      "🔍 Analyse d'interprétabilité avec interpretability_analyzer...\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. tenure              : 0.0567\r\n",
      "   2. StreamingMovies     : 0.0543\r\n",
      "   3. PaymentMethod       : 0.0534\r\n",
      "   4. gender              : 0.0534\r\n",
      "   5. Dependents          : 0.0531\r\n",
      "   6. SeniorCitizen       : 0.0530\r\n",
      "   7. Partner             : 0.0529\r\n",
      "   8. StreamingTV         : 0.0526\r\n",
      "   9. Contract            : 0.0525\r\n",
      "  10. DeviceProtection    : 0.0525\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus_plus/seed_0/heatmaps/interpretable_ftt_plus_from_ftt_plus_plus_importance_seed_0.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_metrics_seed_0.json\r\n",
      "Importance: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_importance_seed_0.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_{importance|attention}_seed_0.png\r\n",
      "Modèle: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_weights_seed_0.pt\r\n",
      "\r\n",
      "🎯 Sélection des 15 features les plus importantes...\r\n",
      "📋 Features sélectionnées:\r\n",
      "   1. tenure               (NUM): 0.0567\r\n",
      "   2. StreamingMovies      (CAT): 0.0543\r\n",
      "   3. PaymentMethod        (CAT): 0.0534\r\n",
      "   4. gender               (CAT): 0.0534\r\n",
      "   5. Dependents           (CAT): 0.0531\r\n",
      "   6. SeniorCitizen        (CAT): 0.0530\r\n",
      "   7. Partner              (CAT): 0.0529\r\n",
      "   8. StreamingTV          (CAT): 0.0526\r\n",
      "   9. Contract             (CAT): 0.0525\r\n",
      "  10. DeviceProtection     (CAT): 0.0525\r\n",
      "  11. TotalCharges         (NUM): 0.0525\r\n",
      "  12. PaperlessBilling     (CAT): 0.0524\r\n",
      "  13. InternetService      (CAT): 0.0521\r\n",
      "  14. PhoneService         (CAT): 0.0520\r\n",
      "  15. MultipleLines        (CAT): 0.0517\r\n",
      "\r\n",
      "🎯 === ÉTAPE 2: Entraînement Modèle Random ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "📋 Mapping des features sélectionnées:\r\n",
      "   - Numériques sélectionnées: ['tenure', 'TotalCharges'] → indices [0, 2]\r\n",
      "   - Catégorielles sélectionnées: ['StreamingMovies', 'PaymentMethod', 'gender', 'Dependents', 'SeniorCitizen', 'Partner', 'StreamingTV', 'Contract', 'DeviceProtection', 'PaperlessBilling', 'InternetService', 'PhoneService', 'MultipleLines'] → indices [12, 15, 0, 3, 1, 2, 11, 13, 9, 14, 6, 4, 5]\r\n",
      "📊 Features sélectionnées: 2 numériques, 13 catégorielles\r\n",
      "🎲 Interactions aléatoires: 8 paires\r\n",
      "Modèle Random créé avec 87,105 paramètres\r\n",
      "🔗 Sparsité d'attention: 82.03%\r\n",
      "   - Connexions feature-feature: 16\r\n",
      "⏳ Entraînement du modèle Random en cours...\r\n",
      "Epoch 000 | Train Loss: 0.4886 | Val Loss: 0.4512 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4512)\r\n",
      "Epoch 001 | Train Loss: 0.4510 | Val Loss: 0.4346 | Time: 1.63s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4346)\r\n",
      "Epoch 002 | Train Loss: 0.4402 | Val Loss: 0.4368 | Time: 1.63s\r\n",
      "Epoch 003 | Train Loss: 0.4377 | Val Loss: 0.4321 | Time: 1.62s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4321)\r\n",
      "Epoch 004 | Train Loss: 0.4320 | Val Loss: 0.4337 | Time: 1.67s\r\n",
      "Epoch 005 | Train Loss: 0.4339 | Val Loss: 0.4343 | Time: 1.70s\r\n",
      "Epoch 006 | Train Loss: 0.4349 | Val Loss: 0.4293 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4293)\r\n",
      "Epoch 007 | Train Loss: 0.4329 | Val Loss: 0.4244 | Time: 1.63s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4244)\r\n",
      "Epoch 008 | Train Loss: 0.4281 | Val Loss: 0.4283 | Time: 1.64s\r\n",
      "Epoch 009 | Train Loss: 0.4285 | Val Loss: 0.4299 | Time: 1.63s\r\n",
      "Epoch 010 | Train Loss: 0.4275 | Val Loss: 0.4249 | Time: 1.67s\r\n",
      "Epoch 011 | Train Loss: 0.4243 | Val Loss: 0.4229 | Time: 1.65s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4229)\r\n",
      "Epoch 012 | Train Loss: 0.4258 | Val Loss: 0.4242 | Time: 1.63s\r\n",
      "Epoch 013 | Train Loss: 0.4221 | Val Loss: 0.4270 | Time: 1.62s\r\n",
      "Epoch 014 | Train Loss: 0.4264 | Val Loss: 0.4257 | Time: 1.63s\r\n",
      "Epoch 015 | Train Loss: 0.4231 | Val Loss: 0.4316 | Time: 1.63s\r\n",
      "Epoch 016 | Train Loss: 0.4249 | Val Loss: 0.4296 | Time: 1.66s\r\n",
      "Epoch 017 | Train Loss: 0.4261 | Val Loss: 0.4212 | Time: 1.62s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4212)\r\n",
      "Epoch 018 | Train Loss: 0.4261 | Val Loss: 0.4205 | Time: 1.60s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4205)\r\n",
      "Epoch 019 | Train Loss: 0.4247 | Val Loss: 0.4263 | Time: 1.60s\r\n",
      "Epoch 020 | Train Loss: 0.4243 | Val Loss: 0.4196 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4196)\r\n",
      "Epoch 021 | Train Loss: 0.4233 | Val Loss: 0.4189 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4189)\r\n",
      "Epoch 022 | Train Loss: 0.4237 | Val Loss: 0.4237 | Time: 1.65s\r\n",
      "Epoch 023 | Train Loss: 0.4241 | Val Loss: 0.4226 | Time: 1.62s\r\n",
      "Epoch 024 | Train Loss: 0.4206 | Val Loss: 0.4287 | Time: 1.60s\r\n",
      "Epoch 025 | Train Loss: 0.4238 | Val Loss: 0.4176 | Time: 1.71s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4176)\r\n",
      "Epoch 026 | Train Loss: 0.4186 | Val Loss: 0.4190 | Time: 1.64s\r\n",
      "Epoch 027 | Train Loss: 0.4197 | Val Loss: 0.4211 | Time: 1.65s\r\n",
      "Epoch 028 | Train Loss: 0.4227 | Val Loss: 0.4237 | Time: 1.64s\r\n",
      "Epoch 029 | Train Loss: 0.4211 | Val Loss: 0.4198 | Time: 1.71s\r\n",
      "Epoch 030 | Train Loss: 0.4224 | Val Loss: 0.4236 | Time: 1.65s\r\n",
      "Epoch 031 | Train Loss: 0.4185 | Val Loss: 0.4267 | Time: 1.68s\r\n",
      "Epoch 032 | Train Loss: 0.4217 | Val Loss: 0.4252 | Time: 1.63s\r\n",
      "Epoch 033 | Train Loss: 0.4208 | Val Loss: 0.4313 | Time: 1.63s\r\n",
      "Epoch 034 | Train Loss: 0.4221 | Val Loss: 0.4249 | Time: 1.65s\r\n",
      "Epoch 035 | Train Loss: 0.4193 | Val Loss: 0.4281 | Time: 1.69s\r\n",
      "Epoch 036 | Train Loss: 0.4160 | Val Loss: 0.4260 | Time: 1.65s\r\n",
      "Epoch 037 | Train Loss: 0.4217 | Val Loss: 0.4275 | Time: 1.64s\r\n",
      "Epoch 038 | Train Loss: 0.4211 | Val Loss: 0.4256 | Time: 1.63s\r\n",
      "Epoch 039 | Train Loss: 0.4216 | Val Loss: 0.4321 | Time: 1.65s\r\n",
      "Epoch 040 | Train Loss: 0.4197 | Val Loss: 0.4282 | Time: 1.63s\r\n",
      "Epoch 041 | Train Loss: 0.4222 | Val Loss: 0.4359 | Time: 1.63s\r\n",
      "Epoch 042 | Train Loss: 0.4204 | Val Loss: 0.4209 | Time: 1.59s\r\n",
      "Epoch 043 | Train Loss: 0.4237 | Val Loss: 0.4266 | Time: 1.58s\r\n",
      "Epoch 044 | Train Loss: 0.4204 | Val Loss: 0.4253 | Time: 1.65s\r\n",
      "Epoch 045 | Train Loss: 0.4228 | Val Loss: 0.4253 | Time: 1.62s\r\n",
      "\r\n",
      "Early stopping à l'époque 45 (patience: 20)\r\n",
      "✅ Meilleur modèle Random chargé (époque 25, val_loss: 0.4176)\r\n",
      "\r\n",
      "📊 Évaluation finale du modèle Random...\r\n",
      "\r\n",
      "🔍 Analyse d'importance des features dans le modèle Random...\r\n",
      "\r\n",
      "📊 Importance des features dans le modèle Random:\r\n",
      "   1. PaperlessBilling     (CAT): 0.1392\r\n",
      "   2. Dependents           (CAT): 0.1278\r\n",
      "   3. PhoneService         (CAT): 0.1116\r\n",
      "   4. DeviceProtection     (CAT): 0.0947\r\n",
      "   5. StreamingTV          (CAT): 0.0861\r\n",
      "   6. InternetService      (CAT): 0.0794\r\n",
      "   7. SeniorCitizen        (CAT): 0.0702\r\n",
      "   8. TotalCharges         (NUM): 0.0697\r\n",
      "   9. tenure               (NUM): 0.0630\r\n",
      "  10. Contract             (CAT): 0.0453\r\n",
      "  11. StreamingMovies      (CAT): 0.0229\r\n",
      "  12. Partner              (CAT): 0.0228\r\n",
      "  13. MultipleLines        (CAT): 0.0228\r\n",
      "  14. PaymentMethod        (CAT): 0.0225\r\n",
      "  15. gender               (CAT): 0.0219\r\n",
      "\r\n",
      "🔍 Analyse d'interprétabilité complète du modèle Random...\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. PaperlessBilling    : 0.1392\r\n",
      "   2. Dependents          : 0.1278\r\n",
      "   3. PhoneService        : 0.1116\r\n",
      "   4. DeviceProtection    : 0.0947\r\n",
      "   5. StreamingTV         : 0.0861\r\n",
      "   6. InternetService     : 0.0794\r\n",
      "   7. SeniorCitizen       : 0.0702\r\n",
      "   8. TotalCharges        : 0.0697\r\n",
      "   9. tenure              : 0.0630\r\n",
      "  10. Contract            : 0.0453\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus_plus/seed_0/heatmaps/interpretable_ftt_plus_plus_importance_seed_0.png\r\n",
      "Heatmap d'attention sparse sauvegardée: results/results_telecom/ftt_plus_plus/seed_0/heatmaps/interpretable_ftt_plus_plus_attention_seed_0.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_metrics_seed_0.json\r\n",
      "Importance: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_importance_seed_0.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_{importance|attention}_seed_0.png\r\n",
      "Modèle: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_weights_seed_0.pt\r\n",
      "💾 Résultats complets sauvegardés: results/results_telecom/ftt_plus_plus/seed_0/métriques/ftt_plus_plus_results.json\r\n",
      "\r\n",
      "✅ === PIPELINE TERMINÉ EN 128.9s ===\r\n"
     ]
    }
   ],
   "source": [
    "# Avec embedding T-LR et paramètres personnalisés\n",
    "!PYTHONPATH=/kaggle/working/customer-churn-ft_transformer python train/Telecom/train_ftt_plus_plus/train.py --embedding_type \"T-LR\" --M 15 --k 8 --stage1_epochs 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226ed8eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T11:32:57.322084Z",
     "iopub.status.busy": "2025-07-07T11:32:57.321863Z",
     "iopub.status.idle": "2025-07-07T11:34:49.298965Z",
     "shell.execute_reply": "2025-07-07T11:34:49.298171Z"
    },
    "papermill": {
     "duration": 111.998779,
     "end_time": "2025-07-07T11:34:49.300990",
     "exception": false,
     "start_time": "2025-07-07T11:32:57.302211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENTRAÎNEMENT FTT++ MODULAIRE - DATASET TELECOM ===\r\n",
      "GPU détecté: Tesla P100-PCIE-16GB (17.1GB)\r\n",
      "Device sélectionné: cuda\r\n",
      "Chargement des données (seed: 42)\r\n",
      "Données originales: 7043 lignes\r\n",
      "Après nettoyage: 7032 lignes (11 supprimées)\r\n",
      "\r\n",
      "Informations sur les features:\r\n",
      "Features numériques (3): ['tenure', 'MonthlyCharges', 'TotalCharges']\r\n",
      "Variables catégorielles (16): ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\r\n",
      "Cardinalités des variables catégorielles: [2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4]\r\n",
      "Distribution des classes: [5163 1869]\r\n",
      "Tailles des ensembles:\r\n",
      "Train: 4781 | Val: 844 | Test: 1407\r\n",
      "Features numériques: 3\r\n",
      "Features catégorielles: 16\r\n",
      "Échantillons: train=4781, val=844, test=1407\r\n",
      "🚀 === PIPELINE FTT++ COMPLET ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "🚀 === ÉTAPE 1: Entraînement FTT+ Complet ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "✅ Validation mapping: 3 num + 16 cat = 19 total\r\n",
      "Type d'embedding numérique: P-LR-LR\r\n",
      "Modèle FTT+ créé avec 285,841 paramètres\r\n",
      "⏳ Entraînement du modèle FTT+ en cours...\r\n",
      "Epoch 000 | Train Loss: 0.4919 | Val Loss: 0.4429 | Time: 2.16s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4429)\r\n",
      "Epoch 001 | Train Loss: 0.4441 | Val Loss: 0.4324 | Time: 1.85s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4324)\r\n",
      "Epoch 002 | Train Loss: 0.4434 | Val Loss: 0.4295 | Time: 1.89s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4295)\r\n",
      "Epoch 003 | Train Loss: 0.4378 | Val Loss: 0.4343 | Time: 1.85s\r\n",
      "Epoch 004 | Train Loss: 0.4353 | Val Loss: 0.4370 | Time: 1.80s\r\n",
      "Epoch 005 | Train Loss: 0.4359 | Val Loss: 0.4359 | Time: 1.82s\r\n",
      "Epoch 006 | Train Loss: 0.4300 | Val Loss: 0.4424 | Time: 1.83s\r\n",
      "Epoch 007 | Train Loss: 0.4328 | Val Loss: 0.4454 | Time: 1.86s\r\n",
      "Epoch 008 | Train Loss: 0.4346 | Val Loss: 0.4378 | Time: 1.81s\r\n",
      "Epoch 009 | Train Loss: 0.4288 | Val Loss: 0.4469 | Time: 1.81s\r\n",
      "Epoch 010 | Train Loss: 0.4273 | Val Loss: 0.4376 | Time: 1.80s\r\n",
      "Epoch 011 | Train Loss: 0.4316 | Val Loss: 0.4400 | Time: 1.92s\r\n",
      "Epoch 012 | Train Loss: 0.4306 | Val Loss: 0.4303 | Time: 1.93s\r\n",
      "Epoch 013 | Train Loss: 0.4267 | Val Loss: 0.4381 | Time: 1.87s\r\n",
      "Epoch 014 | Train Loss: 0.4226 | Val Loss: 0.4456 | Time: 1.83s\r\n",
      "Epoch 015 | Train Loss: 0.4257 | Val Loss: 0.4490 | Time: 1.83s\r\n",
      "Epoch 016 | Train Loss: 0.4256 | Val Loss: 0.4398 | Time: 1.82s\r\n",
      "Epoch 017 | Train Loss: 0.4222 | Val Loss: 0.4443 | Time: 1.82s\r\n",
      "Epoch 018 | Train Loss: 0.4206 | Val Loss: 0.4483 | Time: 1.85s\r\n",
      "Epoch 019 | Train Loss: 0.4233 | Val Loss: 0.4503 | Time: 1.87s\r\n",
      "Epoch 020 | Train Loss: 0.4198 | Val Loss: 0.4495 | Time: 1.83s\r\n",
      "Epoch 021 | Train Loss: 0.4205 | Val Loss: 0.4438 | Time: 1.85s\r\n",
      "Epoch 022 | Train Loss: 0.4170 | Val Loss: 0.4566 | Time: 1.82s\r\n",
      "\r\n",
      "Early stopping à l'époque 22 (patience: 20)\r\n",
      "✅ Meilleur modèle chargé (époque 2, val_loss: 0.4295)\r\n",
      "\r\n",
      "📊 Évaluation finale du modèle FTT+...\r\n",
      "\r\n",
      "🔍 Analyse d'interprétabilité avec interpretability_analyzer...\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. OnlineBackup        : 0.0532\r\n",
      "   2. MultipleLines       : 0.0529\r\n",
      "   3. TotalCharges        : 0.0529\r\n",
      "   4. SeniorCitizen       : 0.0528\r\n",
      "   5. OnlineSecurity      : 0.0528\r\n",
      "   6. PaperlessBilling    : 0.0528\r\n",
      "   7. InternetService     : 0.0527\r\n",
      "   8. Contract            : 0.0527\r\n",
      "   9. PaymentMethod       : 0.0527\r\n",
      "  10. Dependents          : 0.0527\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus_plus/seed_42/heatmaps/interpretable_ftt_plus_from_ftt_plus_plus_importance_seed_42.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_from_ftt_plus_plus_metrics_seed_42.json\r\n",
      "Importance: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_from_ftt_plus_plus_importance_seed_42.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_from_ftt_plus_plus_{importance|attention}_seed_42.png\r\n",
      "Modèle: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_from_ftt_plus_plus_weights_seed_42.pt\r\n",
      "\r\n",
      "🎯 Sélection des 12 features les plus importantes...\r\n",
      "📋 Features sélectionnées:\r\n",
      "   1. OnlineBackup         (CAT): 0.0532\r\n",
      "   2. MultipleLines        (CAT): 0.0529\r\n",
      "   3. TotalCharges         (NUM): 0.0529\r\n",
      "   4. SeniorCitizen        (CAT): 0.0528\r\n",
      "   5. OnlineSecurity       (CAT): 0.0528\r\n",
      "   6. PaperlessBilling     (CAT): 0.0528\r\n",
      "   7. InternetService      (CAT): 0.0527\r\n",
      "   8. Contract             (CAT): 0.0527\r\n",
      "   9. PaymentMethod        (CAT): 0.0527\r\n",
      "  10. Dependents           (CAT): 0.0527\r\n",
      "  11. tenure               (NUM): 0.0527\r\n",
      "  12. StreamingTV          (CAT): 0.0526\r\n",
      "\r\n",
      "🎯 === ÉTAPE 2: Entraînement Modèle Random ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "📋 Mapping des features sélectionnées:\r\n",
      "   - Numériques sélectionnées: ['TotalCharges', 'tenure'] → indices [2, 0]\r\n",
      "   - Catégorielles sélectionnées: ['OnlineBackup', 'MultipleLines', 'SeniorCitizen', 'OnlineSecurity', 'PaperlessBilling', 'InternetService', 'Contract', 'PaymentMethod', 'Dependents', 'StreamingTV'] → indices [8, 5, 1, 7, 14, 6, 13, 15, 3, 11]\r\n",
      "📊 Features sélectionnées: 2 numériques, 10 catégorielles\r\n",
      "🎲 Interactions aléatoires: 6 paires\r\n",
      "Modèle Random créé avec 238,081 paramètres\r\n",
      "🔗 Sparsité d'attention: 78.70%\r\n",
      "   - Connexions feature-feature: 12\r\n",
      "⏳ Entraînement du modèle Random en cours...\r\n",
      "Epoch 000 | Train Loss: 0.4806 | Val Loss: 0.4468 | Time: 1.68s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4468)\r\n",
      "Epoch 001 | Train Loss: 0.4495 | Val Loss: 0.4425 | Time: 1.65s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4425)\r\n",
      "Epoch 002 | Train Loss: 0.4372 | Val Loss: 0.4465 | Time: 1.64s\r\n",
      "Epoch 003 | Train Loss: 0.4390 | Val Loss: 0.4326 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4326)\r\n",
      "Epoch 004 | Train Loss: 0.4341 | Val Loss: 0.4347 | Time: 1.64s\r\n",
      "Epoch 005 | Train Loss: 0.4375 | Val Loss: 0.4321 | Time: 1.66s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4321)\r\n",
      "Epoch 006 | Train Loss: 0.4328 | Val Loss: 0.4374 | Time: 1.80s\r\n",
      "Epoch 007 | Train Loss: 0.4325 | Val Loss: 0.4406 | Time: 1.63s\r\n",
      "Epoch 008 | Train Loss: 0.4329 | Val Loss: 0.4405 | Time: 1.64s\r\n",
      "Epoch 009 | Train Loss: 0.4324 | Val Loss: 0.4358 | Time: 1.65s\r\n",
      "Epoch 010 | Train Loss: 0.4232 | Val Loss: 0.4401 | Time: 1.65s\r\n",
      "Epoch 011 | Train Loss: 0.4262 | Val Loss: 0.4403 | Time: 1.63s\r\n",
      "Epoch 012 | Train Loss: 0.4311 | Val Loss: 0.4385 | Time: 1.69s\r\n",
      "Epoch 013 | Train Loss: 0.4262 | Val Loss: 0.4405 | Time: 1.66s\r\n",
      "Epoch 014 | Train Loss: 0.4260 | Val Loss: 0.4456 | Time: 1.67s\r\n",
      "Epoch 015 | Train Loss: 0.4258 | Val Loss: 0.4385 | Time: 1.66s\r\n",
      "Epoch 016 | Train Loss: 0.4286 | Val Loss: 0.4312 | Time: 1.66s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4312)\r\n",
      "Epoch 017 | Train Loss: 0.4259 | Val Loss: 0.4367 | Time: 1.68s\r\n",
      "Epoch 018 | Train Loss: 0.4243 | Val Loss: 0.4462 | Time: 1.68s\r\n",
      "Epoch 019 | Train Loss: 0.4286 | Val Loss: 0.4445 | Time: 1.66s\r\n",
      "Epoch 020 | Train Loss: 0.4259 | Val Loss: 0.4394 | Time: 1.67s\r\n",
      "Epoch 021 | Train Loss: 0.4271 | Val Loss: 0.4467 | Time: 1.64s\r\n",
      "Epoch 022 | Train Loss: 0.4251 | Val Loss: 0.4486 | Time: 1.63s\r\n",
      "Epoch 023 | Train Loss: 0.4252 | Val Loss: 0.4415 | Time: 1.62s\r\n",
      "Epoch 024 | Train Loss: 0.4185 | Val Loss: 0.4506 | Time: 1.67s\r\n",
      "Epoch 025 | Train Loss: 0.4310 | Val Loss: 0.4460 | Time: 1.71s\r\n",
      "Epoch 026 | Train Loss: 0.4277 | Val Loss: 0.4476 | Time: 1.61s\r\n",
      "Epoch 027 | Train Loss: 0.4255 | Val Loss: 0.4503 | Time: 1.62s\r\n",
      "Epoch 028 | Train Loss: 0.4174 | Val Loss: 0.4496 | Time: 1.61s\r\n",
      "Epoch 029 | Train Loss: 0.4181 | Val Loss: 0.4544 | Time: 1.60s\r\n",
      "Epoch 030 | Train Loss: 0.4189 | Val Loss: 0.4477 | Time: 1.65s\r\n",
      "Epoch 031 | Train Loss: 0.4169 | Val Loss: 0.4610 | Time: 1.65s\r\n",
      "Epoch 032 | Train Loss: 0.4196 | Val Loss: 0.4559 | Time: 1.64s\r\n",
      "Epoch 033 | Train Loss: 0.4216 | Val Loss: 0.4552 | Time: 1.66s\r\n",
      "Epoch 034 | Train Loss: 0.4200 | Val Loss: 0.4479 | Time: 1.65s\r\n",
      "Epoch 035 | Train Loss: 0.4201 | Val Loss: 0.4576 | Time: 1.65s\r\n",
      "Epoch 036 | Train Loss: 0.4198 | Val Loss: 0.4506 | Time: 1.67s\r\n",
      "\r\n",
      "Early stopping à l'époque 36 (patience: 20)\r\n",
      "✅ Meilleur modèle Random chargé (époque 16, val_loss: 0.4312)\r\n",
      "\r\n",
      "📊 Évaluation finale du modèle Random...\r\n",
      "\r\n",
      "🔍 Analyse d'importance des features dans le modèle Random...\r\n",
      "\r\n",
      "📊 Importance des features dans le modèle Random:\r\n",
      "   1. PaperlessBilling     (CAT): 0.1293\r\n",
      "   2. PaymentMethod        (CAT): 0.1142\r\n",
      "   3. TotalCharges         (NUM): 0.1015\r\n",
      "   4. Contract             (CAT): 0.0913\r\n",
      "   5. InternetService      (CAT): 0.0860\r\n",
      "   6. OnlineSecurity       (CAT): 0.0837\r\n",
      "   7. SeniorCitizen        (CAT): 0.0740\r\n",
      "   8. OnlineBackup         (CAT): 0.0716\r\n",
      "   9. Dependents           (CAT): 0.0623\r\n",
      "  10. tenure               (NUM): 0.0622\r\n",
      "  11. StreamingTV          (CAT): 0.0621\r\n",
      "  12. MultipleLines        (CAT): 0.0618\r\n",
      "\r\n",
      "🔍 Analyse d'interprétabilité complète du modèle Random...\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. PaperlessBilling    : 0.1293\r\n",
      "   2. PaymentMethod       : 0.1142\r\n",
      "   3. TotalCharges        : 0.1015\r\n",
      "   4. Contract            : 0.0913\r\n",
      "   5. InternetService     : 0.0860\r\n",
      "   6. OnlineSecurity      : 0.0837\r\n",
      "   7. SeniorCitizen       : 0.0740\r\n",
      "   8. OnlineBackup        : 0.0716\r\n",
      "   9. Dependents          : 0.0623\r\n",
      "  10. tenure              : 0.0622\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus_plus/seed_42/heatmaps/interpretable_ftt_plus_plus_importance_seed_42.png\r\n",
      "Heatmap d'attention sparse sauvegardée: results/results_telecom/ftt_plus_plus/seed_42/heatmaps/interpretable_ftt_plus_plus_attention_seed_42.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_plus_metrics_seed_42.json\r\n",
      "Importance: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_plus_importance_seed_42.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_plus_{importance|attention}_seed_42.png\r\n",
      "Modèle: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_plus_weights_seed_42.pt\r\n",
      "💾 Résultats complets sauvegardés: results/results_telecom/ftt_plus_plus/seed_42/métriques/ftt_plus_plus_results.json\r\n",
      "\r\n",
      "✅ === PIPELINE TERMINÉ EN 107.3s ===\r\n"
     ]
    }
   ],
   "source": [
    "# Configuration complète\n",
    "!PYTHONPATH=/kaggle/working/customer-churn-ft_transformer python train/Telecom/train_ftt_plus_plus/train.py \\\n",
    "    --embedding_type \"P-LR-LR\" \\\n",
    "    --M 12 \\\n",
    "    --k 6 \\\n",
    "    --stage1_epochs 75 \\\n",
    "    --stage2_epochs 50 \\\n",
    "    --lr 0.0005 \\\n",
    "    --d_token 128 \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78469e63",
   "metadata": {
    "papermill": {
     "duration": 0.021439,
     "end_time": "2025-07-07T11:34:49.344793",
     "exception": false,
     "start_time": "2025-07-07T11:34:49.323354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "661cce9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T11:34:49.389116Z",
     "iopub.status.busy": "2025-07-07T11:34:49.388838Z",
     "iopub.status.idle": "2025-07-07T11:34:49.620567Z",
     "shell.execute_reply": "2025-07-07T11:34:49.619886Z"
    },
    "papermill": {
     "duration": 0.255663,
     "end_time": "2025-07-07T11:34:49.621953",
     "exception": false,
     "start_time": "2025-07-07T11:34:49.366290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/customer-churn-ft_transformer\r\n",
      "total 184\r\n",
      "drwxr-xr-x 10 root root  4096 Jul  7 11:25 .\r\n",
      "drwxr-xr-x  3 root root  4096 Jul  7 11:22 ..\r\n",
      "drwxr-xr-x  3 root root  4096 Jul  7 11:22 data\r\n",
      "-rw-r--r--  1 root root 98979 Jul  7 11:22 Experiments.ipynb\r\n",
      "drwxr-xr-x  3 root root  4096 Jul  7 11:25 ftt_plus\r\n",
      "drwxr-xr-x  8 root root  4096 Jul  7 11:27 ftt_plus_plus\r\n",
      "drwxr-xr-x  8 root root  4096 Jul  7 11:22 .git\r\n",
      "-rw-r--r--  1 root root  8324 Jul  7 11:22 interpretability_analyzer.py\r\n",
      "-rw-r--r--  1 root root 10266 Jul  7 11:22 num_embedding_factory.py\r\n",
      "drwxr-xr-x  2 root root  4096 Jul  7 11:25 __pycache__\r\n",
      "-rw-r--r--  1 root root  6726 Jul  7 11:22 README.md\r\n",
      "drwxr-xr-x  3 root root  4096 Jul  7 11:25 results\r\n",
      "drwxr-xr-x  5 root root  4096 Jul  7 11:22 rtdl_lib\r\n",
      "-rw-r--r--  1 root root  6821 Jul  7 11:22 test_embeddings.py\r\n",
      "drwxr-xr-x  3 root root  4096 Jul  7 11:22 train\r\n",
      "-rw-r--r--  1 root root  2213 Jul  7 11:22 utils.py\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8809f2f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T11:34:49.667275Z",
     "iopub.status.busy": "2025-07-07T11:34:49.666598Z",
     "iopub.status.idle": "2025-07-07T11:34:50.167503Z",
     "shell.execute_reply": "2025-07-07T11:34:50.166656Z"
    },
    "papermill": {
     "duration": 0.524575,
     "end_time": "2025-07-07T11:34:50.168916",
     "exception": false,
     "start_time": "2025-07-07T11:34:49.644341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/results.zip'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# On se place dans le bon dossier racine\n",
    "import os\n",
    "os.chdir('/kaggle/working/customer-churn-ft_transformer')\n",
    "\n",
    "# On crée une archive ZIP du dossier results\n",
    "shutil.make_archive('/kaggle/working/results', 'zip', 'results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88ea28",
   "metadata": {
    "papermill": {
     "duration": 0.021499,
     "end_time": "2025-07-07T11:34:50.213340",
     "exception": false,
     "start_time": "2025-07-07T11:34:50.191841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89160e99",
   "metadata": {
    "papermill": {
     "duration": 0.021414,
     "end_time": "2025-07-07T11:34:50.256565",
     "exception": false,
     "start_time": "2025-07-07T11:34:50.235151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 772.41116,
   "end_time": "2025-07-07T11:34:50.596841",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-07T11:21:58.185681",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
