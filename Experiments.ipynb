{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15821e0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-07T10:35:57.433947Z",
     "iopub.status.busy": "2025-07-07T10:35:57.433682Z",
     "iopub.status.idle": "2025-07-07T10:35:58.303469Z",
     "shell.execute_reply": "2025-07-07T10:35:58.302452Z"
    },
    "papermill": {
     "duration": 0.876112,
     "end_time": "2025-07-07T10:35:58.304983",
     "exception": false,
     "start_time": "2025-07-07T10:35:57.428871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'customer-churn-ft_transformer'...\r\n",
      "remote: Enumerating objects: 629, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (321/321), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (207/207), done.\u001b[K\r\n",
      "remote: Total 629 (delta 154), reused 243 (delta 81), pack-reused 308 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (629/629), 711.82 KiB | 15.47 MiB/s, done.\r\n",
      "Resolving deltas: 100% (298/298), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vleonel-junior/customer-churn-ft_transformer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6ec8dae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:35:58.314091Z",
     "iopub.status.busy": "2025-07-07T10:35:58.313422Z",
     "iopub.status.idle": "2025-07-07T10:35:58.317460Z",
     "shell.execute_reply": "2025-07-07T10:35:58.316768Z"
    },
    "papermill": {
     "duration": 0.009585,
     "end_time": "2025-07-07T10:35:58.318593",
     "exception": false,
     "start_time": "2025-07-07T10:35:58.309008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/working/customer-churn-ft_transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680aba49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:35:58.328537Z",
     "iopub.status.busy": "2025-07-07T10:35:58.328269Z",
     "iopub.status.idle": "2025-07-07T10:35:58.684751Z",
     "shell.execute_reply": "2025-07-07T10:35:58.683895Z"
    },
    "papermill": {
     "duration": 0.363606,
     "end_time": "2025-07-07T10:35:58.686361",
     "exception": false,
     "start_time": "2025-07-07T10:35:58.322755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/customer-churn-ft_transformer\r\n",
      "total 168\r\n",
      "drwxr-xr-x 9 root root  4096 Jul  7 10:35 .\r\n",
      "drwxr-xr-x 3 root root  4096 Jul  7 10:35 ..\r\n",
      "drwxr-xr-x 3 root root  4096 Jul  7 10:35 data\r\n",
      "-rw-r--r-- 1 root root 92591 Jul  7 10:35 Experiments.ipynb\r\n",
      "drwxr-xr-x 2 root root  4096 Jul  7 10:35 ftt_plus\r\n",
      "drwxr-xr-x 7 root root  4096 Jul  7 10:35 ftt_plus_plus\r\n",
      "drwxr-xr-x 8 root root  4096 Jul  7 10:35 .git\r\n",
      "-rw-r--r-- 1 root root  7839 Jul  7 10:35 interpretability_analyzer.py\r\n",
      "-rw-r--r-- 1 root root 10266 Jul  7 10:35 num_embedding_factory.py\r\n",
      "drwxr-xr-x 2 root root  4096 Jul  7 10:35 __pycache__\r\n",
      "-rw-r--r-- 1 root root  6726 Jul  7 10:35 README.md\r\n",
      "drwxr-xr-x 5 root root  4096 Jul  7 10:35 rtdl_lib\r\n",
      "-rw-r--r-- 1 root root  6821 Jul  7 10:35 test_embeddings.py\r\n",
      "drwxr-xr-x 3 root root  4096 Jul  7 10:35 train\r\n",
      "-rw-r--r-- 1 root root  2213 Jul  7 10:35 utils.py\r\n",
      "total 968\r\n",
      "drwxr-xr-x 3 root root   4096 Jul  7 10:35 .\r\n",
      "drwxr-xr-x 9 root root   4096 Jul  7 10:35 ..\r\n",
      "-rw-r--r-- 1 root root   4224 Jul  7 10:35 process_telecom_data.py\r\n",
      "drwxr-xr-x 2 root root   4096 Jul  7 10:35 __pycache__\r\n",
      "-rw-r--r-- 1 root root 970457 Jul  7 10:35 Telco_Customer_Churn.csv\r\n",
      "-rw-r--r-- 1 root root      0 Jul  7 10:35 utils.py\r\n"
     ]
    }
   ],
   "source": [
    "# Le bon chemin est directement :\n",
    "import os\n",
    "os.chdir('/kaggle/working/customer-churn-ft_transformer')\n",
    "\n",
    "# Vérifier que vous êtes au bon endroit\n",
    "!pwd\n",
    "!ls -la\n",
    "\n",
    "# Vérifier que les datasets sont là\n",
    "!ls -la data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d90e270f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:35:58.700137Z",
     "iopub.status.busy": "2025-07-07T10:35:58.699882Z",
     "iopub.status.idle": "2025-07-07T10:37:12.851031Z",
     "shell.execute_reply": "2025-07-07T10:37:12.850262Z"
    },
    "papermill": {
     "duration": 74.159611,
     "end_time": "2025-07-07T10:37:12.852558",
     "exception": false,
     "start_time": "2025-07-07T10:35:58.692947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation de rtdl_num_embeddings réussie\r\n",
      "Installation de scikit-learn réussie\r\n"
     ]
    }
   ],
   "source": [
    "# Installation silencieuse des packages pour rtdl_num_embeddings\n",
    "!pip install rtdl_num_embeddings -qqq > /dev/null 2>&1 && echo 'Installation de rtdl_num_embeddings réussie'\n",
    "!pip install \"scikit-learn>=1.0,<2\" -qqq > /dev/null 2>&1 && echo 'Installation de scikit-learn réussie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe072d13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:37:12.861630Z",
     "iopub.status.busy": "2025-07-07T10:37:12.861372Z",
     "iopub.status.idle": "2025-07-07T10:38:41.001816Z",
     "shell.execute_reply": "2025-07-07T10:38:41.001044Z"
    },
    "papermill": {
     "duration": 88.146462,
     "end_time": "2025-07-07T10:38:41.003135",
     "exception": false,
     "start_time": "2025-07-07T10:37:12.856673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installation de libzero réussie\r\n",
      "Installation de optuna réussie\r\n"
     ]
    }
   ],
   "source": [
    "!pip install libzero==0.0.4 -qqq > /dev/null 2>&1 && echo 'Installation de libzero réussie'\n",
    "!pip install optuna -qqq > /dev/null 2>&1 && echo 'Installation de optuna réussie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb18b97",
   "metadata": {
    "papermill": {
     "duration": 0.003625,
     "end_time": "2025-07-07T10:38:41.010932",
     "exception": false,
     "start_time": "2025-07-07T10:38:41.007307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1e20cfd",
   "metadata": {
    "papermill": {
     "duration": 0.003538,
     "end_time": "2025-07-07T10:38:41.018111",
     "exception": false,
     "start_time": "2025-07-07T10:38:41.014573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modèle FT-T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b554666a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:38:41.026949Z",
     "iopub.status.busy": "2025-07-07T10:38:41.026253Z",
     "iopub.status.idle": "2025-07-07T10:39:21.436337Z",
     "shell.execute_reply": "2025-07-07T10:39:21.435558Z"
    },
    "papermill": {
     "duration": 40.416051,
     "end_time": "2025-07-07T10:39:21.437802",
     "exception": false,
     "start_time": "2025-07-07T10:38:41.021751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation du device: cuda\r\n",
      "Seed: 0\r\n",
      "Données originales: 7043 lignes\r\n",
      "Après nettoyage: 7032 lignes (11 supprimées)\r\n",
      "\r\n",
      "Informations sur les features:\r\n",
      "Features numériques (3): ['tenure', 'MonthlyCharges', 'TotalCharges']\r\n",
      "Variables catégorielles (16): ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\r\n",
      "Cardinalités des variables catégorielles: [2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4]\r\n",
      "Distribution des classes: [5163 1869]\r\n",
      "Tailles des ensembles:\r\n",
      "Train: 4781 | Val: 844 | Test: 1407\r\n",
      "Type d'embedding numérique: P-LR-LR\r\n",
      "Nombre de paramètres: 996,049\r\n",
      "\r\n",
      "=== Début de l'entraînement ===\r\n",
      "Epoch 000 | Training loss: 0.4768\r\n",
      "Epoch 000 | Validation loss: 0.4496\r\n",
      "Epoch 000 completed in 1.33s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4496)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8304, AUC-PR: 0.6034, Accuracy: 0.7868, B_ACC : 0.6544, MCC: 0.3874, Sensitivity/Recall: 0.3717, Specificity: 0.9371, Precision: 0.6814, F1-score: 0.481, CK-score 0.3611\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8304 | PR-AUC: 0.6034 | Accuracy: 0.7868\r\n",
      "  F1: 0.4810 | MCC: 0.3874 | Balanced Acc: 0.6544\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 001 | Training loss: 0.4439\r\n",
      "Epoch 001 | Validation loss: 0.4494\r\n",
      "Epoch 001 completed in 0.96s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4494)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8375, AUC-PR: 0.6219, Accuracy: 0.7811, B_ACC : 0.6343, MCC: 0.3604, Sensitivity/Recall: 0.3209, Specificity: 0.9477, Precision: 0.6897, F1-score: 0.438, CK-score 0.3238\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8375 | PR-AUC: 0.6219 | Accuracy: 0.7811\r\n",
      "  F1: 0.4380 | MCC: 0.3604 | Balanced Acc: 0.6343\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 002 | Training loss: 0.4358\r\n",
      "Epoch 002 | Validation loss: 0.4350\r\n",
      "Epoch 002 completed in 0.96s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4350)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8419, AUC-PR: 0.6388, Accuracy: 0.7889, B_ACC : 0.6447, MCC: 0.3875, Sensitivity/Recall: 0.3369, Specificity: 0.9526, Precision: 0.72, F1-score: 0.459, CK-score 0.3486\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8419 | PR-AUC: 0.6388 | Accuracy: 0.7889\r\n",
      "  F1: 0.4590 | MCC: 0.3875 | Balanced Acc: 0.6447\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 003 | Training loss: 0.4327\r\n",
      "Epoch 003 | Validation loss: 0.4221\r\n",
      "Epoch 003 completed in 0.96s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4221)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8441, AUC-PR: 0.646, Accuracy: 0.7996, B_ACC : 0.675, MCC: 0.4306, Sensitivity/Recall: 0.4091, Specificity: 0.9409, Precision: 0.715, F1-score: 0.5204, CK-score 0.4054\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8441 | PR-AUC: 0.6460 | Accuracy: 0.7996\r\n",
      "  F1: 0.5204 | MCC: 0.4306 | Balanced Acc: 0.6750\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 004 | Training loss: 0.4270\r\n",
      "Epoch 004 | Validation loss: 0.4224\r\n",
      "Epoch 004 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 005 | Training loss: 0.4267\r\n",
      "Epoch 005 | Validation loss: 0.4224\r\n",
      "Epoch 005 completed in 0.96s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 006 | Training loss: 0.4247\r\n",
      "Epoch 006 | Validation loss: 0.4240\r\n",
      "Epoch 006 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 007 | Training loss: 0.4227\r\n",
      "Epoch 007 | Validation loss: 0.4218\r\n",
      "Epoch 007 completed in 0.97s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4218)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8478, AUC-PR: 0.657, Accuracy: 0.7939, B_ACC : 0.6524, MCC: 0.405, Sensitivity/Recall: 0.3503, Specificity: 0.9545, Precision: 0.736, F1-score: 0.4747, CK-score 0.3659\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8478 | PR-AUC: 0.6570 | Accuracy: 0.7939\r\n",
      "  F1: 0.4747 | MCC: 0.4050 | Balanced Acc: 0.6524\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 008 | Training loss: 0.4225\r\n",
      "Epoch 008 | Validation loss: 0.4220\r\n",
      "Epoch 008 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 009 | Training loss: 0.4201\r\n",
      "Epoch 009 | Validation loss: 0.4232\r\n",
      "Epoch 009 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 010 | Training loss: 0.4210\r\n",
      "Epoch 010 | Validation loss: 0.4214\r\n",
      "Epoch 010 completed in 1.01s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4214)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.845, AUC-PR: 0.6537, Accuracy: 0.7982, B_ACC : 0.6681, MCC: 0.4235, Sensitivity/Recall: 0.3904, Specificity: 0.9458, Precision: 0.7228, F1-score: 0.507, CK-score 0.394\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8450 | PR-AUC: 0.6537 | Accuracy: 0.7982\r\n",
      "  F1: 0.5070 | MCC: 0.4235 | Balanced Acc: 0.6681\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 011 | Training loss: 0.4195\r\n",
      "Epoch 011 | Validation loss: 0.4235\r\n",
      "Epoch 011 completed in 0.96s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 012 | Training loss: 0.4187\r\n",
      "Epoch 012 | Validation loss: 0.4183\r\n",
      "Epoch 012 completed in 0.95s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4183)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8451, AUC-PR: 0.6549, Accuracy: 0.801, B_ACC : 0.6734, MCC: 0.4334, Sensitivity/Recall: 0.4011, Specificity: 0.9458, Precision: 0.7282, F1-score: 0.5173, CK-score 0.4049\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8451 | PR-AUC: 0.6549 | Accuracy: 0.8010\r\n",
      "  F1: 0.5173 | MCC: 0.4334 | Balanced Acc: 0.6734\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 013 | Training loss: 0.4179\r\n",
      "Epoch 013 | Validation loss: 0.4223\r\n",
      "Epoch 013 completed in 0.96s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 014 | Training loss: 0.4171\r\n",
      "Epoch 014 | Validation loss: 0.4199\r\n",
      "Epoch 014 completed in 0.95s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 015 | Training loss: 0.4153\r\n",
      "Epoch 015 | Validation loss: 0.4208\r\n",
      "Epoch 015 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 016 | Training loss: 0.4146\r\n",
      "Epoch 016 | Validation loss: 0.4184\r\n",
      "Epoch 016 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 017 | Training loss: 0.4119\r\n",
      "Epoch 017 | Validation loss: 0.4253\r\n",
      "Epoch 017 completed in 0.95s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 018 | Training loss: 0.4129\r\n",
      "Epoch 018 | Validation loss: 0.4227\r\n",
      "Epoch 018 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 019 | Training loss: 0.4099\r\n",
      "Epoch 019 | Validation loss: 0.4240\r\n",
      "Epoch 019 completed in 1.09s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 020 | Training loss: 0.4102\r\n",
      "Epoch 020 | Validation loss: 0.4224\r\n",
      "Epoch 020 completed in 1.01s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 021 | Training loss: 0.4086\r\n",
      "Epoch 021 | Validation loss: 0.4225\r\n",
      "Epoch 021 completed in 0.97s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 022 | Training loss: 0.4074\r\n",
      "Epoch 022 | Validation loss: 0.4303\r\n",
      "Epoch 022 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 023 | Training loss: 0.4083\r\n",
      "Epoch 023 | Validation loss: 0.4300\r\n",
      "Epoch 023 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 024 | Training loss: 0.4085\r\n",
      "Epoch 024 | Validation loss: 0.4244\r\n",
      "Epoch 024 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 025 | Training loss: 0.4064\r\n",
      "Epoch 025 | Validation loss: 0.4247\r\n",
      "Epoch 025 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 026 | Training loss: 0.4033\r\n",
      "Epoch 026 | Validation loss: 0.4295\r\n",
      "Epoch 026 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 027 | Training loss: 0.4032\r\n",
      "Epoch 027 | Validation loss: 0.4264\r\n",
      "Epoch 027 completed in 0.98s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 028 | Training loss: 0.4010\r\n",
      "Epoch 028 | Validation loss: 0.4298\r\n",
      "Epoch 028 completed in 0.99s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 029 | Training loss: 0.3997\r\n",
      "Epoch 029 | Validation loss: 0.4241\r\n",
      "Epoch 029 completed in 0.96s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 030 | Training loss: 0.3964\r\n",
      "Epoch 030 | Validation loss: 0.4211\r\n",
      "Epoch 030 completed in 0.96s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 031 | Training loss: 0.3963\r\n",
      "Epoch 031 | Validation loss: 0.4276\r\n",
      "Epoch 031 completed in 1.00s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 032 | Training loss: 0.3949\r\n",
      "Epoch 032 | Validation loss: 0.4321\r\n",
      "Epoch 032 completed in 0.96s\r\n",
      "\r\n",
      "Early stopping à l'époque 32 (patience: 20)\r\n",
      "\r\n",
      "Meilleur modèle chargé (époque 12, val_loss: 0.4183)\r\n",
      "\r\n",
      "=== Évaluation finale ===\r\n",
      "Performance sur l'ensemble de validation:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8342, AUC-PR: 0.6618, Accuracy: 0.8009, B_ACC : 0.7105, MCC: 0.4577, Sensitivity/Recall: 0.5179, Specificity: 0.9032, Precision: 0.6591, F1-score: 0.58, CK-score 0.452\r\n",
      "Val Performance:\r\n",
      "  ROC-AUC: 0.8342 | PR-AUC: 0.6618 | Accuracy: 0.8009\r\n",
      "  F1: 0.5800 | MCC: 0.4577 | Balanced Acc: 0.7105\r\n",
      "\r\n",
      "Performance sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8294, AUC-PR: 0.6525, Accuracy: 0.7974, B_ACC : 0.6983, MCC: 0.4418, Sensitivity/Recall: 0.4866, Specificity: 0.91, Precision: 0.6618, F1-score: 0.5608, CK-score 0.4332\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8294 | PR-AUC: 0.6525 | Accuracy: 0.7974\r\n",
      "  F1: 0.5608 | MCC: 0.4418 | Balanced Acc: 0.6983\r\n",
      "\r\n",
      "Résultats sauvegardés dans results/results_telecom/ftt/seed_0/\r\n",
      "Entraînement terminé!\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Changer vers le répertoire racine\n",
    "os.chdir('/kaggle/working/customer-churn-ft_transformer')\n",
    "\n",
    "# Utiliser PYTHONPATH pour que train.py trouve les modules\n",
    "!PYTHONPATH=/kaggle/working/customer-churn-ft_transformer python train/Telecom/train_ftt/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0ef86",
   "metadata": {
    "papermill": {
     "duration": 0.006249,
     "end_time": "2025-07-07T10:39:21.452040",
     "exception": false,
     "start_time": "2025-07-07T10:39:21.445791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc22b7",
   "metadata": {
    "papermill": {
     "duration": 0.006112,
     "end_time": "2025-07-07T10:39:21.464422",
     "exception": false,
     "start_time": "2025-07-07T10:39:21.458310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fbb279",
   "metadata": {
    "papermill": {
     "duration": 0.006107,
     "end_time": "2025-07-07T10:39:21.477211",
     "exception": false,
     "start_time": "2025-07-07T10:39:21.471104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36836be4",
   "metadata": {
    "papermill": {
     "duration": 0.00791,
     "end_time": "2025-07-07T10:39:21.491341",
     "exception": false,
     "start_time": "2025-07-07T10:39:21.483431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modèle FT-T Plus *Interprétable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11d445e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:39:21.505685Z",
     "iopub.status.busy": "2025-07-07T10:39:21.504999Z",
     "iopub.status.idle": "2025-07-07T10:41:02.974453Z",
     "shell.execute_reply": "2025-07-07T10:41:02.973519Z"
    },
    "papermill": {
     "duration": 101.478238,
     "end_time": "2025-07-07T10:41:02.975964",
     "exception": false,
     "start_time": "2025-07-07T10:39:21.497726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation du device: cuda\r\n",
      "Seed: 0\r\n",
      "Données originales: 7043 lignes\r\n",
      "Après nettoyage: 7032 lignes (11 supprimées)\r\n",
      "\r\n",
      "Informations sur les features:\r\n",
      "Features numériques (3): ['tenure', 'MonthlyCharges', 'TotalCharges']\r\n",
      "Variables catégorielles (16): ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\r\n",
      "Cardinalités des variables catégorielles: [2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4]\r\n",
      "Distribution des classes: [5163 1869]\r\n",
      "Tailles des ensembles:\r\n",
      "Train: 4781 | Val: 844 | Test: 1407\r\n",
      "Configuration du modèle:\r\n",
      "  - Features numériques: 3\r\n",
      "  - Features catégorielles: 16 (cardinalités: [2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4])\r\n",
      "  - Taille des tokens: 64\r\n",
      "Type d'embedding numérique: P-LR-LR\r\n",
      "Nombre de paramètres: 102,289\r\n",
      "\r\n",
      "=== Début de l'entraînement ===\r\n",
      "Epoch 000 | Training loss: 0.4832\r\n",
      "Epoch 000 | Validation loss: 0.4432\r\n",
      "Epoch 000 completed in 2.14s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4432)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.838, AUC-PR: 0.6425, Accuracy: 0.7918, B_ACC : 0.6475, MCC: 0.3969, Sensitivity/Recall: 0.3396, Specificity: 0.9555, Precision: 0.7341, F1-score: 0.4644, CK-score 0.3561\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8380 | PR-AUC: 0.6425 | Accuracy: 0.7918\r\n",
      "  F1: 0.4644 | MCC: 0.3969 | Balanced Acc: 0.6475\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 001 | Training loss: 0.4504\r\n",
      "Epoch 001 | Validation loss: 0.4381\r\n",
      "Epoch 001 completed in 1.83s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4381)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8357, AUC-PR: 0.6341, Accuracy: 0.791, B_ACC : 0.653, MCC: 0.3973, Sensitivity/Recall: 0.3583, Specificity: 0.9477, Precision: 0.7128, F1-score: 0.4769, CK-score 0.3637\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8357 | PR-AUC: 0.6341 | Accuracy: 0.7910\r\n",
      "  F1: 0.4769 | MCC: 0.3973 | Balanced Acc: 0.6530\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 002 | Training loss: 0.4452\r\n",
      "Epoch 002 | Validation loss: 0.4611\r\n",
      "Epoch 002 completed in 1.82s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 003 | Training loss: 0.4466\r\n",
      "Epoch 003 | Validation loss: 0.4342\r\n",
      "Epoch 003 completed in 1.82s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4342)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8467, AUC-PR: 0.6338, Accuracy: 0.7754, B_ACC : 0.6202, MCC: 0.3363, Sensitivity/Recall: 0.2888, Specificity: 0.9516, Precision: 0.6835, F1-score: 0.406, CK-score 0.2946\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8467 | PR-AUC: 0.6338 | Accuracy: 0.7754\r\n",
      "  F1: 0.4060 | MCC: 0.3363 | Balanced Acc: 0.6202\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 004 | Training loss: 0.4393\r\n",
      "Epoch 004 | Validation loss: 0.4241\r\n",
      "Epoch 004 completed in 1.82s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4241)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8453, AUC-PR: 0.6401, Accuracy: 0.7889, B_ACC : 0.655, MCC: 0.3929, Sensitivity/Recall: 0.369, Specificity: 0.9409, Precision: 0.6935, F1-score: 0.4817, CK-score 0.3643\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8453 | PR-AUC: 0.6401 | Accuracy: 0.7889\r\n",
      "  F1: 0.4817 | MCC: 0.3929 | Balanced Acc: 0.6550\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 005 | Training loss: 0.4359\r\n",
      "Epoch 005 | Validation loss: 0.4246\r\n",
      "Epoch 005 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 006 | Training loss: 0.4377\r\n",
      "Epoch 006 | Validation loss: 0.4290\r\n",
      "Epoch 006 completed in 1.77s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 007 | Training loss: 0.4390\r\n",
      "Epoch 007 | Validation loss: 0.4242\r\n",
      "Epoch 007 completed in 1.93s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 008 | Training loss: 0.4391\r\n",
      "Epoch 008 | Validation loss: 0.4234\r\n",
      "Epoch 008 completed in 1.81s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4234)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8391, AUC-PR: 0.6276, Accuracy: 0.806, B_ACC : 0.716, MCC: 0.4713, Sensitivity/Recall: 0.5241, Specificity: 0.908, Precision: 0.6735, F1-score: 0.5895, CK-score 0.465\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8391 | PR-AUC: 0.6276 | Accuracy: 0.8060\r\n",
      "  F1: 0.5895 | MCC: 0.4713 | Balanced Acc: 0.7160\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 009 | Training loss: 0.4349\r\n",
      "Epoch 009 | Validation loss: 0.4177\r\n",
      "Epoch 009 completed in 1.80s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4177)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8438, AUC-PR: 0.6327, Accuracy: 0.8045, B_ACC : 0.7057, MCC: 0.4609, Sensitivity/Recall: 0.4947, Specificity: 0.9167, Precision: 0.6827, F1-score: 0.5737, CK-score 0.451\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8438 | PR-AUC: 0.6327 | Accuracy: 0.8045\r\n",
      "  F1: 0.5737 | MCC: 0.4609 | Balanced Acc: 0.7057\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 010 | Training loss: 0.4317\r\n",
      "Epoch 010 | Validation loss: 0.4184\r\n",
      "Epoch 010 completed in 1.79s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 011 | Training loss: 0.4318\r\n",
      "Epoch 011 | Validation loss: 0.4181\r\n",
      "Epoch 011 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 012 | Training loss: 0.4341\r\n",
      "Epoch 012 | Validation loss: 0.4192\r\n",
      "Epoch 012 completed in 1.84s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 013 | Training loss: 0.4352\r\n",
      "Epoch 013 | Validation loss: 0.4186\r\n",
      "Epoch 013 completed in 1.79s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 014 | Training loss: 0.4313\r\n",
      "Epoch 014 | Validation loss: 0.4246\r\n",
      "Epoch 014 completed in 1.80s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 015 | Training loss: 0.4335\r\n",
      "Epoch 015 | Validation loss: 0.4242\r\n",
      "Epoch 015 completed in 1.82s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 016 | Training loss: 0.4287\r\n",
      "Epoch 016 | Validation loss: 0.4241\r\n",
      "Epoch 016 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 017 | Training loss: 0.4270\r\n",
      "Epoch 017 | Validation loss: 0.4190\r\n",
      "Epoch 017 completed in 1.80s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 018 | Training loss: 0.4325\r\n",
      "Epoch 018 | Validation loss: 0.4158\r\n",
      "Epoch 018 completed in 1.82s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4158)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8408, AUC-PR: 0.6424, Accuracy: 0.8053, B_ACC : 0.7147, MCC: 0.469, Sensitivity/Recall: 0.5214, Specificity: 0.908, Precision: 0.6724, F1-score: 0.5874, CK-score 0.4626\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8408 | PR-AUC: 0.6424 | Accuracy: 0.8053\r\n",
      "  F1: 0.5874 | MCC: 0.4690 | Balanced Acc: 0.7147\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 019 | Training loss: 0.4276\r\n",
      "Epoch 019 | Validation loss: 0.4202\r\n",
      "Epoch 019 completed in 1.79s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 020 | Training loss: 0.4282\r\n",
      "Epoch 020 | Validation loss: 0.4220\r\n",
      "Epoch 020 completed in 1.80s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 021 | Training loss: 0.4319\r\n",
      "Epoch 021 | Validation loss: 0.4219\r\n",
      "Epoch 021 completed in 1.77s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 022 | Training loss: 0.4251\r\n",
      "Epoch 022 | Validation loss: 0.4217\r\n",
      "Epoch 022 completed in 1.77s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 023 | Training loss: 0.4265\r\n",
      "Epoch 023 | Validation loss: 0.4171\r\n",
      "Epoch 023 completed in 1.77s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 024 | Training loss: 0.4261\r\n",
      "Epoch 024 | Validation loss: 0.4281\r\n",
      "Epoch 024 completed in 1.95s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 025 | Training loss: 0.4262\r\n",
      "Epoch 025 | Validation loss: 0.4302\r\n",
      "Epoch 025 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 026 | Training loss: 0.4243\r\n",
      "Epoch 026 | Validation loss: 0.4257\r\n",
      "Epoch 026 completed in 1.80s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 027 | Training loss: 0.4257\r\n",
      "Epoch 027 | Validation loss: 0.4220\r\n",
      "Epoch 027 completed in 1.79s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 028 | Training loss: 0.4289\r\n",
      "Epoch 028 | Validation loss: 0.4177\r\n",
      "Epoch 028 completed in 1.78s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 029 | Training loss: 0.4229\r\n",
      "Epoch 029 | Validation loss: 0.4178\r\n",
      "Epoch 029 completed in 1.85s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 030 | Training loss: 0.4235\r\n",
      "Epoch 030 | Validation loss: 0.4128\r\n",
      "Epoch 030 completed in 1.83s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4128)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8428, AUC-PR: 0.6545, Accuracy: 0.8053, B_ACC : 0.7224, MCC: 0.4752, Sensitivity/Recall: 0.5455, Specificity: 0.8993, Precision: 0.6623, F1-score: 0.5983, CK-score 0.4713\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8428 | PR-AUC: 0.6545 | Accuracy: 0.8053\r\n",
      "  F1: 0.5983 | MCC: 0.4752 | Balanced Acc: 0.7224\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 031 | Training loss: 0.4223\r\n",
      "Epoch 031 | Validation loss: 0.4121\r\n",
      "Epoch 031 completed in 1.81s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4121)\r\n",
      " >>> Évaluation sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8446, AUC-PR: 0.6562, Accuracy: 0.8031, B_ACC : 0.7116, MCC: 0.4627, Sensitivity/Recall: 0.516, Specificity: 0.9071, Precision: 0.6678, F1-score: 0.5822, CK-score 0.4562\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8446 | PR-AUC: 0.6562 | Accuracy: 0.8031\r\n",
      "  F1: 0.5822 | MCC: 0.4627 | Balanced Acc: 0.7116\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 032 | Training loss: 0.4242\r\n",
      "Epoch 032 | Validation loss: 0.4193\r\n",
      "Epoch 032 completed in 1.79s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 033 | Training loss: 0.4229\r\n",
      "Epoch 033 | Validation loss: 0.4227\r\n",
      "Epoch 033 completed in 1.77s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 034 | Training loss: 0.4273\r\n",
      "Epoch 034 | Validation loss: 0.4290\r\n",
      "Epoch 034 completed in 1.80s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 035 | Training loss: 0.4262\r\n",
      "Epoch 035 | Validation loss: 0.4155\r\n",
      "Epoch 035 completed in 1.86s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 036 | Training loss: 0.4238\r\n",
      "Epoch 036 | Validation loss: 0.4123\r\n",
      "Epoch 036 completed in 1.82s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 037 | Training loss: 0.4181\r\n",
      "Epoch 037 | Validation loss: 0.4190\r\n",
      "Epoch 037 completed in 1.84s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 038 | Training loss: 0.4219\r\n",
      "Epoch 038 | Validation loss: 0.4186\r\n",
      "Epoch 038 completed in 1.82s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 039 | Training loss: 0.4179\r\n",
      "Epoch 039 | Validation loss: 0.4271\r\n",
      "Epoch 039 completed in 1.82s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 040 | Training loss: 0.4233\r\n",
      "Epoch 040 | Validation loss: 0.4205\r\n",
      "Epoch 040 completed in 1.84s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 041 | Training loss: 0.4196\r\n",
      "Epoch 041 | Validation loss: 0.4224\r\n",
      "Epoch 041 completed in 1.79s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 042 | Training loss: 0.4220\r\n",
      "Epoch 042 | Validation loss: 0.4171\r\n",
      "Epoch 042 completed in 1.95s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 043 | Training loss: 0.4204\r\n",
      "Epoch 043 | Validation loss: 0.4236\r\n",
      "Epoch 043 completed in 1.82s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 044 | Training loss: 0.4185\r\n",
      "Epoch 044 | Validation loss: 0.4175\r\n",
      "Epoch 044 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 045 | Training loss: 0.4158\r\n",
      "Epoch 045 | Validation loss: 0.4347\r\n",
      "Epoch 045 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 046 | Training loss: 0.4187\r\n",
      "Epoch 046 | Validation loss: 0.4307\r\n",
      "Epoch 046 completed in 1.83s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 047 | Training loss: 0.4158\r\n",
      "Epoch 047 | Validation loss: 0.4305\r\n",
      "Epoch 047 completed in 1.79s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 048 | Training loss: 0.4157\r\n",
      "Epoch 048 | Validation loss: 0.4361\r\n",
      "Epoch 048 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 049 | Training loss: 0.4152\r\n",
      "Epoch 049 | Validation loss: 0.4364\r\n",
      "Epoch 049 completed in 1.81s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 050 | Training loss: 0.4132\r\n",
      "Epoch 050 | Validation loss: 0.4326\r\n",
      "Epoch 050 completed in 1.82s\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch 051 | Training loss: 0.4141\r\n",
      "Epoch 051 | Validation loss: 0.4249\r\n",
      "Epoch 051 completed in 1.85s\r\n",
      "\r\n",
      "Early stopping à l'époque 51 (patience: 20)\r\n",
      "\r\n",
      "Meilleur modèle chargé (époque 31, val_loss: 0.4121)\r\n",
      "\r\n",
      "=== Évaluation finale ===\r\n",
      "Performance sur l'ensemble de validation:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.8407, AUC-PR: 0.6552, Accuracy: 0.8021, B_ACC : 0.7413, MCC: 0.4876, Sensitivity/Recall: 0.6116, Specificity: 0.871, Precision: 0.6313, F1-score: 0.6213, CK-score 0.4874\r\n",
      "Val Performance:\r\n",
      "  ROC-AUC: 0.8407 | PR-AUC: 0.6552 | Accuracy: 0.8021\r\n",
      "  F1: 0.6213 | MCC: 0.4876 | Balanced Acc: 0.7413\r\n",
      "\r\n",
      "Performance sur l'ensemble de test:\r\n",
      "Performance for test_dataset\r\n",
      "AUC-ROC: 0.836, AUC-PR: 0.6357, Accuracy: 0.7989, B_ACC : 0.73, MCC: 0.4723, Sensitivity/Recall: 0.5829, Specificity: 0.8771, Precision: 0.6319, F1-score: 0.6064, CK-score 0.4716\r\n",
      "Test Performance:\r\n",
      "  ROC-AUC: 0.8360 | PR-AUC: 0.6357 | Accuracy: 0.7989\r\n",
      "  F1: 0.6064 | MCC: 0.4723 | Balanced Acc: 0.7300\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. MonthlyCharges      : 0.0549\r\n",
      "   2. tenure              : 0.0539\r\n",
      "   3. DeviceProtection    : 0.0532\r\n",
      "   4. PaperlessBilling    : 0.0531\r\n",
      "   5. gender              : 0.0529\r\n",
      "   6. OnlineBackup        : 0.0527\r\n",
      "   7. TotalCharges        : 0.0526\r\n",
      "   8. StreamingMovies     : 0.0526\r\n",
      "   9. MultipleLines       : 0.0525\r\n",
      "  10. InternetService     : 0.0524\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus/seed_0/heatmaps/interpretable_ftt_plus_importance_seed_0.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus/seed_0/interpretable_ftt_plus_metrics_seed_0.json\r\n",
      "Importance: results/results_telecom/ftt_plus/seed_0/interpretable_ftt_plus_importance_seed_0.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus/seed_0/interpretable_ftt_plus_{importance|attention}_seed_0.png\r\n",
      "Modèle: results/results_telecom/ftt_plus/seed_0/interpretable_ftt_plus_weights_seed_0.pt\r\n",
      "Entraînement terminé!\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Changer vers le répertoire racine\n",
    "os.chdir('/kaggle/working/customer-churn-ft_transformer')\n",
    "\n",
    "# Utiliser PYTHONPATH pour que train.py trouve les modules\n",
    "!PYTHONPATH=/kaggle/working/customer-churn-ft_transformer python train/Telecom/train_ftt_plus/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf8f41",
   "metadata": {
    "papermill": {
     "duration": 0.010453,
     "end_time": "2025-07-07T10:41:02.997621",
     "exception": false,
     "start_time": "2025-07-07T10:41:02.987168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c4425e",
   "metadata": {
    "papermill": {
     "duration": 0.010366,
     "end_time": "2025-07-07T10:41:03.018791",
     "exception": false,
     "start_time": "2025-07-07T10:41:03.008425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d7ffa2",
   "metadata": {
    "papermill": {
     "duration": 0.010454,
     "end_time": "2025-07-07T10:41:03.039732",
     "exception": false,
     "start_time": "2025-07-07T10:41:03.029278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02b7c5ea",
   "metadata": {
    "papermill": {
     "duration": 0.010585,
     "end_time": "2025-07-07T10:41:03.060937",
     "exception": false,
     "start_time": "2025-07-07T10:41:03.050352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modèle FT-T Plus Plus *Interprétable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91311135",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:41:03.083606Z",
     "iopub.status.busy": "2025-07-07T10:41:03.082974Z",
     "iopub.status.idle": "2025-07-07T10:44:22.266946Z",
     "shell.execute_reply": "2025-07-07T10:44:22.265784Z"
    },
    "papermill": {
     "duration": 199.197242,
     "end_time": "2025-07-07T10:44:22.268649",
     "exception": false,
     "start_time": "2025-07-07T10:41:03.071407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENTRAÎNEMENT FTT++ MODULAIRE - DATASET TELECOM ===\r\n",
      "GPU détecté: Tesla P100-PCIE-16GB (17.1GB)\r\n",
      "Device sélectionné: cuda\r\n",
      "Chargement des données (seed: 0)\r\n",
      "Données originales: 7043 lignes\r\n",
      "Après nettoyage: 7032 lignes (11 supprimées)\r\n",
      "\r\n",
      "Informations sur les features:\r\n",
      "Features numériques (3): ['tenure', 'MonthlyCharges', 'TotalCharges']\r\n",
      "Variables catégorielles (16): ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\r\n",
      "Cardinalités des variables catégorielles: [2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4]\r\n",
      "Distribution des classes: [5163 1869]\r\n",
      "Tailles des ensembles:\r\n",
      "Train: 4781 | Val: 844 | Test: 1407\r\n",
      "Features numériques: 3\r\n",
      "Features catégorielles: 16\r\n",
      "Échantillons: train=4781, val=844, test=1407\r\n",
      "🚀 === PIPELINE FTT++ COMPLET ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "🚀 === ÉTAPE 1: Entraînement FTT+ Complet ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "✅ Validation mapping: 3 num + 16 cat = 19 total\r\n",
      "Type d'embedding numérique: LR\r\n",
      "Modèle FTT+ créé avec 88,001 paramètres\r\n",
      "⏳ Entraînement du modèle FTT+ en cours...\r\n",
      "Epoch 000 | Train Loss: 0.4783 | Val Loss: 0.4401 | Time: 2.10s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4401)\r\n",
      "Epoch 001 | Train Loss: 0.4435 | Val Loss: 0.4409 | Time: 1.74s\r\n",
      "Epoch 002 | Train Loss: 0.4458 | Val Loss: 0.4431 | Time: 1.75s\r\n",
      "Epoch 003 | Train Loss: 0.4432 | Val Loss: 0.4384 | Time: 1.97s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4384)\r\n",
      "Epoch 004 | Train Loss: 0.4369 | Val Loss: 0.4260 | Time: 1.75s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4260)\r\n",
      "Epoch 005 | Train Loss: 0.4387 | Val Loss: 0.4185 | Time: 1.75s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4185)\r\n",
      "Epoch 006 | Train Loss: 0.4383 | Val Loss: 0.4188 | Time: 1.80s\r\n",
      "Epoch 007 | Train Loss: 0.4353 | Val Loss: 0.4217 | Time: 1.75s\r\n",
      "Epoch 008 | Train Loss: 0.4333 | Val Loss: 0.4095 | Time: 1.78s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4095)\r\n",
      "Epoch 009 | Train Loss: 0.4291 | Val Loss: 0.4254 | Time: 1.77s\r\n",
      "Epoch 010 | Train Loss: 0.4371 | Val Loss: 0.4224 | Time: 1.80s\r\n",
      "Epoch 011 | Train Loss: 0.4312 | Val Loss: 0.4175 | Time: 1.78s\r\n",
      "Epoch 012 | Train Loss: 0.4291 | Val Loss: 0.4164 | Time: 1.81s\r\n",
      "Epoch 013 | Train Loss: 0.4297 | Val Loss: 0.4182 | Time: 1.76s\r\n",
      "Epoch 014 | Train Loss: 0.4246 | Val Loss: 0.4256 | Time: 1.79s\r\n",
      "Epoch 015 | Train Loss: 0.4289 | Val Loss: 0.4170 | Time: 1.75s\r\n",
      "Epoch 016 | Train Loss: 0.4309 | Val Loss: 0.4134 | Time: 1.74s\r\n",
      "Epoch 017 | Train Loss: 0.4227 | Val Loss: 0.4137 | Time: 1.78s\r\n",
      "Epoch 018 | Train Loss: 0.4278 | Val Loss: 0.4097 | Time: 1.74s\r\n",
      "Epoch 019 | Train Loss: 0.4265 | Val Loss: 0.4185 | Time: 1.73s\r\n",
      "Epoch 020 | Train Loss: 0.4239 | Val Loss: 0.4156 | Time: 1.81s\r\n",
      "Epoch 021 | Train Loss: 0.4268 | Val Loss: 0.4089 | Time: 1.76s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4089)\r\n",
      "Epoch 022 | Train Loss: 0.4202 | Val Loss: 0.4198 | Time: 1.72s\r\n",
      "Epoch 023 | Train Loss: 0.4228 | Val Loss: 0.4204 | Time: 1.76s\r\n",
      "Epoch 024 | Train Loss: 0.4271 | Val Loss: 0.4112 | Time: 1.72s\r\n",
      "Epoch 025 | Train Loss: 0.4223 | Val Loss: 0.4146 | Time: 1.72s\r\n",
      "Epoch 026 | Train Loss: 0.4203 | Val Loss: 0.4200 | Time: 1.75s\r\n",
      "Epoch 027 | Train Loss: 0.4239 | Val Loss: 0.4151 | Time: 1.73s\r\n",
      "Epoch 028 | Train Loss: 0.4186 | Val Loss: 0.4263 | Time: 1.73s\r\n",
      "Epoch 029 | Train Loss: 0.4232 | Val Loss: 0.4137 | Time: 1.77s\r\n",
      "Epoch 030 | Train Loss: 0.4239 | Val Loss: 0.4236 | Time: 1.74s\r\n",
      "Epoch 031 | Train Loss: 0.4264 | Val Loss: 0.4242 | Time: 1.73s\r\n",
      "Epoch 032 | Train Loss: 0.4207 | Val Loss: 0.4200 | Time: 1.73s\r\n",
      "Epoch 033 | Train Loss: 0.4224 | Val Loss: 0.4223 | Time: 1.73s\r\n",
      "Epoch 034 | Train Loss: 0.4267 | Val Loss: 0.4240 | Time: 1.77s\r\n",
      "Epoch 035 | Train Loss: 0.4245 | Val Loss: 0.4217 | Time: 1.75s\r\n",
      "Epoch 036 | Train Loss: 0.4201 | Val Loss: 0.4197 | Time: 1.74s\r\n",
      "Epoch 037 | Train Loss: 0.4248 | Val Loss: 0.4121 | Time: 1.76s\r\n",
      "Epoch 038 | Train Loss: 0.4209 | Val Loss: 0.4230 | Time: 1.79s\r\n",
      "Epoch 039 | Train Loss: 0.4211 | Val Loss: 0.4126 | Time: 1.77s\r\n",
      "Epoch 040 | Train Loss: 0.4212 | Val Loss: 0.4092 | Time: 1.77s\r\n",
      "Epoch 041 | Train Loss: 0.4206 | Val Loss: 0.4225 | Time: 1.76s\r\n",
      "\r\n",
      "Early stopping à l'époque 41 (patience: 20)\r\n",
      "✅ Meilleur modèle chargé (époque 21, val_loss: 0.4089)\r\n",
      "\r\n",
      "📊 Évaluation finale du modèle FTT+...\r\n",
      "\r\n",
      "🔍 Analyse d'interprétabilité avec interpretability_analyzer...\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. PaperlessBilling    : 0.0532\r\n",
      "   2. PhoneService        : 0.0529\r\n",
      "   3. Partner             : 0.0529\r\n",
      "   4. Contract            : 0.0529\r\n",
      "   5. TechSupport         : 0.0527\r\n",
      "   6. InternetService     : 0.0527\r\n",
      "   7. OnlineBackup        : 0.0527\r\n",
      "   8. TotalCharges        : 0.0527\r\n",
      "   9. SeniorCitizen       : 0.0527\r\n",
      "  10. DeviceProtection    : 0.0526\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus_plus/seed_0/heatmaps/interpretable_ftt_plus_from_ftt_plus_plus_importance_seed_0.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_metrics_seed_0.json\r\n",
      "Importance: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_importance_seed_0.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_{importance|attention}_seed_0.png\r\n",
      "Modèle: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_weights_seed_0.pt\r\n",
      "\r\n",
      "🎯 Sélection des 10 features les plus importantes...\r\n",
      "📋 Features sélectionnées:\r\n",
      "   1. PaperlessBilling     (CAT): 0.0532\r\n",
      "   2. PhoneService         (CAT): 0.0529\r\n",
      "   3. Partner              (CAT): 0.0529\r\n",
      "   4. Contract             (CAT): 0.0529\r\n",
      "   5. TechSupport          (CAT): 0.0527\r\n",
      "   6. InternetService      (CAT): 0.0527\r\n",
      "   7. OnlineBackup         (CAT): 0.0527\r\n",
      "   8. TotalCharges         (NUM): 0.0527\r\n",
      "   9. SeniorCitizen        (CAT): 0.0527\r\n",
      "  10. DeviceProtection     (CAT): 0.0526\r\n",
      "\r\n",
      "🎯 === ÉTAPE 2: Entraînement Modèle Random ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "📋 Mapping des features sélectionnées:\r\n",
      "   - Numériques sélectionnées: ['TotalCharges'] → indices [2]\r\n",
      "   - Catégorielles sélectionnées: ['PaperlessBilling', 'PhoneService', 'Partner', 'Contract', 'TechSupport', 'InternetService', 'OnlineBackup', 'SeniorCitizen', 'DeviceProtection'] → indices [14, 4, 2, 13, 10, 6, 8, 1, 9]\r\n",
      "📊 Features sélectionnées: 1 numériques, 9 catégorielles\r\n",
      "🎲 Interactions aléatoires: 5 paires\r\n",
      "Modèle Random créé avec 86,017 paramètres\r\n",
      "🔗 Sparsité d'attention: 75.21%\r\n",
      "   - Connexions feature-feature: 10\r\n",
      "⏳ Entraînement du modèle Random en cours...\r\n",
      "Epoch 000 | Train Loss: 0.4850 | Val Loss: 0.4638 | Time: 1.61s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4638)\r\n",
      "Epoch 001 | Train Loss: 0.4504 | Val Loss: 0.4404 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4404)\r\n",
      "Epoch 002 | Train Loss: 0.4451 | Val Loss: 0.4344 | Time: 1.61s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4344)\r\n",
      "Epoch 003 | Train Loss: 0.4417 | Val Loss: 0.4348 | Time: 1.67s\r\n",
      "Epoch 004 | Train Loss: 0.4390 | Val Loss: 0.4259 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4259)\r\n",
      "Epoch 005 | Train Loss: 0.4393 | Val Loss: 0.4297 | Time: 1.63s\r\n",
      "Epoch 006 | Train Loss: 0.4396 | Val Loss: 0.4277 | Time: 1.66s\r\n",
      "Epoch 007 | Train Loss: 0.4375 | Val Loss: 0.4288 | Time: 1.67s\r\n",
      "Epoch 008 | Train Loss: 0.4347 | Val Loss: 0.4297 | Time: 1.64s\r\n",
      "Epoch 009 | Train Loss: 0.4360 | Val Loss: 0.4259 | Time: 1.67s\r\n",
      "Epoch 010 | Train Loss: 0.4345 | Val Loss: 0.4235 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4235)\r\n",
      "Epoch 011 | Train Loss: 0.4361 | Val Loss: 0.4264 | Time: 1.65s\r\n",
      "Epoch 012 | Train Loss: 0.4355 | Val Loss: 0.4235 | Time: 1.61s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4235)\r\n",
      "Epoch 013 | Train Loss: 0.4335 | Val Loss: 0.4228 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4228)\r\n",
      "Epoch 014 | Train Loss: 0.4315 | Val Loss: 0.4247 | Time: 1.62s\r\n",
      "Epoch 015 | Train Loss: 0.4335 | Val Loss: 0.4225 | Time: 1.79s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4225)\r\n",
      "Epoch 016 | Train Loss: 0.4330 | Val Loss: 0.4222 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4222)\r\n",
      "Epoch 017 | Train Loss: 0.4325 | Val Loss: 0.4219 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4219)\r\n",
      "Epoch 018 | Train Loss: 0.4327 | Val Loss: 0.4232 | Time: 1.64s\r\n",
      "Epoch 019 | Train Loss: 0.4309 | Val Loss: 0.4252 | Time: 1.63s\r\n",
      "Epoch 020 | Train Loss: 0.4332 | Val Loss: 0.4267 | Time: 1.64s\r\n",
      "Epoch 021 | Train Loss: 0.4313 | Val Loss: 0.4223 | Time: 1.64s\r\n",
      "Epoch 022 | Train Loss: 0.4314 | Val Loss: 0.4247 | Time: 1.67s\r\n",
      "Epoch 023 | Train Loss: 0.4326 | Val Loss: 0.4243 | Time: 1.62s\r\n",
      "Epoch 024 | Train Loss: 0.4320 | Val Loss: 0.4248 | Time: 1.64s\r\n",
      "Epoch 025 | Train Loss: 0.4302 | Val Loss: 0.4235 | Time: 1.64s\r\n",
      "Epoch 026 | Train Loss: 0.4315 | Val Loss: 0.4249 | Time: 1.64s\r\n",
      "Epoch 027 | Train Loss: 0.4283 | Val Loss: 0.4250 | Time: 1.65s\r\n",
      "Epoch 028 | Train Loss: 0.4274 | Val Loss: 0.4211 | Time: 1.69s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4211)\r\n",
      "Epoch 029 | Train Loss: 0.4333 | Val Loss: 0.4225 | Time: 1.65s\r\n",
      "Epoch 030 | Train Loss: 0.4295 | Val Loss: 0.4238 | Time: 1.66s\r\n",
      "Epoch 031 | Train Loss: 0.4285 | Val Loss: 0.4224 | Time: 1.65s\r\n",
      "Epoch 032 | Train Loss: 0.4289 | Val Loss: 0.4229 | Time: 1.65s\r\n",
      "Epoch 033 | Train Loss: 0.4308 | Val Loss: 0.4238 | Time: 1.63s\r\n",
      "Epoch 034 | Train Loss: 0.4311 | Val Loss: 0.4238 | Time: 1.78s\r\n",
      "Epoch 035 | Train Loss: 0.4291 | Val Loss: 0.4257 | Time: 1.64s\r\n",
      "Epoch 036 | Train Loss: 0.4305 | Val Loss: 0.4228 | Time: 1.66s\r\n",
      "Epoch 037 | Train Loss: 0.4314 | Val Loss: 0.4190 | Time: 1.61s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4190)\r\n",
      "Epoch 038 | Train Loss: 0.4297 | Val Loss: 0.4218 | Time: 1.61s\r\n",
      "Epoch 039 | Train Loss: 0.4298 | Val Loss: 0.4201 | Time: 1.62s\r\n",
      "Epoch 040 | Train Loss: 0.4299 | Val Loss: 0.4223 | Time: 1.64s\r\n",
      "Epoch 041 | Train Loss: 0.4314 | Val Loss: 0.4229 | Time: 1.62s\r\n",
      "Epoch 042 | Train Loss: 0.4279 | Val Loss: 0.4225 | Time: 1.65s\r\n",
      "Epoch 043 | Train Loss: 0.4320 | Val Loss: 0.4201 | Time: 1.64s\r\n",
      "Epoch 044 | Train Loss: 0.4281 | Val Loss: 0.4193 | Time: 1.65s\r\n",
      "Epoch 045 | Train Loss: 0.4298 | Val Loss: 0.4235 | Time: 1.63s\r\n",
      "Epoch 046 | Train Loss: 0.4288 | Val Loss: 0.4217 | Time: 1.69s\r\n",
      "Epoch 047 | Train Loss: 0.4279 | Val Loss: 0.4220 | Time: 1.65s\r\n",
      "Epoch 048 | Train Loss: 0.4288 | Val Loss: 0.4221 | Time: 1.65s\r\n",
      "Epoch 049 | Train Loss: 0.4289 | Val Loss: 0.4179 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4179)\r\n",
      "Epoch 050 | Train Loss: 0.4304 | Val Loss: 0.4166 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4166)\r\n",
      "Epoch 051 | Train Loss: 0.4279 | Val Loss: 0.4185 | Time: 1.64s\r\n",
      "Epoch 052 | Train Loss: 0.4300 | Val Loss: 0.4179 | Time: 1.69s\r\n",
      "Epoch 053 | Train Loss: 0.4282 | Val Loss: 0.4221 | Time: 1.69s\r\n",
      "Epoch 054 | Train Loss: 0.4279 | Val Loss: 0.4185 | Time: 1.60s\r\n",
      "Epoch 055 | Train Loss: 0.4294 | Val Loss: 0.4204 | Time: 1.61s\r\n",
      "Epoch 056 | Train Loss: 0.4274 | Val Loss: 0.4197 | Time: 1.61s\r\n",
      "Epoch 057 | Train Loss: 0.4257 | Val Loss: 0.4229 | Time: 1.61s\r\n",
      "Epoch 058 | Train Loss: 0.4257 | Val Loss: 0.4228 | Time: 1.66s\r\n",
      "Epoch 059 | Train Loss: 0.4260 | Val Loss: 0.4231 | Time: 1.63s\r\n",
      "Epoch 060 | Train Loss: 0.4275 | Val Loss: 0.4216 | Time: 1.63s\r\n",
      "Epoch 061 | Train Loss: 0.4298 | Val Loss: 0.4262 | Time: 1.65s\r\n",
      "Epoch 062 | Train Loss: 0.4293 | Val Loss: 0.4245 | Time: 1.63s\r\n",
      "Epoch 063 | Train Loss: 0.4288 | Val Loss: 0.4220 | Time: 1.61s\r\n",
      "Epoch 064 | Train Loss: 0.4302 | Val Loss: 0.4232 | Time: 1.66s\r\n",
      "Epoch 065 | Train Loss: 0.4259 | Val Loss: 0.4217 | Time: 1.63s\r\n",
      "Epoch 066 | Train Loss: 0.4280 | Val Loss: 0.4236 | Time: 1.63s\r\n",
      "Epoch 067 | Train Loss: 0.4306 | Val Loss: 0.4229 | Time: 1.65s\r\n",
      "Epoch 068 | Train Loss: 0.4283 | Val Loss: 0.4207 | Time: 1.62s\r\n",
      "Epoch 069 | Train Loss: 0.4289 | Val Loss: 0.4217 | Time: 1.64s\r\n",
      "Epoch 070 | Train Loss: 0.4320 | Val Loss: 0.4179 | Time: 1.66s\r\n",
      "\r\n",
      "Early stopping à l'époque 70 (patience: 20)\r\n",
      "✅ Meilleur modèle Random chargé (époque 50, val_loss: 0.4166)\r\n",
      "\r\n",
      "📊 Évaluation finale du modèle Random...\r\n",
      "\r\n",
      "🔍 Analyse d'importance des features dans le modèle Random...\r\n",
      "\r\n",
      "📊 Importance des features dans le modèle Random:\r\n",
      "   1. TechSupport          (CAT): 0.1969\r\n",
      "   2. OnlineBackup         (CAT): 0.1559\r\n",
      "   3. InternetService      (CAT): 0.1099\r\n",
      "   4. DeviceProtection     (CAT): 0.0960\r\n",
      "   5. PaperlessBilling     (CAT): 0.0835\r\n",
      "   6. Contract             (CAT): 0.0801\r\n",
      "   7. Partner              (CAT): 0.0769\r\n",
      "   8. PhoneService         (CAT): 0.0764\r\n",
      "   9. SeniorCitizen        (CAT): 0.0755\r\n",
      "  10. TotalCharges         (NUM): 0.0490\r\n",
      "\r\n",
      "🔍 Analyse d'interprétabilité complète du modèle Random...\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. TechSupport         : 0.1969\r\n",
      "   2. OnlineBackup        : 0.1559\r\n",
      "   3. InternetService     : 0.1099\r\n",
      "   4. DeviceProtection    : 0.0960\r\n",
      "   5. PaperlessBilling    : 0.0835\r\n",
      "   6. Contract            : 0.0801\r\n",
      "   7. Partner             : 0.0769\r\n",
      "   8. PhoneService        : 0.0764\r\n",
      "   9. SeniorCitizen       : 0.0755\r\n",
      "  10. TotalCharges        : 0.0490\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus_plus/seed_0/heatmaps/interpretable_ftt_plus_plus_importance_seed_0.png\r\n",
      "Heatmap d'attention sparse sauvegardée: results/results_telecom/ftt_plus_plus/seed_0/heatmaps/interpretable_ftt_plus_plus_attention_seed_0.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_metrics_seed_0.json\r\n",
      "Importance: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_importance_seed_0.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_{importance|attention}_seed_0.png\r\n",
      "Modèle: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_weights_seed_0.pt\r\n",
      "💾 Résultats complets sauvegardés: results/results_telecom/ftt_plus_plus/seed_0/métriques/ftt_plus_plus_results.json\r\n",
      "\r\n",
      "✅ === PIPELINE TERMINÉ EN 194.3s ===\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Changer vers le répertoire racine\n",
    "os.chdir('/kaggle/working/customer-churn-ft_transformer')\n",
    "\n",
    "# Embedding par défaut (LR)\n",
    "!PYTHONPATH=/kaggle/working/customer-churn-ft_transformer python train/Telecom/train_ftt_plus_plus/train.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "495c897b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:44:22.302630Z",
     "iopub.status.busy": "2025-07-07T10:44:22.302365Z",
     "iopub.status.idle": "2025-07-07T10:47:06.763110Z",
     "shell.execute_reply": "2025-07-07T10:47:06.762379Z"
    },
    "papermill": {
     "duration": 164.479338,
     "end_time": "2025-07-07T10:47:06.764465",
     "exception": false,
     "start_time": "2025-07-07T10:44:22.285127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENTRAÎNEMENT FTT++ MODULAIRE - DATASET TELECOM ===\r\n",
      "GPU détecté: Tesla P100-PCIE-16GB (17.1GB)\r\n",
      "Device sélectionné: cuda\r\n",
      "Chargement des données (seed: 0)\r\n",
      "Données originales: 7043 lignes\r\n",
      "Après nettoyage: 7032 lignes (11 supprimées)\r\n",
      "\r\n",
      "Informations sur les features:\r\n",
      "Features numériques (3): ['tenure', 'MonthlyCharges', 'TotalCharges']\r\n",
      "Variables catégorielles (16): ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\r\n",
      "Cardinalités des variables catégorielles: [2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4]\r\n",
      "Distribution des classes: [5163 1869]\r\n",
      "Tailles des ensembles:\r\n",
      "Train: 4781 | Val: 844 | Test: 1407\r\n",
      "Features numériques: 3\r\n",
      "Features catégorielles: 16\r\n",
      "Échantillons: train=4781, val=844, test=1407\r\n",
      "🚀 === PIPELINE FTT++ COMPLET ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "🚀 === ÉTAPE 1: Entraînement FTT+ Complet ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "✅ Validation mapping: 3 num + 16 cat = 19 total\r\n",
      "Type d'embedding numérique: T-LR\r\n",
      "/usr/local/lib/python3.11/dist-packages/rtdl_num_embeddings.py:499: UserWarning: Computing tree-based bins involves the conversion of the input PyTorch tensors to NumPy arrays. The provided PyTorch tensors are not located on CPU, so the conversion has some overhead.\r\n",
      "  warnings.warn(\r\n",
      "Modèle FTT+ créé avec 90,689 paramètres\r\n",
      "⏳ Entraînement du modèle FTT+ en cours...\r\n",
      "Epoch 000 | Train Loss: 0.4738 | Val Loss: 0.4172 | Time: 2.02s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4172)\r\n",
      "Epoch 001 | Train Loss: 0.4362 | Val Loss: 0.4199 | Time: 1.78s\r\n",
      "Epoch 002 | Train Loss: 0.4368 | Val Loss: 0.4174 | Time: 1.74s\r\n",
      "Epoch 003 | Train Loss: 0.4321 | Val Loss: 0.4131 | Time: 1.77s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4131)\r\n",
      "Epoch 004 | Train Loss: 0.4307 | Val Loss: 0.4113 | Time: 1.72s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4113)\r\n",
      "Epoch 005 | Train Loss: 0.4250 | Val Loss: 0.4099 | Time: 1.74s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4099)\r\n",
      "Epoch 006 | Train Loss: 0.4258 | Val Loss: 0.4105 | Time: 1.76s\r\n",
      "Epoch 007 | Train Loss: 0.4207 | Val Loss: 0.4101 | Time: 1.79s\r\n",
      "Epoch 008 | Train Loss: 0.4210 | Val Loss: 0.4114 | Time: 1.73s\r\n",
      "Epoch 009 | Train Loss: 0.4166 | Val Loss: 0.4091 | Time: 1.72s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4091)\r\n",
      "Epoch 010 | Train Loss: 0.4208 | Val Loss: 0.4149 | Time: 1.72s\r\n",
      "Epoch 011 | Train Loss: 0.4217 | Val Loss: 0.4083 | Time: 1.69s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4083)\r\n",
      "Epoch 012 | Train Loss: 0.4162 | Val Loss: 0.4089 | Time: 1.80s\r\n",
      "Epoch 013 | Train Loss: 0.4176 | Val Loss: 0.4076 | Time: 1.75s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4076)\r\n",
      "Epoch 014 | Train Loss: 0.4173 | Val Loss: 0.4108 | Time: 1.76s\r\n",
      "Epoch 015 | Train Loss: 0.4152 | Val Loss: 0.4118 | Time: 1.85s\r\n",
      "Epoch 016 | Train Loss: 0.4188 | Val Loss: 0.4105 | Time: 1.74s\r\n",
      "Epoch 017 | Train Loss: 0.4120 | Val Loss: 0.4117 | Time: 1.73s\r\n",
      "Epoch 018 | Train Loss: 0.4133 | Val Loss: 0.4174 | Time: 1.77s\r\n",
      "Epoch 019 | Train Loss: 0.4094 | Val Loss: 0.4154 | Time: 1.75s\r\n",
      "Epoch 020 | Train Loss: 0.4070 | Val Loss: 0.4178 | Time: 1.74s\r\n",
      "Epoch 021 | Train Loss: 0.4139 | Val Loss: 0.4151 | Time: 1.74s\r\n",
      "Epoch 022 | Train Loss: 0.4053 | Val Loss: 0.4107 | Time: 1.73s\r\n",
      "Epoch 023 | Train Loss: 0.4075 | Val Loss: 0.4107 | Time: 1.73s\r\n",
      "Epoch 024 | Train Loss: 0.4079 | Val Loss: 0.4214 | Time: 1.80s\r\n",
      "Epoch 025 | Train Loss: 0.4069 | Val Loss: 0.4289 | Time: 1.73s\r\n",
      "Epoch 026 | Train Loss: 0.4054 | Val Loss: 0.4246 | Time: 1.76s\r\n",
      "Epoch 027 | Train Loss: 0.4070 | Val Loss: 0.4229 | Time: 1.74s\r\n",
      "Epoch 028 | Train Loss: 0.4071 | Val Loss: 0.4295 | Time: 1.75s\r\n",
      "Epoch 029 | Train Loss: 0.3988 | Val Loss: 0.4128 | Time: 1.78s\r\n",
      "Epoch 030 | Train Loss: 0.4031 | Val Loss: 0.4249 | Time: 1.77s\r\n",
      "Epoch 031 | Train Loss: 0.4024 | Val Loss: 0.4229 | Time: 1.75s\r\n",
      "Epoch 032 | Train Loss: 0.4000 | Val Loss: 0.4323 | Time: 1.81s\r\n",
      "Epoch 033 | Train Loss: 0.4032 | Val Loss: 0.4248 | Time: 1.82s\r\n",
      "\r\n",
      "Early stopping à l'époque 33 (patience: 20)\r\n",
      "✅ Meilleur modèle chargé (époque 13, val_loss: 0.4076)\r\n",
      "\r\n",
      "📊 Évaluation finale du modèle FTT+...\r\n",
      "\r\n",
      "🔍 Analyse d'interprétabilité avec interpretability_analyzer...\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. Contract            : 0.0535\r\n",
      "   2. MonthlyCharges      : 0.0532\r\n",
      "   3. SeniorCitizen       : 0.0531\r\n",
      "   4. gender              : 0.0530\r\n",
      "   5. PhoneService        : 0.0530\r\n",
      "   6. Partner             : 0.0529\r\n",
      "   7. OnlineBackup        : 0.0529\r\n",
      "   8. PaperlessBilling    : 0.0529\r\n",
      "   9. tenure              : 0.0528\r\n",
      "  10. TotalCharges        : 0.0528\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus_plus/seed_0/heatmaps/interpretable_ftt_plus_from_ftt_plus_plus_importance_seed_0.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_metrics_seed_0.json\r\n",
      "Importance: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_importance_seed_0.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_{importance|attention}_seed_0.png\r\n",
      "Modèle: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_from_ftt_plus_plus_weights_seed_0.pt\r\n",
      "\r\n",
      "🎯 Sélection des 15 features les plus importantes...\r\n",
      "📋 Features sélectionnées:\r\n",
      "   1. Contract             (CAT): 0.0535\r\n",
      "   2. MonthlyCharges       (NUM): 0.0532\r\n",
      "   3. SeniorCitizen        (CAT): 0.0531\r\n",
      "   4. gender               (CAT): 0.0530\r\n",
      "   5. PhoneService         (CAT): 0.0530\r\n",
      "   6. Partner              (CAT): 0.0529\r\n",
      "   7. OnlineBackup         (CAT): 0.0529\r\n",
      "   8. PaperlessBilling     (CAT): 0.0529\r\n",
      "   9. tenure               (NUM): 0.0528\r\n",
      "  10. TotalCharges         (NUM): 0.0528\r\n",
      "  11. MultipleLines        (CAT): 0.0528\r\n",
      "  12. InternetService      (CAT): 0.0526\r\n",
      "  13. Dependents           (CAT): 0.0526\r\n",
      "  14. OnlineSecurity       (CAT): 0.0522\r\n",
      "  15. StreamingMovies      (CAT): 0.0520\r\n",
      "\r\n",
      "🎯 === ÉTAPE 2: Entraînement Modèle Random ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "📋 Mapping des features sélectionnées:\r\n",
      "   - Numériques sélectionnées: ['MonthlyCharges', 'tenure', 'TotalCharges'] → indices [1, 0, 2]\r\n",
      "   - Catégorielles sélectionnées: ['Contract', 'SeniorCitizen', 'gender', 'PhoneService', 'Partner', 'OnlineBackup', 'PaperlessBilling', 'MultipleLines', 'InternetService', 'Dependents', 'OnlineSecurity', 'StreamingMovies'] → indices [13, 1, 0, 4, 2, 8, 14, 5, 6, 3, 7, 12]\r\n",
      "📊 Features sélectionnées: 3 numériques, 12 catégorielles\r\n",
      "🎲 Interactions aléatoires: 8 paires\r\n",
      "Modèle Random créé avec 86,913 paramètres\r\n",
      "🔗 Sparsité d'attention: 82.03%\r\n",
      "   - Connexions feature-feature: 16\r\n",
      "⏳ Entraînement du modèle Random en cours...\r\n",
      "Epoch 000 | Train Loss: 0.5213 | Val Loss: 0.4426 | Time: 1.68s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4426)\r\n",
      "Epoch 001 | Train Loss: 0.4597 | Val Loss: 0.4352 | Time: 1.61s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4352)\r\n",
      "Epoch 002 | Train Loss: 0.4516 | Val Loss: 0.4357 | Time: 1.60s\r\n",
      "Epoch 003 | Train Loss: 0.4489 | Val Loss: 0.4276 | Time: 1.65s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4276)\r\n",
      "Epoch 004 | Train Loss: 0.4473 | Val Loss: 0.4266 | Time: 1.65s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4266)\r\n",
      "Epoch 005 | Train Loss: 0.4449 | Val Loss: 0.4327 | Time: 1.64s\r\n",
      "Epoch 006 | Train Loss: 0.4447 | Val Loss: 0.4228 | Time: 1.63s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4228)\r\n",
      "Epoch 007 | Train Loss: 0.4430 | Val Loss: 0.4237 | Time: 1.66s\r\n",
      "Epoch 008 | Train Loss: 0.4351 | Val Loss: 0.4228 | Time: 1.66s\r\n",
      "Epoch 009 | Train Loss: 0.4378 | Val Loss: 0.4327 | Time: 1.66s\r\n",
      "Epoch 010 | Train Loss: 0.4393 | Val Loss: 0.4229 | Time: 1.66s\r\n",
      "Epoch 011 | Train Loss: 0.4361 | Val Loss: 0.4287 | Time: 1.60s\r\n",
      "Epoch 012 | Train Loss: 0.4389 | Val Loss: 0.4291 | Time: 1.64s\r\n",
      "Epoch 013 | Train Loss: 0.4339 | Val Loss: 0.4200 | Time: 1.70s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4200)\r\n",
      "Epoch 014 | Train Loss: 0.4379 | Val Loss: 0.4190 | Time: 1.64s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4190)\r\n",
      "Epoch 015 | Train Loss: 0.4311 | Val Loss: 0.4224 | Time: 1.66s\r\n",
      "Epoch 016 | Train Loss: 0.4301 | Val Loss: 0.4244 | Time: 1.64s\r\n",
      "Epoch 017 | Train Loss: 0.4325 | Val Loss: 0.4176 | Time: 1.80s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4176)\r\n",
      "Epoch 018 | Train Loss: 0.4294 | Val Loss: 0.4191 | Time: 1.65s\r\n",
      "Epoch 019 | Train Loss: 0.4317 | Val Loss: 0.4163 | Time: 1.68s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4163)\r\n",
      "Epoch 020 | Train Loss: 0.4318 | Val Loss: 0.4178 | Time: 1.63s\r\n",
      "Epoch 021 | Train Loss: 0.4303 | Val Loss: 0.4181 | Time: 1.61s\r\n",
      "Epoch 022 | Train Loss: 0.4275 | Val Loss: 0.4189 | Time: 1.59s\r\n",
      "Epoch 023 | Train Loss: 0.4311 | Val Loss: 0.4224 | Time: 1.61s\r\n",
      "Epoch 024 | Train Loss: 0.4272 | Val Loss: 0.4195 | Time: 1.60s\r\n",
      "Epoch 025 | Train Loss: 0.4288 | Val Loss: 0.4240 | Time: 1.67s\r\n",
      "Epoch 026 | Train Loss: 0.4260 | Val Loss: 0.4232 | Time: 1.66s\r\n",
      "Epoch 027 | Train Loss: 0.4301 | Val Loss: 0.4196 | Time: 1.64s\r\n",
      "Epoch 028 | Train Loss: 0.4303 | Val Loss: 0.4229 | Time: 1.65s\r\n",
      "Epoch 029 | Train Loss: 0.4310 | Val Loss: 0.4250 | Time: 1.62s\r\n",
      "Epoch 030 | Train Loss: 0.4280 | Val Loss: 0.4267 | Time: 1.66s\r\n",
      "Epoch 031 | Train Loss: 0.4325 | Val Loss: 0.4241 | Time: 1.68s\r\n",
      "Epoch 032 | Train Loss: 0.4303 | Val Loss: 0.4240 | Time: 1.64s\r\n",
      "Epoch 033 | Train Loss: 0.4307 | Val Loss: 0.4186 | Time: 1.61s\r\n",
      "Epoch 034 | Train Loss: 0.4280 | Val Loss: 0.4178 | Time: 1.62s\r\n",
      "Epoch 035 | Train Loss: 0.4243 | Val Loss: 0.4154 | Time: 1.65s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4154)\r\n",
      "Epoch 036 | Train Loss: 0.4244 | Val Loss: 0.4206 | Time: 1.85s\r\n",
      "Epoch 037 | Train Loss: 0.4249 | Val Loss: 0.4140 | Time: 1.75s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4140)\r\n",
      "Epoch 038 | Train Loss: 0.4251 | Val Loss: 0.4197 | Time: 1.68s\r\n",
      "Epoch 039 | Train Loss: 0.4222 | Val Loss: 0.4179 | Time: 1.69s\r\n",
      "Epoch 040 | Train Loss: 0.4218 | Val Loss: 0.4146 | Time: 1.66s\r\n",
      "Epoch 041 | Train Loss: 0.4270 | Val Loss: 0.4275 | Time: 1.65s\r\n",
      "Epoch 042 | Train Loss: 0.4277 | Val Loss: 0.4214 | Time: 1.66s\r\n",
      "Epoch 043 | Train Loss: 0.4242 | Val Loss: 0.4203 | Time: 1.73s\r\n",
      "Epoch 044 | Train Loss: 0.4284 | Val Loss: 0.4239 | Time: 1.64s\r\n",
      "Epoch 045 | Train Loss: 0.4271 | Val Loss: 0.4206 | Time: 1.65s\r\n",
      "Epoch 046 | Train Loss: 0.4257 | Val Loss: 0.4210 | Time: 1.66s\r\n",
      "Epoch 047 | Train Loss: 0.4241 | Val Loss: 0.4221 | Time: 1.62s\r\n",
      "Epoch 048 | Train Loss: 0.4238 | Val Loss: 0.4218 | Time: 1.61s\r\n",
      "Epoch 049 | Train Loss: 0.4239 | Val Loss: 0.4248 | Time: 1.72s\r\n",
      "Epoch 050 | Train Loss: 0.4243 | Val Loss: 0.4239 | Time: 1.64s\r\n",
      "Epoch 051 | Train Loss: 0.4268 | Val Loss: 0.4245 | Time: 1.65s\r\n",
      "Epoch 052 | Train Loss: 0.4291 | Val Loss: 0.4283 | Time: 1.65s\r\n",
      "Epoch 053 | Train Loss: 0.4265 | Val Loss: 0.4251 | Time: 1.65s\r\n",
      "Epoch 054 | Train Loss: 0.4257 | Val Loss: 0.4273 | Time: 1.63s\r\n",
      "Epoch 055 | Train Loss: 0.4235 | Val Loss: 0.4286 | Time: 1.75s\r\n",
      "Epoch 056 | Train Loss: 0.4271 | Val Loss: 0.4243 | Time: 1.62s\r\n",
      "Epoch 057 | Train Loss: 0.4279 | Val Loss: 0.4247 | Time: 1.61s\r\n",
      "\r\n",
      "Early stopping à l'époque 57 (patience: 20)\r\n",
      "✅ Meilleur modèle Random chargé (époque 37, val_loss: 0.4140)\r\n",
      "\r\n",
      "📊 Évaluation finale du modèle Random...\r\n",
      "\r\n",
      "🔍 Analyse d'importance des features dans le modèle Random...\r\n",
      "\r\n",
      "📊 Importance des features dans le modèle Random:\r\n",
      "   1. TotalCharges         (NUM): 0.1214\r\n",
      "   2. PhoneService         (CAT): 0.1199\r\n",
      "   3. PaperlessBilling     (CAT): 0.1198\r\n",
      "   4. OnlineSecurity       (CAT): 0.1141\r\n",
      "   5. tenure               (NUM): 0.0874\r\n",
      "   6. Dependents           (CAT): 0.0788\r\n",
      "   7. Contract             (CAT): 0.0708\r\n",
      "   8. InternetService      (CAT): 0.0696\r\n",
      "   9. Partner              (CAT): 0.0473\r\n",
      "  10. MultipleLines        (CAT): 0.0369\r\n",
      "  11. SeniorCitizen        (CAT): 0.0274\r\n",
      "  12. MonthlyCharges       (NUM): 0.0273\r\n",
      "  13. gender               (CAT): 0.0267\r\n",
      "  14. StreamingMovies      (CAT): 0.0263\r\n",
      "  15. OnlineBackup         (CAT): 0.0263\r\n",
      "\r\n",
      "🔍 Analyse d'interprétabilité complète du modèle Random...\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. TotalCharges        : 0.1214\r\n",
      "   2. PhoneService        : 0.1199\r\n",
      "   3. PaperlessBilling    : 0.1198\r\n",
      "   4. OnlineSecurity      : 0.1141\r\n",
      "   5. tenure              : 0.0874\r\n",
      "   6. Dependents          : 0.0788\r\n",
      "   7. Contract            : 0.0708\r\n",
      "   8. InternetService     : 0.0696\r\n",
      "   9. Partner             : 0.0473\r\n",
      "  10. MultipleLines       : 0.0369\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus_plus/seed_0/heatmaps/interpretable_ftt_plus_plus_importance_seed_0.png\r\n",
      "Heatmap d'attention sparse sauvegardée: results/results_telecom/ftt_plus_plus/seed_0/heatmaps/interpretable_ftt_plus_plus_attention_seed_0.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_metrics_seed_0.json\r\n",
      "Importance: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_importance_seed_0.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_{importance|attention}_seed_0.png\r\n",
      "Modèle: results/results_telecom/ftt_plus_plus/seed_0/interpretable_ftt_plus_plus_weights_seed_0.pt\r\n",
      "💾 Résultats complets sauvegardés: results/results_telecom/ftt_plus_plus/seed_0/métriques/ftt_plus_plus_results.json\r\n",
      "\r\n",
      "✅ === PIPELINE TERMINÉ EN 159.6s ===\r\n"
     ]
    }
   ],
   "source": [
    "# Avec embedding T-LR et paramètres personnalisés\n",
    "!PYTHONPATH=/kaggle/working/customer-churn-ft_transformer python train/Telecom/train_ftt_plus_plus/train.py --embedding_type \"T-LR\" --M 15 --k 8 --stage1_epochs 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dd36dda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:47:06.806222Z",
     "iopub.status.busy": "2025-07-07T10:47:06.805584Z",
     "iopub.status.idle": "2025-07-07T10:48:45.772690Z",
     "shell.execute_reply": "2025-07-07T10:48:45.771896Z"
    },
    "papermill": {
     "duration": 98.989113,
     "end_time": "2025-07-07T10:48:45.774043",
     "exception": false,
     "start_time": "2025-07-07T10:47:06.784930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENTRAÎNEMENT FTT++ MODULAIRE - DATASET TELECOM ===\r\n",
      "GPU détecté: Tesla P100-PCIE-16GB (17.1GB)\r\n",
      "Device sélectionné: cuda\r\n",
      "Chargement des données (seed: 42)\r\n",
      "Données originales: 7043 lignes\r\n",
      "Après nettoyage: 7032 lignes (11 supprimées)\r\n",
      "\r\n",
      "Informations sur les features:\r\n",
      "Features numériques (3): ['tenure', 'MonthlyCharges', 'TotalCharges']\r\n",
      "Variables catégorielles (16): ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\r\n",
      "Cardinalités des variables catégorielles: [2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 4]\r\n",
      "Distribution des classes: [5163 1869]\r\n",
      "Tailles des ensembles:\r\n",
      "Train: 4781 | Val: 844 | Test: 1407\r\n",
      "Features numériques: 3\r\n",
      "Features catégorielles: 16\r\n",
      "Échantillons: train=4781, val=844, test=1407\r\n",
      "🚀 === PIPELINE FTT++ COMPLET ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "🚀 === ÉTAPE 1: Entraînement FTT+ Complet ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "✅ Validation mapping: 3 num + 16 cat = 19 total\r\n",
      "Type d'embedding numérique: P-LR-LR\r\n",
      "Modèle FTT+ créé avec 285,841 paramètres\r\n",
      "⏳ Entraînement du modèle FTT+ en cours...\r\n",
      "Epoch 000 | Train Loss: 0.4805 | Val Loss: 0.4499 | Time: 2.16s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4499)\r\n",
      "Epoch 001 | Train Loss: 0.4468 | Val Loss: 0.4405 | Time: 1.85s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4405)\r\n",
      "Epoch 002 | Train Loss: 0.4449 | Val Loss: 0.4383 | Time: 1.85s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4383)\r\n",
      "Epoch 003 | Train Loss: 0.4420 | Val Loss: 0.4381 | Time: 1.83s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4381)\r\n",
      "Epoch 004 | Train Loss: 0.4365 | Val Loss: 0.4411 | Time: 1.90s\r\n",
      "Epoch 005 | Train Loss: 0.4350 | Val Loss: 0.4376 | Time: 1.85s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4376)\r\n",
      "Epoch 006 | Train Loss: 0.4315 | Val Loss: 0.4464 | Time: 1.84s\r\n",
      "Epoch 007 | Train Loss: 0.4307 | Val Loss: 0.4344 | Time: 1.81s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4344)\r\n",
      "Epoch 008 | Train Loss: 0.4293 | Val Loss: 0.4391 | Time: 1.83s\r\n",
      "Epoch 009 | Train Loss: 0.4316 | Val Loss: 0.4385 | Time: 1.85s\r\n",
      "Epoch 010 | Train Loss: 0.4308 | Val Loss: 0.4431 | Time: 1.92s\r\n",
      "Epoch 011 | Train Loss: 0.4247 | Val Loss: 0.4485 | Time: 1.81s\r\n",
      "Epoch 012 | Train Loss: 0.4287 | Val Loss: 0.4439 | Time: 1.86s\r\n",
      "Epoch 013 | Train Loss: 0.4309 | Val Loss: 0.4439 | Time: 1.84s\r\n",
      "Epoch 014 | Train Loss: 0.4223 | Val Loss: 0.4497 | Time: 1.87s\r\n",
      "Epoch 015 | Train Loss: 0.4224 | Val Loss: 0.4562 | Time: 1.85s\r\n",
      "Epoch 016 | Train Loss: 0.4253 | Val Loss: 0.4462 | Time: 1.83s\r\n",
      "Epoch 017 | Train Loss: 0.4190 | Val Loss: 0.4486 | Time: 1.83s\r\n",
      "Epoch 018 | Train Loss: 0.4245 | Val Loss: 0.4493 | Time: 1.83s\r\n",
      "Epoch 019 | Train Loss: 0.4302 | Val Loss: 0.4405 | Time: 1.82s\r\n",
      "Epoch 020 | Train Loss: 0.4230 | Val Loss: 0.4489 | Time: 1.85s\r\n",
      "Epoch 021 | Train Loss: 0.4224 | Val Loss: 0.4435 | Time: 1.83s\r\n",
      "Epoch 022 | Train Loss: 0.4237 | Val Loss: 0.4509 | Time: 1.82s\r\n",
      "Epoch 023 | Train Loss: 0.4218 | Val Loss: 0.4460 | Time: 1.85s\r\n",
      "Epoch 024 | Train Loss: 0.4197 | Val Loss: 0.4604 | Time: 1.84s\r\n",
      "Epoch 025 | Train Loss: 0.4209 | Val Loss: 0.4487 | Time: 1.86s\r\n",
      "Epoch 026 | Train Loss: 0.4193 | Val Loss: 0.4462 | Time: 1.84s\r\n",
      "Epoch 027 | Train Loss: 0.4194 | Val Loss: 0.4420 | Time: 1.91s\r\n",
      "\r\n",
      "Early stopping à l'époque 27 (patience: 20)\r\n",
      "✅ Meilleur modèle chargé (époque 7, val_loss: 0.4344)\r\n",
      "\r\n",
      "📊 Évaluation finale du modèle FTT+...\r\n",
      "\r\n",
      "🔍 Analyse d'interprétabilité avec interpretability_analyzer...\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. TotalCharges        : 0.0535\r\n",
      "   2. gender              : 0.0531\r\n",
      "   3. SeniorCitizen       : 0.0529\r\n",
      "   4. StreamingTV         : 0.0529\r\n",
      "   5. PaymentMethod       : 0.0528\r\n",
      "   6. TechSupport         : 0.0528\r\n",
      "   7. PaperlessBilling    : 0.0528\r\n",
      "   8. tenure              : 0.0527\r\n",
      "   9. MonthlyCharges      : 0.0527\r\n",
      "  10. OnlineSecurity      : 0.0526\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus_plus/seed_42/heatmaps/interpretable_ftt_plus_from_ftt_plus_plus_importance_seed_42.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_from_ftt_plus_plus_metrics_seed_42.json\r\n",
      "Importance: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_from_ftt_plus_plus_importance_seed_42.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_from_ftt_plus_plus_{importance|attention}_seed_42.png\r\n",
      "Modèle: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_from_ftt_plus_plus_weights_seed_42.pt\r\n",
      "\r\n",
      "🎯 Sélection des 12 features les plus importantes...\r\n",
      "📋 Features sélectionnées:\r\n",
      "   1. TotalCharges         (NUM): 0.0535\r\n",
      "   2. gender               (CAT): 0.0531\r\n",
      "   3. SeniorCitizen        (CAT): 0.0529\r\n",
      "   4. StreamingTV          (CAT): 0.0529\r\n",
      "   5. PaymentMethod        (CAT): 0.0528\r\n",
      "   6. TechSupport          (CAT): 0.0528\r\n",
      "   7. PaperlessBilling     (CAT): 0.0528\r\n",
      "   8. tenure               (NUM): 0.0527\r\n",
      "   9. MonthlyCharges       (NUM): 0.0527\r\n",
      "  10. OnlineSecurity       (CAT): 0.0526\r\n",
      "  11. StreamingMovies      (CAT): 0.0526\r\n",
      "  12. OnlineBackup         (CAT): 0.0525\r\n",
      "\r\n",
      "🎯 === ÉTAPE 2: Entraînement Modèle Random ===\r\n",
      "🖥️  Device utilisé: cuda\r\n",
      "📋 Mapping des features sélectionnées:\r\n",
      "   - Numériques sélectionnées: ['TotalCharges', 'tenure', 'MonthlyCharges'] → indices [2, 0, 1]\r\n",
      "   - Catégorielles sélectionnées: ['gender', 'SeniorCitizen', 'StreamingTV', 'PaymentMethod', 'TechSupport', 'PaperlessBilling', 'OnlineSecurity', 'StreamingMovies', 'OnlineBackup'] → indices [0, 1, 11, 15, 10, 14, 7, 12, 8]\r\n",
      "📊 Features sélectionnées: 3 numériques, 9 catégorielles\r\n",
      "🎲 Interactions aléatoires: 6 paires\r\n",
      "Modèle Random créé avec 237,825 paramètres\r\n",
      "🔗 Sparsité d'attention: 78.70%\r\n",
      "   - Connexions feature-feature: 12\r\n",
      "⏳ Entraînement du modèle Random en cours...\r\n",
      "Epoch 000 | Train Loss: 0.4908 | Val Loss: 0.4521 | Time: 1.62s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4521)\r\n",
      "Epoch 001 | Train Loss: 0.4587 | Val Loss: 0.4575 | Time: 1.65s\r\n",
      "Epoch 002 | Train Loss: 0.4498 | Val Loss: 0.4516 | Time: 1.72s\r\n",
      " <<< NOUVEAU MEILLEUR MODÈLE (val_loss: 0.4516)\r\n",
      "Epoch 003 | Train Loss: 0.4493 | Val Loss: 0.4610 | Time: 1.68s\r\n",
      "Epoch 004 | Train Loss: 0.4481 | Val Loss: 0.4638 | Time: 1.65s\r\n",
      "Epoch 005 | Train Loss: 0.4403 | Val Loss: 0.4649 | Time: 1.66s\r\n",
      "Epoch 006 | Train Loss: 0.4458 | Val Loss: 0.4589 | Time: 1.66s\r\n",
      "Epoch 007 | Train Loss: 0.4423 | Val Loss: 0.4628 | Time: 1.67s\r\n",
      "Epoch 008 | Train Loss: 0.4417 | Val Loss: 0.4702 | Time: 1.71s\r\n",
      "Epoch 009 | Train Loss: 0.4381 | Val Loss: 0.4630 | Time: 1.66s\r\n",
      "Epoch 010 | Train Loss: 0.4405 | Val Loss: 0.4664 | Time: 1.66s\r\n",
      "Epoch 011 | Train Loss: 0.4360 | Val Loss: 0.4638 | Time: 1.66s\r\n",
      "Epoch 012 | Train Loss: 0.4348 | Val Loss: 0.4692 | Time: 1.66s\r\n",
      "Epoch 013 | Train Loss: 0.4334 | Val Loss: 0.4685 | Time: 1.66s\r\n",
      "Epoch 014 | Train Loss: 0.4347 | Val Loss: 0.4621 | Time: 1.69s\r\n",
      "Epoch 015 | Train Loss: 0.4342 | Val Loss: 0.4711 | Time: 1.67s\r\n",
      "Epoch 016 | Train Loss: 0.4350 | Val Loss: 0.4656 | Time: 1.68s\r\n",
      "Epoch 017 | Train Loss: 0.4382 | Val Loss: 0.4567 | Time: 1.88s\r\n",
      "Epoch 018 | Train Loss: 0.4357 | Val Loss: 0.4658 | Time: 1.69s\r\n",
      "Epoch 019 | Train Loss: 0.4328 | Val Loss: 0.4705 | Time: 1.65s\r\n",
      "Epoch 020 | Train Loss: 0.4334 | Val Loss: 0.4681 | Time: 1.72s\r\n",
      "Epoch 021 | Train Loss: 0.4276 | Val Loss: 0.4744 | Time: 1.65s\r\n",
      "Epoch 022 | Train Loss: 0.4232 | Val Loss: 0.4744 | Time: 1.67s\r\n",
      "\r\n",
      "Early stopping à l'époque 22 (patience: 20)\r\n",
      "✅ Meilleur modèle Random chargé (époque 2, val_loss: 0.4516)\r\n",
      "\r\n",
      "📊 Évaluation finale du modèle Random...\r\n",
      "\r\n",
      "🔍 Analyse d'importance des features dans le modèle Random...\r\n",
      "\r\n",
      "📊 Importance des features dans le modèle Random:\r\n",
      "   1. tenure               (NUM): 0.1511\r\n",
      "   2. PaymentMethod        (CAT): 0.1235\r\n",
      "   3. TechSupport          (CAT): 0.1052\r\n",
      "   4. SeniorCitizen        (CAT): 0.0829\r\n",
      "   5. MonthlyCharges       (NUM): 0.0808\r\n",
      "   6. PaperlessBilling     (CAT): 0.0806\r\n",
      "   7. StreamingTV          (CAT): 0.0776\r\n",
      "   8. TotalCharges         (NUM): 0.0671\r\n",
      "   9. gender               (CAT): 0.0580\r\n",
      "  10. StreamingMovies      (CAT): 0.0578\r\n",
      "  11. OnlineSecurity       (CAT): 0.0577\r\n",
      "  12. OnlineBackup         (CAT): 0.0576\r\n",
      "\r\n",
      "🔍 Analyse d'interprétabilité complète du modèle Random...\r\n",
      "\r\n",
      "=== Analyse d'interprétabilité ===\r\n",
      "\r\n",
      "Top 10 features importantes:\r\n",
      "   1. tenure              : 0.1511\r\n",
      "   2. PaymentMethod       : 0.1235\r\n",
      "   3. TechSupport         : 0.1052\r\n",
      "   4. SeniorCitizen       : 0.0829\r\n",
      "   5. MonthlyCharges      : 0.0808\r\n",
      "   6. PaperlessBilling    : 0.0806\r\n",
      "   7. StreamingTV         : 0.0776\r\n",
      "   8. TotalCharges        : 0.0671\r\n",
      "   9. gender              : 0.0580\r\n",
      "  10. StreamingMovies     : 0.0578\r\n",
      "\r\n",
      "Génération des visualisations...\r\n",
      "Graphique d'importance sauvegardé: results/results_telecom/ftt_plus_plus/seed_42/heatmaps/interpretable_ftt_plus_plus_importance_seed_42.png\r\n",
      "Heatmap d'attention sparse sauvegardée: results/results_telecom/ftt_plus_plus/seed_42/heatmaps/interpretable_ftt_plus_plus_attention_seed_42.png\r\n",
      "\r\n",
      "=== Résultats sauvegardés ===\r\n",
      "Métriques: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_plus_metrics_seed_42.json\r\n",
      "Importance: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_plus_importance_seed_42.json\r\n",
      "Visualisations: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_plus_{importance|attention}_seed_42.png\r\n",
      "Modèle: results/results_telecom/ftt_plus_plus/seed_42/interpretable_ftt_plus_plus_weights_seed_42.pt\r\n",
      "💾 Résultats complets sauvegardés: results/results_telecom/ftt_plus_plus/seed_42/métriques/ftt_plus_plus_results.json\r\n",
      "\r\n",
      "✅ === PIPELINE TERMINÉ EN 94.0s ===\r\n"
     ]
    }
   ],
   "source": [
    "# Configuration complète\n",
    "!PYTHONPATH=/kaggle/working/customer-churn-ft_transformer python train/Telecom/train_ftt_plus_plus/train.py \\\n",
    "    --embedding_type \"P-LR-LR\" \\\n",
    "    --M 12 \\\n",
    "    --k 6 \\\n",
    "    --stage1_epochs 75 \\\n",
    "    --stage2_epochs 50 \\\n",
    "    --lr 0.0005 \\\n",
    "    --d_token 128 \\\n",
    "    --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade67f7a",
   "metadata": {
    "papermill": {
     "duration": 0.022304,
     "end_time": "2025-07-07T10:48:45.819894",
     "exception": false,
     "start_time": "2025-07-07T10:48:45.797590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac1c3f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:48:45.866604Z",
     "iopub.status.busy": "2025-07-07T10:48:45.865853Z",
     "iopub.status.idle": "2025-07-07T10:48:46.099105Z",
     "shell.execute_reply": "2025-07-07T10:48:46.098121Z"
    },
    "papermill": {
     "duration": 0.258141,
     "end_time": "2025-07-07T10:48:46.100575",
     "exception": false,
     "start_time": "2025-07-07T10:48:45.842434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/customer-churn-ft_transformer\r\n",
      "total 172\r\n",
      "drwxr-xr-x 10 root root  4096 Jul  7 10:38 .\r\n",
      "drwxr-xr-x  3 root root  4096 Jul  7 10:35 ..\r\n",
      "drwxr-xr-x  3 root root  4096 Jul  7 10:35 data\r\n",
      "-rw-r--r--  1 root root 92591 Jul  7 10:35 Experiments.ipynb\r\n",
      "drwxr-xr-x  3 root root  4096 Jul  7 10:39 ftt_plus\r\n",
      "drwxr-xr-x  8 root root  4096 Jul  7 10:40 ftt_plus_plus\r\n",
      "drwxr-xr-x  8 root root  4096 Jul  7 10:35 .git\r\n",
      "-rw-r--r--  1 root root  7839 Jul  7 10:35 interpretability_analyzer.py\r\n",
      "-rw-r--r--  1 root root 10266 Jul  7 10:35 num_embedding_factory.py\r\n",
      "drwxr-xr-x  2 root root  4096 Jul  7 10:39 __pycache__\r\n",
      "-rw-r--r--  1 root root  6726 Jul  7 10:35 README.md\r\n",
      "drwxr-xr-x  3 root root  4096 Jul  7 10:38 results\r\n",
      "drwxr-xr-x  5 root root  4096 Jul  7 10:35 rtdl_lib\r\n",
      "-rw-r--r--  1 root root  6821 Jul  7 10:35 test_embeddings.py\r\n",
      "drwxr-xr-x  3 root root  4096 Jul  7 10:35 train\r\n",
      "-rw-r--r--  1 root root  2213 Jul  7 10:35 utils.py\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22c1acb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-07T10:48:46.148876Z",
     "iopub.status.busy": "2025-07-07T10:48:46.148601Z",
     "iopub.status.idle": "2025-07-07T10:48:46.651141Z",
     "shell.execute_reply": "2025-07-07T10:48:46.650308Z"
    },
    "papermill": {
     "duration": 0.527474,
     "end_time": "2025-07-07T10:48:46.652414",
     "exception": false,
     "start_time": "2025-07-07T10:48:46.124940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/results.zip'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# On se place dans le bon dossier racine\n",
    "import os\n",
    "os.chdir('/kaggle/working/customer-churn-ft_transformer')\n",
    "\n",
    "# On crée une archive ZIP du dossier results\n",
    "shutil.make_archive('/kaggle/working/results', 'zip', 'results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcc339",
   "metadata": {
    "papermill": {
     "duration": 0.02294,
     "end_time": "2025-07-07T10:48:46.698802",
     "exception": false,
     "start_time": "2025-07-07T10:48:46.675862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b778f5a",
   "metadata": {
    "papermill": {
     "duration": 0.02299,
     "end_time": "2025-07-07T10:48:46.744689",
     "exception": false,
     "start_time": "2025-07-07T10:48:46.721699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 773.808581,
   "end_time": "2025-07-07T10:48:47.086937",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-07T10:35:53.278356",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
